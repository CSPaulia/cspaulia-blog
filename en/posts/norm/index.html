<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>100 Normalization Methods (Work in Progress) | cspaulia-blog</title><meta name=keywords content="Normalization"><meta name=description content="[Epoch 1/100] Updating..."><meta name=author content="CSPaulia"><link rel=canonical href=https://cspaulia.github.io/cspaulia-blog/en/posts/norm/><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><script async src=//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js></script><meta name=referrer content="no-referrer-when-downgrade"><link crossorigin=anonymous href=/cspaulia-blog/assets/css/stylesheet.4a40da687e9ad320449d5d267445e114ee7b6620a3d534bde2b12baa408f07f5.css integrity="sha256-SkDaaH6a0yBEnV0mdEXhFO57ZiCj1TS94rErqkCPB/U=" rel="preload stylesheet" as=style><link rel=icon href=https://cspaulia.github.io/cspaulia-blog/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=https://cspaulia.github.io/cspaulia-blog/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=https://cspaulia.github.io/cspaulia-blog/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=https://cspaulia.github.io/cspaulia-blog/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=https://cspaulia.github.io/cspaulia-blog/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=zh href=https://cspaulia.github.io/cspaulia-blog/posts/norm/><link rel=alternate hreflang=en href=https://cspaulia.github.io/cspaulia-blog/en/posts/norm/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js crossorigin=anonymous></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}],throwOnError:!1,trust:!0,strict:!1})})</script><meta property="og:url" content="https://cspaulia.github.io/cspaulia-blog/en/posts/norm/"><meta property="og:site_name" content="cspaulia-blog"><meta property="og:title" content="100 Normalization Methods (Work in Progress)"><meta property="og:description" content="[Epoch 1/100] Updating..."><meta property="og:locale" content="en-US"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-05-21T21:15:00+08:00"><meta property="article:modified_time" content="2026-01-30T16:43:57+08:00"><meta property="article:tag" content="Normalization"><meta property="og:image" content="https://cspaulia.github.io/cspaulia-blog/norm_cover.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://cspaulia.github.io/cspaulia-blog/norm_cover.png"><meta name=twitter:title content="100 Normalization Methods (Work in Progress)"><meta name=twitter:description content="[Epoch 1/100] Updating..."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://cspaulia.github.io/cspaulia-blog/en/posts/"},{"@type":"ListItem","position":2,"name":"100 Normalization Methods (Work in Progress)","item":"https://cspaulia.github.io/cspaulia-blog/en/posts/norm/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"100 Normalization Methods (Work in Progress)","name":"100 Normalization Methods (Work in Progress)","description":"[Epoch 1/100] Updating...","keywords":["Normalization"],"articleBody":"Layer Normalization In the figure above, $N$ denotes the sample axis, $C$ the channel axis, and $F$ the number of features per channel. Batch Normalization (BN, right) normalizes using features from the same channel across different samples. Layer Normalization (LN, left) normalizes using features from different channels within the same sample.\n1. Issues with BN 1.1 BN and batch size BN computes normalization statistics based on the number of samples in a batch. When the batch is very small (e.g., only 4 samples), the mean and variance estimated from those samples may not represent the global data distribution well, so BN can perform poorly.\n1.2 BN and RNNs Within a batch, sequence lengths often differ. For later time steps (e.g., $t\u003e4$ in the figure), only a small number of sequences may still have valid tokens. Statistics computed from so few samples are not representative of the overall distribution, so BN tends to work poorly in this setting.\nAlso, at inference time, if we encounter a test sequence longer than any training sequence, we may not have the corresponding saved normalization statistics for those time steps, which makes BN hard to apply.\n2. LayerNorm in detail 2.1 LN in an MLP Consider LN in an MLP. Let $H$ be the number of hidden units in a layer, and $l$ be the layer index. LN computes the normalization statistics $\\mu$ and $\\sigma$ as:\n$$ \\mu^{l} = \\frac{1}{H} \\sum_{i=1}^{H} a^l_i ~~~~~~~ \\sigma^{l} = \\sqrt{\\frac{1}{H} \\sum_{i=1}^{H}(a^l_i-\\mu^l)^2} $$\nNote that these statistics do not depend on batch size; they only depend on the number of hidden units. If $H$ is sufficiently large, the estimated statistics can still be stable. The normalized activation is:\n$$ \\hat{a}^l = \\frac{a^l-\\mu^l}{\\sqrt{(\\sigma^l)^2+\\epsilon}} \\tag{1} $$\nwhere $\\epsilon$ is a small constant to avoid division by zero.\nLN also uses learnable parameters to preserve representational capacity: gain $g$ and bias $b$. With activation function $f$, the LN output is:\n$$ h^l = f(g^l \\odot \\hat{a}^l + b^l) \\tag{2} $$\nCombining (1) and (2) and omitting the layer index $l$:\n$$ h=f(\\frac{g}{\\sqrt{\\sigma^2+\\epsilon}} \\odot (a-\\mu) + b) $$\n2.2 LN in an RNN For an RNN at time step $t$, the input is the previous hidden state $h^t$ at time step $t-1$ and the current input $\\text{x}_t$. It can be written as:\n$$ ext{a}^t = W_{hh}h^{t-1}+W_{xh}\\text{x}^{t} $$\nThen we can apply the same normalization procedure on $\\text{a}^t$ as above:\n$$ h^t=f(\\frac{g}{\\sqrt{\\sigma^2+\\epsilon}} \\odot (a^t-\\mu^t) + b) ~~~~~~ \\mu^{t} = \\frac{1}{H} \\sum_{i=1}^{H} a^t_i ~~~~~~~ \\sigma^{l} = \\sqrt{\\frac{1}{H} \\sum_{i=1}^{H}(a^t_i-\\mu^t)^2} $$\n","wordCount":"413","inLanguage":"en","image":"https://cspaulia.github.io/cspaulia-blog/norm_cover.png","datePublished":"2025-05-21T21:15:00+08:00","dateModified":"2026-01-30T16:43:57+08:00","author":{"@type":"Person","name":"CSPaulia"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://cspaulia.github.io/cspaulia-blog/en/posts/norm/"},"publisher":{"@type":"Organization","name":"cspaulia-blog","logo":{"@type":"ImageObject","url":"https://cspaulia.github.io/cspaulia-blog/%3Clink%20/%20abs%20url%3E"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://cspaulia.github.io/cspaulia-blog/en/ accesskey=h title="Home (Alt + H)"><img src=https://cspaulia.github.io/apple-touch-icon.png alt aria-label=logo height=35>Home</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button><ul class=lang-switch><li>|</li><li><a href=https://cspaulia.github.io/cspaulia-blog/ title=中文 aria-label=中文>中文</a></li></ul></div></div><ul id=menu><li><a href=https://cspaulia.github.io/cspaulia-blog/en/publications/ title=Publications><span>Publications</span></a></li><li><a href=https://cspaulia.github.io/cspaulia-blog/en/posts/ title=Posts><span>Posts</span></a></li><li><a href=https://cspaulia.github.io/cspaulia-blog/en/series/ title=Series><span>Series</span></a></li><li><a href=https://cspaulia.github.io/cspaulia-blog/en/categories/ title=Categories><span>Categories</span></a></li><li><a href=https://cspaulia.github.io/cspaulia-blog/en/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://cspaulia.github.io/cspaulia-blog/en/archives/ title=Archives><span>Archives</span></a></li><li><a href=https://cspaulia.github.io/cspaulia-blog/en/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://cspaulia.github.io/cspaulia-blog/en/>Home</a>&nbsp;»&nbsp;<a href=https://cspaulia.github.io/cspaulia-blog/en/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">100 Normalization Methods (Work in Progress)</h1><div class=post-description>[Epoch 1/100] Updating...</div><div class=post-meta><span class=post-meta-item><svg width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><rect x="3" y="4" width="18" height="18" rx="2" ry="2"/><line x1="16" y1="2" x2="16" y2="6"/><line x1="8" y1="2" x2="8" y2="6"/><line x1="3" y1="10" x2="21" y2="10"/></svg> May 21, 2025</span> ｜ <span class=post-meta-item><svg width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M12 19l7-7 3 3-7 7-3-3z"/><path d="M18 13l-1.5-7.5L2 2l3.5 14.5L13 18l5-5z"/><path d="M2 2l7.586 7.586"/><circle cx="11" cy="11" r="2"/></svg> January 30, 2026</span> ｜ <span class=post-meta-item><svg width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M14 2H6A2 2 0 004 4v16a2 2 0 002 2h12a2 2 0 002-2V8z"/><path d="M14 2v6h6"/><line x1="8" y1="13" x2="16" y2="13"/><line x1="8" y1="17" x2="16" y2="17"/><line x1="8" y1="9" x2="12" y2="9"/></svg> 413 words</span> ｜ <span class=post-meta-item><svg width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="10"/><polyline points="12 6 12 12 16 14"/></svg> 2 min</span> ｜ <span class=post-meta-item><svg width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M20 21v-2a4 4 0 00-4-4H8a4 4 0 00-4 4v2"/><circle cx="12" cy="7" r="4"/></svg> CSPaulia</span>
&nbsp;|&nbsp;Translations:<ul class=i18n_list><li><a href=https://cspaulia.github.io/cspaulia-blog/posts/norm/>中文</a></li></ul><span id=busuanzi_container_page_pv>｜ <span id=busuanzi_value_page_pv></span> views</span></div></header><aside id=toc-container class="toc-container wide"><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#layer-normalization aria-label="Layer Normalization">Layer Normalization</a></li></ul></div></details></div></aside><script>let activeElement,elements;window.addEventListener("DOMContentLoaded",function(){checkTocPosition(),elements=document.querySelectorAll("h2[id],h3[id]"),activeElement=elements[0];const t=encodeURI(activeElement.getAttribute("id")).toLowerCase();document.querySelector(`.inner ul li a[href="#${t}"]`).classList.add("active")},!1),window.addEventListener("resize",function(){checkTocPosition()},!1),window.addEventListener("scroll",()=>{activeElement=Array.from(elements).find(e=>{if(getOffsetTop(e)-window.pageYOffset>0&&getOffsetTop(e)-window.pageYOffset<window.innerHeight/2)return e})||activeElement,elements.forEach(e=>{const t=encodeURI(e.getAttribute("id")).toLowerCase();e===activeElement?document.querySelector(`.inner ul li a[href="#${t}"]`).classList.add("active"):document.querySelector(`.inner ul li a[href="#${t}"]`).classList.remove("active")})},!1);const main=parseInt(getComputedStyle(document.body).getPropertyValue("--article-width"),10),toc=parseInt(getComputedStyle(document.body).getPropertyValue("--toc-width"),10),gap=parseInt(getComputedStyle(document.body).getPropertyValue("--gap"),10);function checkTocPosition(){const e=document.body.scrollWidth;e-main-toc*2-gap*4>0?document.getElementById("toc-container").classList.add("wide"):document.getElementById("toc-container").classList.remove("wide")}function getOffsetTop(e){if(!e.getClientRects().length)return 0;let t=e.getBoundingClientRect(),n=e.ownerDocument.defaultView;return t.top+n.pageYOffset}</script><div class=post-content><h3 id=layer-normalization>Layer Normalization<a hidden class=anchor aria-hidden=true href=#layer-normalization>#</a></h3><p align=center><img src=/cspaulia-blog/posts/norm/LNvsBN.jpg alt="LN vs BN" loading=lazy></p><p>In the figure above, $N$ denotes the sample axis, $C$ the channel axis, and $F$ the number of features per channel.
Batch Normalization (BN, right) normalizes using features from <strong>the same channel across different samples</strong>.
Layer Normalization (LN, left) normalizes using features from <strong>different channels within the same sample</strong>.</p><h4 id=1-issues-with-bn>1. Issues with BN<a hidden class=anchor aria-hidden=true href=#1-issues-with-bn>#</a></h4><h5 id=11-bn-and-batch-size>1.1 BN and batch size<a hidden class=anchor aria-hidden=true href=#11-bn-and-batch-size>#</a></h5><p>BN computes normalization statistics based on the <strong>number of samples</strong> in a batch.
When the batch is very small (e.g., only 4 samples), the mean and variance estimated from those samples may not represent the global data distribution well, so BN can perform poorly.</p><h5 id=12-bn-and-rnns>1.2 BN and RNNs<a hidden class=anchor aria-hidden=true href=#12-bn-and-rnns>#</a></h5><p align=center><img src=/cspaulia-blog/posts/norm/RNN.jpg alt=RNN loading=lazy></p><p>Within a batch, sequence lengths often differ.
For later time steps (e.g., $t>4$ in the figure), only a small number of sequences may still have valid tokens.
Statistics computed from so few samples are not representative of the overall distribution, so BN tends to work poorly in this setting.</p><p>Also, at inference time, if we encounter a test sequence longer than any training sequence, we may not have the corresponding saved normalization statistics for those time steps, which makes BN hard to apply.</p><h4 id=2-layernorm-in-detail>2. LayerNorm in detail<a hidden class=anchor aria-hidden=true href=#2-layernorm-in-detail>#</a></h4><h5 id=21-ln-in-an-mlp>2.1 LN in an MLP<a hidden class=anchor aria-hidden=true href=#21-ln-in-an-mlp>#</a></h5><p>Consider LN in an MLP.
Let $H$ be the number of hidden units in a layer, and $l$ be the layer index.
LN computes the normalization statistics $\mu$ and $\sigma$ as:</p><p>$$
\mu^{l} = \frac{1}{H} \sum_{i=1}^{H} a^l_i ~~~~~~~
\sigma^{l} = \sqrt{\frac{1}{H} \sum_{i=1}^{H}(a^l_i-\mu^l)^2}
$$</p><p>Note that these statistics do <strong>not</strong> depend on batch size; they only depend on the number of hidden units.
If $H$ is sufficiently large, the estimated statistics can still be stable.
The normalized activation is:</p><p>$$
\hat{a}^l = \frac{a^l-\mu^l}{\sqrt{(\sigma^l)^2+\epsilon}} \tag{1}
$$</p><p>where $\epsilon$ is a small constant to avoid division by zero.</p><p>LN also uses learnable parameters to preserve representational capacity: gain $g$ and bias $b$.
With activation function $f$, the LN output is:</p><p>$$
h^l = f(g^l \odot \hat{a}^l + b^l) \tag{2}
$$</p><p>Combining (1) and (2) and omitting the layer index $l$:</p><p>$$
h=f(\frac{g}{\sqrt{\sigma^2+\epsilon}} \odot (a-\mu) + b)
$$</p><h5 id=22-ln-in-an-rnn>2.2 LN in an RNN<a hidden class=anchor aria-hidden=true href=#22-ln-in-an-rnn>#</a></h5><p>For an RNN at time step $t$, the input is the previous hidden state $h^t$ at time step $t-1$ and the current input $\text{x}_t$.
It can be written as:</p><p>$$
ext{a}^t = W_{hh}h^{t-1}+W_{xh}\text{x}^{t}
$$</p><p>Then we can apply the same normalization procedure on $\text{a}^t$ as above:</p><p>$$
h^t=f(\frac{g}{\sqrt{\sigma^2+\epsilon}} \odot (a^t-\mu^t) + b) ~~~~~~
\mu^{t} = \frac{1}{H} \sum_{i=1}^{H} a^t_i ~~~~~~~
\sigma^{l} = \sqrt{\frac{1}{H} \sum_{i=1}^{H}(a^t_i-\mu^t)^2}
$$</p></div><br><div><div class=copyright-card><div class=copyright-card-main><div class=copyright-info><h3 class=copyright-title>100 Normalization Methods (Work in Progress)</h3><p class=copyright-link><a href=https://cspaulia.github.io/cspaulia-blog/en/posts/norm/>https://cspaulia.github.io/cspaulia-blog/en/posts/norm/</a></p><div class=copyright-meta><span><strong>Author</strong><br>CSPaulia</span>
<span><strong>Published at</strong><br>May 21, 2025</span>
<span><strong>Copyright</strong><br><a rel=license href=https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh target=_blank>CC BY-NC-SA 4.0</a></span></div></div><div class=copyright-icon>©</div></div></div></div><footer class=post-footer><p style=font-size:medium;margin-bottom:5px;font-weight:700>categories</p><ul class=post-tags><li><a href=https://cspaulia.github.io/cspaulia-blog/en/categories/deep-learning-skills/>Deep Learning Skills</a></li></ul><p style=font-size:medium;margin-bottom:5px;font-weight:700>tags</p><ul class=post-tags><li><a href=https://cspaulia.github.io/cspaulia-blog/en/tags/normalization/>Normalization</a></li></ul><nav class=paginav><a class=prev href=https://cspaulia.github.io/cspaulia-blog/en/posts/cross_attention/><span class=title>« Prev</span><br><span>Cross-Attention Mechanism</span>
</a><a class=next href=https://cspaulia.github.io/cspaulia-blog/en/posts/github-tips/><span class=title>Next »</span><br><span>How to Use Git to Push Local Files to a GitHub Repository</span></a></nav><ul class=share-buttons><li><a target=_blank rel="noopener noreferrer" aria-label="share 100 Normalization Methods (Work in Progress) on x" href="https://x.com/intent/tweet/?text=100%20Normalization%20Methods%20%28Work%20in%20Progress%29&amp;url=https%3a%2f%2fcspaulia.github.io%2fcspaulia-blog%2fen%2fposts%2fnorm%2f&amp;hashtags=Normalization"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share 100 Normalization Methods (Work in Progress) on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fcspaulia.github.io%2fcspaulia-blog%2fen%2fposts%2fnorm%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share 100 Normalization Methods (Work in Progress) on telegram" href="https://telegram.me/share/url?text=100%20Normalization%20Methods%20%28Work%20in%20Progress%29&amp;url=https%3a%2f%2fcspaulia.github.io%2fcspaulia-blog%2fen%2fposts%2fnorm%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentColor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></li></ul></footer></article></main><footer class=footer><span>&copy; 2026 <a href=https://cspaulia.github.io/cspaulia-blog/en/>cspaulia-blog</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>