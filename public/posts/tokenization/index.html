<!doctype html><html lang=en dir=auto><head><script src="/cspaulia-blog/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=cspaulia-blog/livereload" data-no-instant defer></script><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Tokenization | cspaulia-blog</title><meta name=keywords content="Tokenization,LLM"><meta name=description content="Tokenization in LLM"><meta name=author content="CSPaulia"><link rel=canonical href=http://localhost:1313/cspaulia-blog/posts/tokenization/><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/cspaulia-blog/assets/css/stylesheet.7f7470401ba22070365916022e21efedc8961ad7a41f853fa74ec95e1c55c2ea.css integrity="sha256-f3RwQBuiIHA2WRYCLiHv7ciWGtekH4U/p07JXhxVwuo=" rel="preload stylesheet" as=style><link rel=icon href=http://localhost:1313/cspaulia-blog/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=http://localhost:1313/cspaulia-blog/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=http://localhost:1313/cspaulia-blog/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=http://localhost:1313/cspaulia-blog/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=http://localhost:1313/cspaulia-blog/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=http://localhost:1313/cspaulia-blog/posts/tokenization/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js crossorigin=anonymous></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}],throwOnError:!1,trust:!0,strict:!1})})</script><meta property="og:url" content="http://localhost:1313/cspaulia-blog/posts/tokenization/"><meta property="og:site_name" content="cspaulia-blog"><meta property="og:title" content="Tokenization"><meta property="og:description" content="Tokenization in LLM"><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-07-17T10:20:03+08:00"><meta property="article:modified_time" content="2025-07-19T19:49:05+08:00"><meta property="article:tag" content="Tokenization"><meta property="article:tag" content="LLM"><meta property="og:image" content="http://localhost:1313/cspaulia-blog/tokenization_cover.jpg"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="http://localhost:1313/cspaulia-blog/tokenization_cover.jpg"><meta name=twitter:title content="Tokenization"><meta name=twitter:description content="Tokenization in LLM"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"http://localhost:1313/cspaulia-blog/posts/"},{"@type":"ListItem","position":2,"name":"Tokenization","item":"http://localhost:1313/cspaulia-blog/posts/tokenization/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Tokenization","name":"Tokenization","description":"Tokenization in LLM","keywords":["Tokenization","LLM"],"articleBody":"👉 在线体验地址：Tokenization 可视化工具\n原始的文本统一表征为 Unicode 字符串\nstring = \"Hello, 🌍! 你好!\" 语言模型会对一系列token（通常用整数索引表示）上的可能性进行建模，构成一个概率分布\nindices = [15496, 11, 995, 0] 我们需要：\n✅ 一个方法：将字符串编码为 token ✅ 一个方法：将 token 解码回字符串 class Tokenizer: def encode(self, string: str) -\u003e list[int]: ... def decode(self, indices: list[int]) -\u003e str: ... vocab_size: 词表大小，即可能出现的 token（整数 ID）总数。 Character-based tokenization Unicode 概述 统一全球字符编码的标准（约 150,000 个字符） ord(char)：获取字符的十进制编码 ord(\"h\") # 104 ord(\"😊\") # 128522 编解码 class CharacterTokenizer(Tokenizer): \"\"\"Represent a string as a sequence of Unicode code points.\"\"\" def encode(self, string: str) -\u003e list[int]: return list(map(ord, string)) def decode(self, indices: list[int]) -\u003e str: return \"\".join(map(chr, indices)) 示例：\ntokenizer = CharacterTokenizer() string = \"Hello, 🌍! 你好!\" # @inspect string indices = tokenizer.encode(string) # @inspect indices reconstructed_string = tokenizer.decode(indices) # @inspect reconstructed_string 输出：\nstring = \"Hello, 🌍! 你好!\" indices = [72, 101, 108, 108, 111, 44, 32, 127757, 33, 32, 20320, 22909, 33] reconstructed_string = \"Hello, 🌍! 你好!\" 存在的问题 问题一：这会是一个相当大的词汇表（vocabulary）\n问题二：很多字符出现几率很低（例如🌍），对词汇表的使用并不高效\ndef get_compression_ratio(string: str, indices: list[int]) -\u003e float: \"\"\"Given `string` that has been tokenized into `indices`, .\"\"\" num_bytes = len(bytes(string, encoding=\"utf-8\")) # @inspect num_bytes num_tokens = len(indices) # @inspect num_tokens return num_bytes / num_tokens vocabulary_size = max(indices) + 1 # This is a lower bound @inspect vocabulary_size compression_ratio = get_compression_ratio(string, indices) # @inspect compression_ratio 输出：\nvocabulary_size = 127758 num_bytes = 20 num_tokens = 13 compression_ratio = 1.5384615384615385 Byte-based tokenization Unicode 字符串（String）可以表示为一串字节（Byte），其中字节（即八位二进制）可以表示为0到255的数字\n最常见的 Unicode 编码是 UTF-8\n输入：\nbytes(\"a\", encoding=\"utf-8\") bytes(\"🌍\", encoding=\"utf-8\") 输出：\nb\"a\" # one byte b\"\\xf0\\x9f\\x8c\\x8d\"s # multiple bytes 编解码 class ByteTokenizer(Tokenizer): \"\"\"Represent a string as a sequence of bytes.\"\"\" def encode(self, string: str) -\u003e list[int]: string_bytes = string.encode(\"utf-8\") # @inspect string_bytes indices = list(map(int, string_bytes)) # @inspect indices return indices def decode(self, indices: list[int]) -\u003e str: string_bytes = bytes(indices) # @inspect string_bytes string = string_bytes.decode(\"utf-8\") # @inspect string return string 示例：\ntokenizer = ByteTokenizer() string = \"Hello, 🌍! 你好!\" # @inspect string indices = tokenizer.encode(string) # @inspect indices reconstructed_string = tokenizer.decode(indices) # @inspect reconstructed_string 输出：\nstring = \"Hello, 🌍! 你好!\" string_bytes = \"b'Hello, \\\\xf0\\\\x9f\\\\x8c\\\\x8d!\\\\xe4\\\\xbd\\\\xa0\\\\xe5\\\\xa5\\\\xbd'\" indices = [72, 101, 108, 108, 111, 44, 32, 240, 159, 140, 141, 33, 32, 228, 189, 160, 229, 165, 189, 33] reconstructed_string = \"Hello, 🌍! 你好!\" 存在的问题 问题一：虽然词汇表很小（仅为256），但这也导致序列很长。而在 Transformer 中，计算复杂度是随着序列长度二次增长的\nvocabulary_size = 256 # This is a lower bound @inspect vocabulary_size compression_ratio = get_compression_ratio(string, indices) # @inspect compression_ratio 输出：\nnum_bytes = 20 num_tokens = 20 compression_ratio = 1.0 Word-based tokenization 使用类似于传统NLP分词方法分离字符串，输入：\nstring = \"I'll say supercalifragilisticexpialidocious!\" segments = regex.findall(r\"\\w+|.\", string) # @inspect segments 输出：\nsegments = [\"I\", \"ll\", \"say\", \"supercalifragilisticexpialidocious\", \"!\"] 编解码 要将其转换为一个tokenizer，我们需要将这些片段映射为整数 构建一个从每个片段到整数的映射 存在的问题 词的数量是非常庞大的 很多词很少出现，模型不会从这些词中学习到很多内容 它无法提供一个固定长度的词典 Byte Pair Encoding（BPE） 主要思想：在原始文本上训练tokenizer，自发的生成词汇表\n意图：对于常见的字符序列，可以仅用一个token表示；对于不常见的字符序列，则用多个token表示\n算法简述：首先将每一个byte看作是一个token，随后逐渐合并常出现的相邻token为一个新token\n算法流程 def merge(indices: list[int], pair: tuple[int, int], new_index: int) -\u003e list[int]: # @inspect indices, @inspect pair, @inspect new_index \"\"\"Return `indices`, but with all instances of `pair` replaced with `new_index`.\"\"\" new_indices = [] # @inspect new_indices i = 0 # @inspect i while i \u003c len(indices): if i + 1 \u003c len(indices) and indices[i] == pair[0] and indices[i + 1] == pair[1]: new_indices.append(new_index) i += 2 else: new_indices.append(indices[i]) i += 1 return new_indices BPE 编码器 class BPETokenizer(Tokenizer): \"\"\"BPE tokenizer given a set of merges and a vocabulary.\"\"\" def __init__(self, params: BPETokenizerParams): self.params = params def encode(self, string: str) -\u003e list[int]: indices = list(map(int, string.encode(\"utf-8\"))) # @inspect indices # Note: this is a very slow implementation for pair, new_index in self.params.merges.items(): # @inspect pair, @inspect new_index indices = merge(indices, pair, new_index) return indices def decode(self, indices: list[int]) -\u003e str: bytes_list = list(map(self.params.vocab.get, indices)) # @inspect bytes_list string = b\"\".join(bytes_list).decode(\"utf-8\") # @inspect string return string 训练 BPE def train_bpe(string: str, num_merges: int) -\u003e BPETokenizerParams: # @inspect string, @inspect num_merges # Start with the list of bytes of string. indices = list(map(int, string.encode(\"utf-8\"))) # @inspect indices merges: dict[tuple[int, int], int] = {} # index1, index2 =\u003e merged index vocab: dict[int, bytes] = {x: bytes([x]) for x in range(256)} # index -\u003e bytes for i in range(num_merges): # Count the number of occurrences of each pair of tokens counts = defaultdict(int) for index1, index2 in zip(indices, indices[1:]): # For each adjacent pair counts[(index1, index2)] += 1 # @inspect counts # Find the most common pair. pair = max(counts, key=counts.get) # @inspect pair index1, index2 = pair # Merge that pair. new_index = 256 + i # @inspect new_index merges[pair] = new_index # @inspect merges vocab[new_index] = vocab[index1] + vocab[index2] # @inspect vocab indices = merge(indices, pair, new_index) # @inspect indices return BPETokenizerParams(vocab=vocab, merges=merges) 示例:\ntext = \"the cat in the hat\" # @inspect string params = train_bpe(text, num_merges=3) string = \"the quick brown fox\" # @inspect string tokenizer = BPETokenizer(params) indices = tokenizer.encode(string) # @inspect indices reconstructed_string = tokenizer.decode(indices) # @inspect reconstructed_string 代码逻辑为：\n初始化词汇表，用0-255表征byte 依次寻找最多次出现的相邻byte (116, 104) –\u003e 256 即 (’t’, ‘h’) –\u003e ’th’ (256, 101) –\u003e 257 即 (’th’, ’e’) –\u003e ’the' (257, 32) –\u003e 258 即 （’the’, ’ ‘）–\u003e ’the ' 词汇表长度更新至259 用新词汇表对字符串进行编码 ","wordCount":"783","inLanguage":"en","image":"http://localhost:1313/cspaulia-blog/tokenization_cover.jpg","datePublished":"2025-07-17T10:20:03+08:00","dateModified":"2025-07-19T19:49:05+08:00","author":{"@type":"Person","name":"CSPaulia"},"mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:1313/cspaulia-blog/posts/tokenization/"},"publisher":{"@type":"Organization","name":"cspaulia-blog","logo":{"@type":"ImageObject","url":"http://localhost:1313/cspaulia-blog/%3Clink%20/%20abs%20url%3E"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=http://localhost:1313/cspaulia-blog/ accesskey=h title="Home (Alt + H)"><img src=http://localhost:1313/apple-touch-icon.png alt aria-label=logo height=35>Home</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=http://localhost:1313/cspaulia-blog/posts/ title=posts><span>posts</span></a></li><li><a href=http://localhost:1313/cspaulia-blog/categories/ title=categories><span>categories</span></a></li><li><a href=http://localhost:1313/cspaulia-blog/series/ title=series><span>series</span></a></li><li><a href=http://localhost:1313/cspaulia-blog/tags/ title=tags><span>tags</span></a></li><li><a href=http://localhost:1313/cspaulia-blog/archives/ title=archives><span>archives</span></a></li><li><a href=http://localhost:1313/cspaulia-blog/search/ title="search (Alt + /)" accesskey=/><span>search</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=http://localhost:1313/cspaulia-blog/>Home</a>&nbsp;»&nbsp;<a href=http://localhost:1313/cspaulia-blog/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">Tokenization</h1><div class=post-description>Tokenization in LLM</div><div class=post-meta><span class=post-meta-item><svg width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><rect x="3" y="4" width="18" height="18" rx="2" ry="2"/><line x1="16" y1="2" x2="16" y2="6"/><line x1="8" y1="2" x2="8" y2="6"/><line x1="3" y1="10" x2="21" y2="10"/></svg> July 17, 2025</span> ｜ <span class=post-meta-item><svg width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M12 19l7-7 3 3-7 7-3-3z"/><path d="M18 13l-1.5-7.5L2 2l3.5 14.5L13 18l5-5z"/><path d="M2 2l7.586 7.586"/><circle cx="11" cy="11" r="2"/></svg> July 19, 2025</span> ｜ <span class=post-meta-item><svg width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M14 2H6A2 2 0 004 4v16a2 2 0 002 2h12a2 2 0 002-2V8z"/><path d="M14 2v6h6"/><line x1="8" y1="13" x2="16" y2="13"/><line x1="8" y1="17" x2="16" y2="17"/><line x1="8" y1="9" x2="12" y2="9"/></svg> 783 words</span> ｜ <span class=post-meta-item><svg width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="10"/><polyline points="12 6 12 12 16 14"/></svg> 4 min</span> ｜ <span class=post-meta-item><svg width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M20 21v-2a4 4 0 00-4-4H8a4 4 0 00-4 4v2"/><circle cx="12" cy="7" r="4"/></svg> CSPaulia</span>
&nbsp;|&nbsp;<a href=https://cspaulia.github.io/cspaulia-blog/content//posts/tokenization/index.md rel="noopener noreferrer edit" target=_blank>Suggest Changes</a></div></header><aside id=toc-container class="toc-container wide"><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#character-based-tokenization aria-label="Character-based tokenization">Character-based tokenization</a><ul><li><a href=#unicode-%e6%a6%82%e8%bf%b0 aria-label="Unicode 概述">Unicode 概述</a></li><li><a href=#%e7%bc%96%e8%a7%a3%e7%a0%81 aria-label=编解码>编解码</a></li><li><a href=#%e5%ad%98%e5%9c%a8%e7%9a%84%e9%97%ae%e9%a2%98 aria-label=存在的问题>存在的问题</a></li></ul></li><li><a href=#byte-based-tokenization aria-label="Byte-based tokenization">Byte-based tokenization</a><ul><li><a href=#%e7%bc%96%e8%a7%a3%e7%a0%81-1 aria-label=编解码>编解码</a></li><li><a href=#%e5%ad%98%e5%9c%a8%e7%9a%84%e9%97%ae%e9%a2%98-1 aria-label=存在的问题>存在的问题</a></li></ul></li><li><a href=#word-based-tokenization aria-label="Word-based tokenization">Word-based tokenization</a><ul><li><a href=#%e7%bc%96%e8%a7%a3%e7%a0%81-2 aria-label=编解码>编解码</a></li><li><a href=#%e5%ad%98%e5%9c%a8%e7%9a%84%e9%97%ae%e9%a2%98-2 aria-label=存在的问题>存在的问题</a></li></ul></li><li><a href=#byte-pair-encodingbpe aria-label="Byte Pair Encoding（BPE）">Byte Pair Encoding（BPE）</a><ul><li><a href=#%e7%ae%97%e6%b3%95%e6%b5%81%e7%a8%8b aria-label=算法流程>算法流程</a></li><li><a href=#bpe-%e7%bc%96%e7%a0%81%e5%99%a8 aria-label="BPE 编码器">BPE 编码器</a></li><li><a href=#%e8%ae%ad%e7%bb%83-bpe aria-label="训练 BPE">训练 BPE</a></li></ul></li></ul></div></details></div></aside><script>let activeElement,elements;window.addEventListener("DOMContentLoaded",function(){checkTocPosition(),elements=document.querySelectorAll("h2[id],h3[id]"),activeElement=elements[0];const t=encodeURI(activeElement.getAttribute("id")).toLowerCase();document.querySelector(`.inner ul li a[href="#${t}"]`).classList.add("active")},!1),window.addEventListener("resize",function(){checkTocPosition()},!1),window.addEventListener("scroll",()=>{activeElement=Array.from(elements).find(e=>{if(getOffsetTop(e)-window.pageYOffset>0&&getOffsetTop(e)-window.pageYOffset<window.innerHeight/2)return e})||activeElement,elements.forEach(e=>{const t=encodeURI(e.getAttribute("id")).toLowerCase();e===activeElement?document.querySelector(`.inner ul li a[href="#${t}"]`).classList.add("active"):document.querySelector(`.inner ul li a[href="#${t}"]`).classList.remove("active")})},!1);const main=parseInt(getComputedStyle(document.body).getPropertyValue("--article-width"),10),toc=parseInt(getComputedStyle(document.body).getPropertyValue("--toc-width"),10),gap=parseInt(getComputedStyle(document.body).getPropertyValue("--gap"),10);function checkTocPosition(){const e=document.body.scrollWidth;e-main-toc*2-gap*4>0?document.getElementById("toc-container").classList.add("wide"):document.getElementById("toc-container").classList.remove("wide")}function getOffsetTop(e){if(!e.getClientRects().length)return 0;let t=e.getBoundingClientRect(),n=e.ownerDocument.defaultView;return t.top+n.pageYOffset}</script><div class=post-content><p>👉 在线体验地址：<a href=https://tiktokenizer.vercel.app>Tokenization 可视化工具</a></p><hr><p>原始的文本统一表征为 Unicode 字符串</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>string</span> <span class=o>=</span> <span class=s2>&#34;Hello, 🌍! 你好!&#34;</span>
</span></span></code></pre></div><p>语言模型会对一系列token（通常用整数索引表示）上的可能性进行建模，构成一个概率分布</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>indices</span> <span class=o>=</span> <span class=p>[</span><span class=mi>15496</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>995</span><span class=p>,</span> <span class=mi>0</span><span class=p>]</span>
</span></span></code></pre></div><p>我们需要：</p><ul><li>✅ 一个方法：<strong>将字符串编码为 token</strong></li><li>✅ 一个方法：<strong>将 token 解码回字符串</strong></li></ul><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>class</span> <span class=nc>Tokenizer</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>encode</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>string</span><span class=p>:</span> <span class=nb>str</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=nb>list</span><span class=p>[</span><span class=nb>int</span><span class=p>]:</span>
</span></span><span class=line><span class=cl>        <span class=o>...</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>decode</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>indices</span><span class=p>:</span> <span class=nb>list</span><span class=p>[</span><span class=nb>int</span><span class=p>])</span> <span class=o>-&gt;</span> <span class=nb>str</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=o>...</span>
</span></span></code></pre></div><ul><li><code>vocab_size</code>: 词表大小，即可能出现的 token（整数 ID）总数。</li></ul><hr><h2 id=character-based-tokenization>Character-based tokenization<a hidden class=anchor aria-hidden=true href=#character-based-tokenization>#</a></h2><h3 id=unicode-概述>Unicode 概述<a hidden class=anchor aria-hidden=true href=#unicode-概述>#</a></h3><ul><li>统一全球字符编码的标准（约 150,000 个字符）</li><li><code>ord(char)</code>：获取字符的十进制编码</li></ul><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=nb>ord</span><span class=p>(</span><span class=s2>&#34;h&#34;</span><span class=p>)</span>     <span class=c1># 104</span>
</span></span><span class=line><span class=cl><span class=nb>ord</span><span class=p>(</span><span class=s2>&#34;😊&#34;</span><span class=p>)</span>    <span class=c1># 128522</span>
</span></span></code></pre></div><h3 id=编解码>编解码<a hidden class=anchor aria-hidden=true href=#编解码>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>class</span> <span class=nc>CharacterTokenizer</span><span class=p>(</span><span class=n>Tokenizer</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;Represent a string as a sequence of Unicode code points.&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>encode</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>string</span><span class=p>:</span> <span class=nb>str</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=nb>list</span><span class=p>[</span><span class=nb>int</span><span class=p>]:</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=nb>list</span><span class=p>(</span><span class=nb>map</span><span class=p>(</span><span class=nb>ord</span><span class=p>,</span> <span class=n>string</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>decode</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>indices</span><span class=p>:</span> <span class=nb>list</span><span class=p>[</span><span class=nb>int</span><span class=p>])</span> <span class=o>-&gt;</span> <span class=nb>str</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=s2>&#34;&#34;</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=nb>map</span><span class=p>(</span><span class=nb>chr</span><span class=p>,</span> <span class=n>indices</span><span class=p>))</span>
</span></span></code></pre></div><p><strong>示例</strong>：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>tokenizer</span> <span class=o>=</span> <span class=n>CharacterTokenizer</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>string</span> <span class=o>=</span> <span class=s2>&#34;Hello, 🌍! 你好!&#34;</span>  <span class=c1># @inspect string</span>
</span></span><span class=line><span class=cl><span class=n>indices</span> <span class=o>=</span> <span class=n>tokenizer</span><span class=o>.</span><span class=n>encode</span><span class=p>(</span><span class=n>string</span><span class=p>)</span>  <span class=c1># @inspect indices</span>
</span></span><span class=line><span class=cl><span class=n>reconstructed_string</span> <span class=o>=</span> <span class=n>tokenizer</span><span class=o>.</span><span class=n>decode</span><span class=p>(</span><span class=n>indices</span><span class=p>)</span>  <span class=c1># @inspect reconstructed_string</span>
</span></span></code></pre></div><p><strong>输出</strong>：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-text data-lang=text><span class=line><span class=cl>string = &#34;Hello, 🌍! 你好!&#34;
</span></span><span class=line><span class=cl>indices = [72, 101, 108, 108, 111, 44, 32, 127757, 33, 32, 20320, 22909, 33]
</span></span><span class=line><span class=cl>reconstructed_string = &#34;Hello, 🌍! 你好!&#34;
</span></span></code></pre></div><h3 id=存在的问题>存在的问题<a hidden class=anchor aria-hidden=true href=#存在的问题>#</a></h3><ul><li><p>问题一：这会是一个相当大的词汇表（vocabulary）</p></li><li><p>问题二：很多字符出现几率很低（例如🌍），对词汇表的使用并不高效</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>get_compression_ratio</span><span class=p>(</span><span class=n>string</span><span class=p>:</span> <span class=nb>str</span><span class=p>,</span> <span class=n>indices</span><span class=p>:</span> <span class=nb>list</span><span class=p>[</span><span class=nb>int</span><span class=p>])</span> <span class=o>-&gt;</span> <span class=nb>float</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;Given `string` that has been tokenized into `indices`, .&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>num_bytes</span> <span class=o>=</span> <span class=nb>len</span><span class=p>(</span><span class=nb>bytes</span><span class=p>(</span><span class=n>string</span><span class=p>,</span> <span class=n>encoding</span><span class=o>=</span><span class=s2>&#34;utf-8&#34;</span><span class=p>))</span>  <span class=c1># @inspect num_bytes</span>
</span></span><span class=line><span class=cl>    <span class=n>num_tokens</span> <span class=o>=</span> <span class=nb>len</span><span class=p>(</span><span class=n>indices</span><span class=p>)</span>                       <span class=c1># @inspect num_tokens</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>num_bytes</span> <span class=o>/</span> <span class=n>num_tokens</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>vocabulary_size</span> <span class=o>=</span> <span class=nb>max</span><span class=p>(</span><span class=n>indices</span><span class=p>)</span> <span class=o>+</span> <span class=mi>1</span>  <span class=c1># This is a lower bound @inspect vocabulary_size</span>
</span></span><span class=line><span class=cl><span class=n>compression_ratio</span> <span class=o>=</span> <span class=n>get_compression_ratio</span><span class=p>(</span><span class=n>string</span><span class=p>,</span> <span class=n>indices</span><span class=p>)</span>  <span class=c1># @inspect compression_ratio</span>
</span></span></code></pre></div><p><strong>输出</strong>：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-text data-lang=text><span class=line><span class=cl>vocabulary_size = 127758
</span></span><span class=line><span class=cl>num_bytes = 20
</span></span><span class=line><span class=cl>num_tokens = 13
</span></span><span class=line><span class=cl>compression_ratio = 1.5384615384615385
</span></span></code></pre></div></li></ul><hr><h2 id=byte-based-tokenization>Byte-based tokenization<a hidden class=anchor aria-hidden=true href=#byte-based-tokenization>#</a></h2><ul><li><p>Unicode 字符串（String）可以表示为一串字节（Byte），其中字节（即八位二进制）可以表示为0到255的数字</p></li><li><p>最常见的 Unicode 编码是 UTF-8</p><p><strong>输入</strong>：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=nb>bytes</span><span class=p>(</span><span class=s2>&#34;a&#34;</span><span class=p>,</span> <span class=n>encoding</span><span class=o>=</span><span class=s2>&#34;utf-8&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>bytes</span><span class=p>(</span><span class=s2>&#34;🌍&#34;</span><span class=p>,</span> <span class=n>encoding</span><span class=o>=</span><span class=s2>&#34;utf-8&#34;</span><span class=p>)</span>
</span></span></code></pre></div><p><strong>输出</strong>：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-text data-lang=text><span class=line><span class=cl>b&#34;a&#34; # one byte
</span></span><span class=line><span class=cl>b&#34;\xf0\x9f\x8c\x8d&#34;s # multiple bytes
</span></span></code></pre></div></li></ul><h3 id=编解码-1>编解码<a hidden class=anchor aria-hidden=true href=#编解码-1>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>class</span> <span class=nc>ByteTokenizer</span><span class=p>(</span><span class=n>Tokenizer</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;Represent a string as a sequence of bytes.&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>encode</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>string</span><span class=p>:</span> <span class=nb>str</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=nb>list</span><span class=p>[</span><span class=nb>int</span><span class=p>]:</span>
</span></span><span class=line><span class=cl>        <span class=n>string_bytes</span> <span class=o>=</span> <span class=n>string</span><span class=o>.</span><span class=n>encode</span><span class=p>(</span><span class=s2>&#34;utf-8&#34;</span><span class=p>)</span>  <span class=c1># @inspect string_bytes</span>
</span></span><span class=line><span class=cl>        <span class=n>indices</span> <span class=o>=</span> <span class=nb>list</span><span class=p>(</span><span class=nb>map</span><span class=p>(</span><span class=nb>int</span><span class=p>,</span> <span class=n>string_bytes</span><span class=p>))</span>  <span class=c1># @inspect indices</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>indices</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>decode</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>indices</span><span class=p>:</span> <span class=nb>list</span><span class=p>[</span><span class=nb>int</span><span class=p>])</span> <span class=o>-&gt;</span> <span class=nb>str</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>string_bytes</span> <span class=o>=</span> <span class=nb>bytes</span><span class=p>(</span><span class=n>indices</span><span class=p>)</span>  <span class=c1># @inspect string_bytes</span>
</span></span><span class=line><span class=cl>        <span class=n>string</span> <span class=o>=</span> <span class=n>string_bytes</span><span class=o>.</span><span class=n>decode</span><span class=p>(</span><span class=s2>&#34;utf-8&#34;</span><span class=p>)</span>  <span class=c1># @inspect string</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>string</span>
</span></span></code></pre></div><p><strong>示例</strong>：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>tokenizer</span> <span class=o>=</span> <span class=n>ByteTokenizer</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>string</span> <span class=o>=</span> <span class=s2>&#34;Hello, 🌍! 你好!&#34;</span>  <span class=c1># @inspect string</span>
</span></span><span class=line><span class=cl><span class=n>indices</span> <span class=o>=</span> <span class=n>tokenizer</span><span class=o>.</span><span class=n>encode</span><span class=p>(</span><span class=n>string</span><span class=p>)</span>  <span class=c1># @inspect indices</span>
</span></span><span class=line><span class=cl><span class=n>reconstructed_string</span> <span class=o>=</span> <span class=n>tokenizer</span><span class=o>.</span><span class=n>decode</span><span class=p>(</span><span class=n>indices</span><span class=p>)</span>  <span class=c1># @inspect reconstructed_string</span>
</span></span></code></pre></div><p><strong>输出</strong>：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-text data-lang=text><span class=line><span class=cl>string = &#34;Hello, 🌍! 你好!&#34;
</span></span><span class=line><span class=cl>string_bytes = &#34;b&#39;Hello, \\xf0\\x9f\\x8c\\x8d!\\xe4\\xbd\\xa0\\xe5\\xa5\\xbd&#39;&#34;
</span></span><span class=line><span class=cl>indices = [72, 101, 108, 108, 111, 44, 32, 240, 159, 140, 141, 33, 32, 228, 189, 160, 229, 165, 189, 33]
</span></span><span class=line><span class=cl>reconstructed_string = &#34;Hello, 🌍! 你好!&#34;
</span></span></code></pre></div><h3 id=存在的问题-1>存在的问题<a hidden class=anchor aria-hidden=true href=#存在的问题-1>#</a></h3><ul><li><p>问题一：虽然词汇表很小（仅为256），但这也导致序列很长。而在 Transformer 中，计算复杂度是随着序列长度<strong>二次增长</strong>的</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>vocabulary_size</span> <span class=o>=</span> <span class=mi>256</span>  <span class=c1># This is a lower bound @inspect vocabulary_size</span>
</span></span><span class=line><span class=cl><span class=n>compression_ratio</span> <span class=o>=</span> <span class=n>get_compression_ratio</span><span class=p>(</span><span class=n>string</span><span class=p>,</span> <span class=n>indices</span><span class=p>)</span>  <span class=c1># @inspect compression_ratio</span>
</span></span></code></pre></div><p><strong>输出</strong>：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-text data-lang=text><span class=line><span class=cl>num_bytes = 20
</span></span><span class=line><span class=cl>num_tokens = 20
</span></span><span class=line><span class=cl>compression_ratio = 1.0
</span></span></code></pre></div></li></ul><hr><h2 id=word-based-tokenization>Word-based tokenization<a hidden class=anchor aria-hidden=true href=#word-based-tokenization>#</a></h2><p>使用类似于传统NLP分词方法分离字符串，<strong>输入</strong>：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>string</span> <span class=o>=</span> <span class=s2>&#34;I&#39;ll say supercalifragilisticexpialidocious!&#34;</span>
</span></span><span class=line><span class=cl><span class=n>segments</span> <span class=o>=</span> <span class=n>regex</span><span class=o>.</span><span class=n>findall</span><span class=p>(</span><span class=sa>r</span><span class=s2>&#34;\w+|.&#34;</span><span class=p>,</span> <span class=n>string</span><span class=p>)</span>  <span class=c1># @inspect segments</span>
</span></span></code></pre></div><p><strong>输出</strong>：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-text data-lang=text><span class=line><span class=cl>segments = [&#34;I&#34;, &#34;ll&#34;, &#34;say&#34;, &#34;supercalifragilisticexpialidocious&#34;, &#34;!&#34;]
</span></span></code></pre></div><h3 id=编解码-2>编解码<a hidden class=anchor aria-hidden=true href=#编解码-2>#</a></h3><ul><li>要将其转换为一个<code>tokenizer</code>，我们需要将这些片段映射为整数</li><li>构建一个从每个片段到整数的映射</li></ul><h3 id=存在的问题-2>存在的问题<a hidden class=anchor aria-hidden=true href=#存在的问题-2>#</a></h3><ul><li>词的数量是非常庞大的</li><li>很多词很少出现，模型不会从这些词中学习到很多内容</li><li>它无法提供一个固定长度的词典</li></ul><hr><h2 id=byte-pair-encodingbpe>Byte Pair Encoding（BPE）<a hidden class=anchor aria-hidden=true href=#byte-pair-encodingbpe>#</a></h2><p><strong>主要思想</strong>：在原始文本上训练<code>tokenizer</code>，自发的生成词汇表</p><p><strong>意图</strong>：对于常见的字符序列，可以仅用一个token表示；对于不常见的字符序列，则用多个token表示</p><p><strong>算法简述</strong>：首先将每一个<strong>byte</strong>看作是一个token，随后逐渐合并常出现的相邻token为一个新token</p><h3 id=算法流程>算法流程<a hidden class=anchor aria-hidden=true href=#算法流程>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>merge</span><span class=p>(</span><span class=n>indices</span><span class=p>:</span> <span class=nb>list</span><span class=p>[</span><span class=nb>int</span><span class=p>],</span> <span class=n>pair</span><span class=p>:</span> <span class=nb>tuple</span><span class=p>[</span><span class=nb>int</span><span class=p>,</span> <span class=nb>int</span><span class=p>],</span> <span class=n>new_index</span><span class=p>:</span> <span class=nb>int</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=nb>list</span><span class=p>[</span><span class=nb>int</span><span class=p>]:</span>  <span class=c1># @inspect indices, @inspect pair, @inspect new_index</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;Return `indices`, but with all instances of `pair` replaced with `new_index`.&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>new_indices</span> <span class=o>=</span> <span class=p>[]</span>  <span class=c1># @inspect new_indices</span>
</span></span><span class=line><span class=cl>    <span class=n>i</span> <span class=o>=</span> <span class=mi>0</span>  <span class=c1># @inspect i</span>
</span></span><span class=line><span class=cl>    <span class=k>while</span> <span class=n>i</span> <span class=o>&lt;</span> <span class=nb>len</span><span class=p>(</span><span class=n>indices</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=n>i</span> <span class=o>+</span> <span class=mi>1</span> <span class=o>&lt;</span> <span class=nb>len</span><span class=p>(</span><span class=n>indices</span><span class=p>)</span> <span class=ow>and</span> <span class=n>indices</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>==</span> <span class=n>pair</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span> <span class=ow>and</span> <span class=n>indices</span><span class=p>[</span><span class=n>i</span> <span class=o>+</span> <span class=mi>1</span><span class=p>]</span> <span class=o>==</span> <span class=n>pair</span><span class=p>[</span><span class=mi>1</span><span class=p>]:</span>
</span></span><span class=line><span class=cl>            <span class=n>new_indices</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>new_index</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>i</span> <span class=o>+=</span> <span class=mi>2</span>
</span></span><span class=line><span class=cl>        <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>new_indices</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>indices</span><span class=p>[</span><span class=n>i</span><span class=p>])</span>
</span></span><span class=line><span class=cl>            <span class=n>i</span> <span class=o>+=</span> <span class=mi>1</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>new_indices</span>
</span></span></code></pre></div><h3 id=bpe-编码器>BPE 编码器<a hidden class=anchor aria-hidden=true href=#bpe-编码器>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>class</span> <span class=nc>BPETokenizer</span><span class=p>(</span><span class=n>Tokenizer</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;BPE tokenizer given a set of merges and a vocabulary.&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>params</span><span class=p>:</span> <span class=n>BPETokenizerParams</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>params</span> <span class=o>=</span> <span class=n>params</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>encode</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>string</span><span class=p>:</span> <span class=nb>str</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=nb>list</span><span class=p>[</span><span class=nb>int</span><span class=p>]:</span>
</span></span><span class=line><span class=cl>        <span class=n>indices</span> <span class=o>=</span> <span class=nb>list</span><span class=p>(</span><span class=nb>map</span><span class=p>(</span><span class=nb>int</span><span class=p>,</span> <span class=n>string</span><span class=o>.</span><span class=n>encode</span><span class=p>(</span><span class=s2>&#34;utf-8&#34;</span><span class=p>)))</span>  <span class=c1># @inspect indices</span>
</span></span><span class=line><span class=cl>        <span class=c1># Note: this is a very slow implementation</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>pair</span><span class=p>,</span> <span class=n>new_index</span> <span class=ow>in</span> <span class=bp>self</span><span class=o>.</span><span class=n>params</span><span class=o>.</span><span class=n>merges</span><span class=o>.</span><span class=n>items</span><span class=p>():</span>  <span class=c1># @inspect pair, @inspect new_index</span>
</span></span><span class=line><span class=cl>            <span class=n>indices</span> <span class=o>=</span> <span class=n>merge</span><span class=p>(</span><span class=n>indices</span><span class=p>,</span> <span class=n>pair</span><span class=p>,</span> <span class=n>new_index</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>indices</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>decode</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>indices</span><span class=p>:</span> <span class=nb>list</span><span class=p>[</span><span class=nb>int</span><span class=p>])</span> <span class=o>-&gt;</span> <span class=nb>str</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>bytes_list</span> <span class=o>=</span> <span class=nb>list</span><span class=p>(</span><span class=nb>map</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>params</span><span class=o>.</span><span class=n>vocab</span><span class=o>.</span><span class=n>get</span><span class=p>,</span> <span class=n>indices</span><span class=p>))</span>  <span class=c1># @inspect bytes_list</span>
</span></span><span class=line><span class=cl>        <span class=n>string</span> <span class=o>=</span> <span class=sa>b</span><span class=s2>&#34;&#34;</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=n>bytes_list</span><span class=p>)</span><span class=o>.</span><span class=n>decode</span><span class=p>(</span><span class=s2>&#34;utf-8&#34;</span><span class=p>)</span>  <span class=c1># @inspect string</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>string</span>
</span></span></code></pre></div><h3 id=训练-bpe>训练 BPE<a hidden class=anchor aria-hidden=true href=#训练-bpe>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>train_bpe</span><span class=p>(</span><span class=n>string</span><span class=p>:</span> <span class=nb>str</span><span class=p>,</span> <span class=n>num_merges</span><span class=p>:</span> <span class=nb>int</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>BPETokenizerParams</span><span class=p>:</span>  <span class=c1># @inspect string, @inspect num_merges</span>
</span></span><span class=line><span class=cl>    <span class=c1># Start with the list of bytes of string.</span>
</span></span><span class=line><span class=cl>    <span class=n>indices</span> <span class=o>=</span> <span class=nb>list</span><span class=p>(</span><span class=nb>map</span><span class=p>(</span><span class=nb>int</span><span class=p>,</span> <span class=n>string</span><span class=o>.</span><span class=n>encode</span><span class=p>(</span><span class=s2>&#34;utf-8&#34;</span><span class=p>)))</span>  <span class=c1># @inspect indices</span>
</span></span><span class=line><span class=cl>    <span class=n>merges</span><span class=p>:</span> <span class=nb>dict</span><span class=p>[</span><span class=nb>tuple</span><span class=p>[</span><span class=nb>int</span><span class=p>,</span> <span class=nb>int</span><span class=p>],</span> <span class=nb>int</span><span class=p>]</span> <span class=o>=</span> <span class=p>{}</span>  <span class=c1># index1, index2 =&gt; merged index</span>
</span></span><span class=line><span class=cl>    <span class=n>vocab</span><span class=p>:</span> <span class=nb>dict</span><span class=p>[</span><span class=nb>int</span><span class=p>,</span> <span class=nb>bytes</span><span class=p>]</span> <span class=o>=</span> <span class=p>{</span><span class=n>x</span><span class=p>:</span> <span class=nb>bytes</span><span class=p>([</span><span class=n>x</span><span class=p>])</span> <span class=k>for</span> <span class=n>x</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>256</span><span class=p>)}</span>  <span class=c1># index -&gt; bytes</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>num_merges</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=c1># Count the number of occurrences of each pair of tokens</span>
</span></span><span class=line><span class=cl>        <span class=n>counts</span> <span class=o>=</span> <span class=n>defaultdict</span><span class=p>(</span><span class=nb>int</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>index1</span><span class=p>,</span> <span class=n>index2</span> <span class=ow>in</span> <span class=nb>zip</span><span class=p>(</span><span class=n>indices</span><span class=p>,</span> <span class=n>indices</span><span class=p>[</span><span class=mi>1</span><span class=p>:]):</span>  <span class=c1># For each adjacent pair</span>
</span></span><span class=line><span class=cl>            <span class=n>counts</span><span class=p>[(</span><span class=n>index1</span><span class=p>,</span> <span class=n>index2</span><span class=p>)]</span> <span class=o>+=</span> <span class=mi>1</span>  <span class=c1># @inspect counts</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># Find the most common pair.</span>
</span></span><span class=line><span class=cl>        <span class=n>pair</span> <span class=o>=</span> <span class=nb>max</span><span class=p>(</span><span class=n>counts</span><span class=p>,</span> <span class=n>key</span><span class=o>=</span><span class=n>counts</span><span class=o>.</span><span class=n>get</span><span class=p>)</span>  <span class=c1># @inspect pair</span>
</span></span><span class=line><span class=cl>        <span class=n>index1</span><span class=p>,</span> <span class=n>index2</span> <span class=o>=</span> <span class=n>pair</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># Merge that pair.</span>
</span></span><span class=line><span class=cl>        <span class=n>new_index</span> <span class=o>=</span> <span class=mi>256</span> <span class=o>+</span> <span class=n>i</span>  <span class=c1># @inspect new_index</span>
</span></span><span class=line><span class=cl>        <span class=n>merges</span><span class=p>[</span><span class=n>pair</span><span class=p>]</span> <span class=o>=</span> <span class=n>new_index</span>  <span class=c1># @inspect merges</span>
</span></span><span class=line><span class=cl>        <span class=n>vocab</span><span class=p>[</span><span class=n>new_index</span><span class=p>]</span> <span class=o>=</span> <span class=n>vocab</span><span class=p>[</span><span class=n>index1</span><span class=p>]</span> <span class=o>+</span> <span class=n>vocab</span><span class=p>[</span><span class=n>index2</span><span class=p>]</span>  <span class=c1># @inspect vocab</span>
</span></span><span class=line><span class=cl>        <span class=n>indices</span> <span class=o>=</span> <span class=n>merge</span><span class=p>(</span><span class=n>indices</span><span class=p>,</span> <span class=n>pair</span><span class=p>,</span> <span class=n>new_index</span><span class=p>)</span>  <span class=c1># @inspect indices</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>BPETokenizerParams</span><span class=p>(</span><span class=n>vocab</span><span class=o>=</span><span class=n>vocab</span><span class=p>,</span> <span class=n>merges</span><span class=o>=</span><span class=n>merges</span><span class=p>)</span>
</span></span></code></pre></div><p><strong>示例</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>text</span> <span class=o>=</span> <span class=s2>&#34;the cat in the hat&#34;</span>  <span class=c1># @inspect string</span>
</span></span><span class=line><span class=cl><span class=n>params</span> <span class=o>=</span> <span class=n>train_bpe</span><span class=p>(</span><span class=n>text</span><span class=p>,</span> <span class=n>num_merges</span><span class=o>=</span><span class=mi>3</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>string</span> <span class=o>=</span> <span class=s2>&#34;the quick brown fox&#34;</span>  <span class=c1># @inspect string</span>
</span></span><span class=line><span class=cl><span class=n>tokenizer</span> <span class=o>=</span> <span class=n>BPETokenizer</span><span class=p>(</span><span class=n>params</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>indices</span> <span class=o>=</span> <span class=n>tokenizer</span><span class=o>.</span><span class=n>encode</span><span class=p>(</span><span class=n>string</span><span class=p>)</span>  <span class=c1># @inspect indices</span>
</span></span><span class=line><span class=cl><span class=n>reconstructed_string</span> <span class=o>=</span> <span class=n>tokenizer</span><span class=o>.</span><span class=n>decode</span><span class=p>(</span><span class=n>indices</span><span class=p>)</span>  <span class=c1># @inspect reconstructed_string</span>
</span></span></code></pre></div><p>代码逻辑为：</p><ol><li>初始化词汇表，用0-255表征byte</li><li>依次寻找最多次出现的相邻byte<ul><li>(116, 104) &ndash;> 256 即 (&rsquo;t&rsquo;, &lsquo;h&rsquo;) &ndash;> &rsquo;th&rsquo;</li><li>(256, 101) &ndash;> 257 即 (&rsquo;th&rsquo;, &rsquo;e&rsquo;) &ndash;> &rsquo;the'</li><li>(257, 32) &ndash;> 258 即 （&rsquo;the&rsquo;, &rsquo; &lsquo;）&ndash;> &rsquo;the '</li></ul></li><li>词汇表长度更新至259</li><li>用新词汇表对字符串进行编码</li></ol></div><footer class=post-footer><p style=font-size:medium;margin-bottom:5px;font-weight:700>categories</p><ul class=post-tags><li><a href=http://localhost:1313/cspaulia-blog/categories/large-language-model/>Large Language Model</a></li><li><a href=http://localhost:1313/cspaulia-blog/categories/nlp/>NLP</a></li></ul><p style=font-size:medium;margin-bottom:5px;font-weight:700>tags</p><ul class=post-tags><li><a href=http://localhost:1313/cspaulia-blog/tags/tokenization/>Tokenization</a></li><li><a href=http://localhost:1313/cspaulia-blog/tags/llm/>LLM</a></li></ul><nav class=paginav><a class=next href=http://localhost:1313/cspaulia-blog/posts/metric/><span class=title>Next »</span><br><span>记录100种评价指标</span></a></nav><ul class=share-buttons><li><a target=_blank rel="noopener noreferrer" aria-label="share Tokenization on x" href="https://x.com/intent/tweet/?text=Tokenization&amp;url=http%3a%2f%2flocalhost%3a1313%2fcspaulia-blog%2fposts%2ftokenization%2f&amp;hashtags=Tokenization%2cLLM"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Tokenization on facebook" href="https://facebook.com/sharer/sharer.php?u=http%3a%2f%2flocalhost%3a1313%2fcspaulia-blog%2fposts%2ftokenization%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Tokenization on telegram" href="https://telegram.me/share/url?text=Tokenization&amp;url=http%3a%2f%2flocalhost%3a1313%2fcspaulia-blog%2fposts%2ftokenization%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentColor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></li></ul></footer></article></main><footer class=footer><span>&copy; 2025 <a href=http://localhost:1313/cspaulia-blog/>cspaulia-blog</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>