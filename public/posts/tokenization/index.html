<!doctype html><html lang=en dir=auto><head><script src="/cspaulia-blog/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=cspaulia-blog/livereload" data-no-instant defer></script><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Tokenization | cspaulia-blog</title><meta name=keywords content="Tokenization,LLM"><meta name=description content="Tokenization in LLM"><meta name=author content="CSPaulia"><link rel=canonical href=http://localhost:1313/cspaulia-blog/posts/tokenization/><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/cspaulia-blog/assets/css/stylesheet.7f7470401ba22070365916022e21efedc8961ad7a41f853fa74ec95e1c55c2ea.css integrity="sha256-f3RwQBuiIHA2WRYCLiHv7ciWGtekH4U/p07JXhxVwuo=" rel="preload stylesheet" as=style><link rel=icon href=http://localhost:1313/cspaulia-blog/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=http://localhost:1313/cspaulia-blog/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=http://localhost:1313/cspaulia-blog/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=http://localhost:1313/cspaulia-blog/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=http://localhost:1313/cspaulia-blog/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=http://localhost:1313/cspaulia-blog/posts/tokenization/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js crossorigin=anonymous></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}],throwOnError:!1,trust:!0,strict:!1})})</script><meta property="og:url" content="http://localhost:1313/cspaulia-blog/posts/tokenization/"><meta property="og:site_name" content="cspaulia-blog"><meta property="og:title" content="Tokenization"><meta property="og:description" content="Tokenization in LLM"><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-07-17T10:20:03+08:00"><meta property="article:modified_time" content="2025-07-19T19:49:05+08:00"><meta property="article:tag" content="Tokenization"><meta property="article:tag" content="LLM"><meta property="og:image" content="http://localhost:1313/cspaulia-blog/tokenization_cover.jpg"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="http://localhost:1313/cspaulia-blog/tokenization_cover.jpg"><meta name=twitter:title content="Tokenization"><meta name=twitter:description content="Tokenization in LLM"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"http://localhost:1313/cspaulia-blog/posts/"},{"@type":"ListItem","position":2,"name":"Tokenization","item":"http://localhost:1313/cspaulia-blog/posts/tokenization/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Tokenization","name":"Tokenization","description":"Tokenization in LLM","keywords":["Tokenization","LLM"],"articleBody":"ğŸ‘‰ åœ¨çº¿ä½“éªŒåœ°å€ï¼šTokenization å¯è§†åŒ–å·¥å…·\nåŸå§‹çš„æ–‡æœ¬ç»Ÿä¸€è¡¨å¾ä¸º Unicode å­—ç¬¦ä¸²\nstring = \"Hello, ğŸŒ! ä½ å¥½!\" è¯­è¨€æ¨¡å‹ä¼šå¯¹ä¸€ç³»åˆ—tokenï¼ˆé€šå¸¸ç”¨æ•´æ•°ç´¢å¼•è¡¨ç¤ºï¼‰ä¸Šçš„å¯èƒ½æ€§è¿›è¡Œå»ºæ¨¡ï¼Œæ„æˆä¸€ä¸ªæ¦‚ç‡åˆ†å¸ƒ\nindices = [15496, 11, 995, 0] æˆ‘ä»¬éœ€è¦ï¼š\nâœ… ä¸€ä¸ªæ–¹æ³•ï¼šå°†å­—ç¬¦ä¸²ç¼–ç ä¸º token âœ… ä¸€ä¸ªæ–¹æ³•ï¼šå°† token è§£ç å›å­—ç¬¦ä¸² class Tokenizer: def encode(self, string: str) -\u003e list[int]: ... def decode(self, indices: list[int]) -\u003e str: ... vocab_size: è¯è¡¨å¤§å°ï¼Œå³å¯èƒ½å‡ºç°çš„ tokenï¼ˆæ•´æ•° IDï¼‰æ€»æ•°ã€‚ Character-based tokenization Unicode æ¦‚è¿° ç»Ÿä¸€å…¨çƒå­—ç¬¦ç¼–ç çš„æ ‡å‡†ï¼ˆçº¦ 150,000 ä¸ªå­—ç¬¦ï¼‰ ord(char)ï¼šè·å–å­—ç¬¦çš„åè¿›åˆ¶ç¼–ç  ord(\"h\") # 104 ord(\"ğŸ˜Š\") # 128522 ç¼–è§£ç  class CharacterTokenizer(Tokenizer): \"\"\"Represent a string as a sequence of Unicode code points.\"\"\" def encode(self, string: str) -\u003e list[int]: return list(map(ord, string)) def decode(self, indices: list[int]) -\u003e str: return \"\".join(map(chr, indices)) ç¤ºä¾‹ï¼š\ntokenizer = CharacterTokenizer() string = \"Hello, ğŸŒ! ä½ å¥½!\" # @inspect string indices = tokenizer.encode(string) # @inspect indices reconstructed_string = tokenizer.decode(indices) # @inspect reconstructed_string è¾“å‡ºï¼š\nstring = \"Hello, ğŸŒ! ä½ å¥½!\" indices = [72, 101, 108, 108, 111, 44, 32, 127757, 33, 32, 20320, 22909, 33] reconstructed_string = \"Hello, ğŸŒ! ä½ å¥½!\" å­˜åœ¨çš„é—®é¢˜ é—®é¢˜ä¸€ï¼šè¿™ä¼šæ˜¯ä¸€ä¸ªç›¸å½“å¤§çš„è¯æ±‡è¡¨ï¼ˆvocabularyï¼‰\né—®é¢˜äºŒï¼šå¾ˆå¤šå­—ç¬¦å‡ºç°å‡ ç‡å¾ˆä½ï¼ˆä¾‹å¦‚ğŸŒï¼‰ï¼Œå¯¹è¯æ±‡è¡¨çš„ä½¿ç”¨å¹¶ä¸é«˜æ•ˆ\ndef get_compression_ratio(string: str, indices: list[int]) -\u003e float: \"\"\"Given `string` that has been tokenized into `indices`, .\"\"\" num_bytes = len(bytes(string, encoding=\"utf-8\")) # @inspect num_bytes num_tokens = len(indices) # @inspect num_tokens return num_bytes / num_tokens vocabulary_size = max(indices) + 1 # This is a lower bound @inspect vocabulary_size compression_ratio = get_compression_ratio(string, indices) # @inspect compression_ratio è¾“å‡ºï¼š\nvocabulary_size = 127758 num_bytes = 20 num_tokens = 13 compression_ratio = 1.5384615384615385 Byte-based tokenization Unicode å­—ç¬¦ä¸²ï¼ˆStringï¼‰å¯ä»¥è¡¨ç¤ºä¸ºä¸€ä¸²å­—èŠ‚ï¼ˆByteï¼‰ï¼Œå…¶ä¸­å­—èŠ‚ï¼ˆå³å…«ä½äºŒè¿›åˆ¶ï¼‰å¯ä»¥è¡¨ç¤ºä¸º0åˆ°255çš„æ•°å­—\næœ€å¸¸è§çš„ Unicode ç¼–ç æ˜¯ UTF-8\nè¾“å…¥ï¼š\nbytes(\"a\", encoding=\"utf-8\") bytes(\"ğŸŒ\", encoding=\"utf-8\") è¾“å‡ºï¼š\nb\"a\" # one byte b\"\\xf0\\x9f\\x8c\\x8d\"s # multiple bytes ç¼–è§£ç  class ByteTokenizer(Tokenizer): \"\"\"Represent a string as a sequence of bytes.\"\"\" def encode(self, string: str) -\u003e list[int]: string_bytes = string.encode(\"utf-8\") # @inspect string_bytes indices = list(map(int, string_bytes)) # @inspect indices return indices def decode(self, indices: list[int]) -\u003e str: string_bytes = bytes(indices) # @inspect string_bytes string = string_bytes.decode(\"utf-8\") # @inspect string return string ç¤ºä¾‹ï¼š\ntokenizer = ByteTokenizer() string = \"Hello, ğŸŒ! ä½ å¥½!\" # @inspect string indices = tokenizer.encode(string) # @inspect indices reconstructed_string = tokenizer.decode(indices) # @inspect reconstructed_string è¾“å‡ºï¼š\nstring = \"Hello, ğŸŒ! ä½ å¥½!\" string_bytes = \"b'Hello, \\\\xf0\\\\x9f\\\\x8c\\\\x8d!\\\\xe4\\\\xbd\\\\xa0\\\\xe5\\\\xa5\\\\xbd'\" indices = [72, 101, 108, 108, 111, 44, 32, 240, 159, 140, 141, 33, 32, 228, 189, 160, 229, 165, 189, 33] reconstructed_string = \"Hello, ğŸŒ! ä½ å¥½!\" å­˜åœ¨çš„é—®é¢˜ é—®é¢˜ä¸€ï¼šè™½ç„¶è¯æ±‡è¡¨å¾ˆå°ï¼ˆä»…ä¸º256ï¼‰ï¼Œä½†è¿™ä¹Ÿå¯¼è‡´åºåˆ—å¾ˆé•¿ã€‚è€Œåœ¨ Transformer ä¸­ï¼Œè®¡ç®—å¤æ‚åº¦æ˜¯éšç€åºåˆ—é•¿åº¦äºŒæ¬¡å¢é•¿çš„\nvocabulary_size = 256 # This is a lower bound @inspect vocabulary_size compression_ratio = get_compression_ratio(string, indices) # @inspect compression_ratio è¾“å‡ºï¼š\nnum_bytes = 20 num_tokens = 20 compression_ratio = 1.0 Word-based tokenization ä½¿ç”¨ç±»ä¼¼äºä¼ ç»ŸNLPåˆ†è¯æ–¹æ³•åˆ†ç¦»å­—ç¬¦ä¸²ï¼Œè¾“å…¥ï¼š\nstring = \"I'll say supercalifragilisticexpialidocious!\" segments = regex.findall(r\"\\w+|.\", string) # @inspect segments è¾“å‡ºï¼š\nsegments = [\"I\", \"ll\", \"say\", \"supercalifragilisticexpialidocious\", \"!\"] ç¼–è§£ç  è¦å°†å…¶è½¬æ¢ä¸ºä¸€ä¸ªtokenizerï¼Œæˆ‘ä»¬éœ€è¦å°†è¿™äº›ç‰‡æ®µæ˜ å°„ä¸ºæ•´æ•° æ„å»ºä¸€ä¸ªä»æ¯ä¸ªç‰‡æ®µåˆ°æ•´æ•°çš„æ˜ å°„ å­˜åœ¨çš„é—®é¢˜ è¯çš„æ•°é‡æ˜¯éå¸¸åºå¤§çš„ å¾ˆå¤šè¯å¾ˆå°‘å‡ºç°ï¼Œæ¨¡å‹ä¸ä¼šä»è¿™äº›è¯ä¸­å­¦ä¹ åˆ°å¾ˆå¤šå†…å®¹ å®ƒæ— æ³•æä¾›ä¸€ä¸ªå›ºå®šé•¿åº¦çš„è¯å…¸ Byte Pair Encodingï¼ˆBPEï¼‰ ä¸»è¦æ€æƒ³ï¼šåœ¨åŸå§‹æ–‡æœ¬ä¸Šè®­ç»ƒtokenizerï¼Œè‡ªå‘çš„ç”Ÿæˆè¯æ±‡è¡¨\næ„å›¾ï¼šå¯¹äºå¸¸è§çš„å­—ç¬¦åºåˆ—ï¼Œå¯ä»¥ä»…ç”¨ä¸€ä¸ªtokenè¡¨ç¤ºï¼›å¯¹äºä¸å¸¸è§çš„å­—ç¬¦åºåˆ—ï¼Œåˆ™ç”¨å¤šä¸ªtokenè¡¨ç¤º\nç®—æ³•ç®€è¿°ï¼šé¦–å…ˆå°†æ¯ä¸€ä¸ªbyteçœ‹ä½œæ˜¯ä¸€ä¸ªtokenï¼Œéšåé€æ¸åˆå¹¶å¸¸å‡ºç°çš„ç›¸é‚»tokenä¸ºä¸€ä¸ªæ–°token\nç®—æ³•æµç¨‹ def merge(indices: list[int], pair: tuple[int, int], new_index: int) -\u003e list[int]: # @inspect indices, @inspect pair, @inspect new_index \"\"\"Return `indices`, but with all instances of `pair` replaced with `new_index`.\"\"\" new_indices = [] # @inspect new_indices i = 0 # @inspect i while i \u003c len(indices): if i + 1 \u003c len(indices) and indices[i] == pair[0] and indices[i + 1] == pair[1]: new_indices.append(new_index) i += 2 else: new_indices.append(indices[i]) i += 1 return new_indices BPE ç¼–ç å™¨ class BPETokenizer(Tokenizer): \"\"\"BPE tokenizer given a set of merges and a vocabulary.\"\"\" def __init__(self, params: BPETokenizerParams): self.params = params def encode(self, string: str) -\u003e list[int]: indices = list(map(int, string.encode(\"utf-8\"))) # @inspect indices # Note: this is a very slow implementation for pair, new_index in self.params.merges.items(): # @inspect pair, @inspect new_index indices = merge(indices, pair, new_index) return indices def decode(self, indices: list[int]) -\u003e str: bytes_list = list(map(self.params.vocab.get, indices)) # @inspect bytes_list string = b\"\".join(bytes_list).decode(\"utf-8\") # @inspect string return string è®­ç»ƒ BPE def train_bpe(string: str, num_merges: int) -\u003e BPETokenizerParams: # @inspect string, @inspect num_merges # Start with the list of bytes of string. indices = list(map(int, string.encode(\"utf-8\"))) # @inspect indices merges: dict[tuple[int, int], int] = {} # index1, index2 =\u003e merged index vocab: dict[int, bytes] = {x: bytes([x]) for x in range(256)} # index -\u003e bytes for i in range(num_merges): # Count the number of occurrences of each pair of tokens counts = defaultdict(int) for index1, index2 in zip(indices, indices[1:]): # For each adjacent pair counts[(index1, index2)] += 1 # @inspect counts # Find the most common pair. pair = max(counts, key=counts.get) # @inspect pair index1, index2 = pair # Merge that pair. new_index = 256 + i # @inspect new_index merges[pair] = new_index # @inspect merges vocab[new_index] = vocab[index1] + vocab[index2] # @inspect vocab indices = merge(indices, pair, new_index) # @inspect indices return BPETokenizerParams(vocab=vocab, merges=merges) ç¤ºä¾‹:\ntext = \"the cat in the hat\" # @inspect string params = train_bpe(text, num_merges=3) string = \"the quick brown fox\" # @inspect string tokenizer = BPETokenizer(params) indices = tokenizer.encode(string) # @inspect indices reconstructed_string = tokenizer.decode(indices) # @inspect reconstructed_string ä»£ç é€»è¾‘ä¸ºï¼š\nåˆå§‹åŒ–è¯æ±‡è¡¨ï¼Œç”¨0-255è¡¨å¾byte ä¾æ¬¡å¯»æ‰¾æœ€å¤šæ¬¡å‡ºç°çš„ç›¸é‚»byte (116, 104) â€“\u003e 256 å³ (â€™tâ€™, â€˜hâ€™) â€“\u003e â€™thâ€™ (256, 101) â€“\u003e 257 å³ (â€™thâ€™, â€™eâ€™) â€“\u003e â€™the' (257, 32) â€“\u003e 258 å³ ï¼ˆâ€™theâ€™, â€™ â€˜ï¼‰â€“\u003e â€™the ' è¯æ±‡è¡¨é•¿åº¦æ›´æ–°è‡³259 ç”¨æ–°è¯æ±‡è¡¨å¯¹å­—ç¬¦ä¸²è¿›è¡Œç¼–ç  ","wordCount":"783","inLanguage":"en","image":"http://localhost:1313/cspaulia-blog/tokenization_cover.jpg","datePublished":"2025-07-17T10:20:03+08:00","dateModified":"2025-07-19T19:49:05+08:00","author":{"@type":"Person","name":"CSPaulia"},"mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:1313/cspaulia-blog/posts/tokenization/"},"publisher":{"@type":"Organization","name":"cspaulia-blog","logo":{"@type":"ImageObject","url":"http://localhost:1313/cspaulia-blog/%3Clink%20/%20abs%20url%3E"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=http://localhost:1313/cspaulia-blog/ accesskey=h title="Home (Alt + H)"><img src=http://localhost:1313/apple-touch-icon.png alt aria-label=logo height=35>Home</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=http://localhost:1313/cspaulia-blog/posts/ title=posts><span>posts</span></a></li><li><a href=http://localhost:1313/cspaulia-blog/categories/ title=categories><span>categories</span></a></li><li><a href=http://localhost:1313/cspaulia-blog/series/ title=series><span>series</span></a></li><li><a href=http://localhost:1313/cspaulia-blog/tags/ title=tags><span>tags</span></a></li><li><a href=http://localhost:1313/cspaulia-blog/archives/ title=archives><span>archives</span></a></li><li><a href=http://localhost:1313/cspaulia-blog/search/ title="search (Alt + /)" accesskey=/><span>search</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=http://localhost:1313/cspaulia-blog/>Home</a>&nbsp;Â»&nbsp;<a href=http://localhost:1313/cspaulia-blog/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">Tokenization</h1><div class=post-description>Tokenization in LLM</div><div class=post-meta><span class=post-meta-item><svg width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><rect x="3" y="4" width="18" height="18" rx="2" ry="2"/><line x1="16" y1="2" x2="16" y2="6"/><line x1="8" y1="2" x2="8" y2="6"/><line x1="3" y1="10" x2="21" y2="10"/></svg> July 17, 2025</span> ï½œ <span class=post-meta-item><svg width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M12 19l7-7 3 3-7 7-3-3z"/><path d="M18 13l-1.5-7.5L2 2l3.5 14.5L13 18l5-5z"/><path d="M2 2l7.586 7.586"/><circle cx="11" cy="11" r="2"/></svg> July 19, 2025</span> ï½œ <span class=post-meta-item><svg width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M14 2H6A2 2 0 004 4v16a2 2 0 002 2h12a2 2 0 002-2V8z"/><path d="M14 2v6h6"/><line x1="8" y1="13" x2="16" y2="13"/><line x1="8" y1="17" x2="16" y2="17"/><line x1="8" y1="9" x2="12" y2="9"/></svg> 783 words</span> ï½œ <span class=post-meta-item><svg width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="10"/><polyline points="12 6 12 12 16 14"/></svg> 4 min</span> ï½œ <span class=post-meta-item><svg width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M20 21v-2a4 4 0 00-4-4H8a4 4 0 00-4 4v2"/><circle cx="12" cy="7" r="4"/></svg> CSPaulia</span>
&nbsp;|&nbsp;<a href=https://cspaulia.github.io/cspaulia-blog/content//posts/tokenization/index.md rel="noopener noreferrer edit" target=_blank>Suggest Changes</a></div></header><aside id=toc-container class="toc-container wide"><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#character-based-tokenization aria-label="Character-based tokenization">Character-based tokenization</a><ul><li><a href=#unicode-%e6%a6%82%e8%bf%b0 aria-label="Unicode æ¦‚è¿°">Unicode æ¦‚è¿°</a></li><li><a href=#%e7%bc%96%e8%a7%a3%e7%a0%81 aria-label=ç¼–è§£ç >ç¼–è§£ç </a></li><li><a href=#%e5%ad%98%e5%9c%a8%e7%9a%84%e9%97%ae%e9%a2%98 aria-label=å­˜åœ¨çš„é—®é¢˜>å­˜åœ¨çš„é—®é¢˜</a></li></ul></li><li><a href=#byte-based-tokenization aria-label="Byte-based tokenization">Byte-based tokenization</a><ul><li><a href=#%e7%bc%96%e8%a7%a3%e7%a0%81-1 aria-label=ç¼–è§£ç >ç¼–è§£ç </a></li><li><a href=#%e5%ad%98%e5%9c%a8%e7%9a%84%e9%97%ae%e9%a2%98-1 aria-label=å­˜åœ¨çš„é—®é¢˜>å­˜åœ¨çš„é—®é¢˜</a></li></ul></li><li><a href=#word-based-tokenization aria-label="Word-based tokenization">Word-based tokenization</a><ul><li><a href=#%e7%bc%96%e8%a7%a3%e7%a0%81-2 aria-label=ç¼–è§£ç >ç¼–è§£ç </a></li><li><a href=#%e5%ad%98%e5%9c%a8%e7%9a%84%e9%97%ae%e9%a2%98-2 aria-label=å­˜åœ¨çš„é—®é¢˜>å­˜åœ¨çš„é—®é¢˜</a></li></ul></li><li><a href=#byte-pair-encodingbpe aria-label="Byte Pair Encodingï¼ˆBPEï¼‰">Byte Pair Encodingï¼ˆBPEï¼‰</a><ul><li><a href=#%e7%ae%97%e6%b3%95%e6%b5%81%e7%a8%8b aria-label=ç®—æ³•æµç¨‹>ç®—æ³•æµç¨‹</a></li><li><a href=#bpe-%e7%bc%96%e7%a0%81%e5%99%a8 aria-label="BPE ç¼–ç å™¨">BPE ç¼–ç å™¨</a></li><li><a href=#%e8%ae%ad%e7%bb%83-bpe aria-label="è®­ç»ƒ BPE">è®­ç»ƒ BPE</a></li></ul></li></ul></div></details></div></aside><script>let activeElement,elements;window.addEventListener("DOMContentLoaded",function(){checkTocPosition(),elements=document.querySelectorAll("h2[id],h3[id]"),activeElement=elements[0];const t=encodeURI(activeElement.getAttribute("id")).toLowerCase();document.querySelector(`.inner ul li a[href="#${t}"]`).classList.add("active")},!1),window.addEventListener("resize",function(){checkTocPosition()},!1),window.addEventListener("scroll",()=>{activeElement=Array.from(elements).find(e=>{if(getOffsetTop(e)-window.pageYOffset>0&&getOffsetTop(e)-window.pageYOffset<window.innerHeight/2)return e})||activeElement,elements.forEach(e=>{const t=encodeURI(e.getAttribute("id")).toLowerCase();e===activeElement?document.querySelector(`.inner ul li a[href="#${t}"]`).classList.add("active"):document.querySelector(`.inner ul li a[href="#${t}"]`).classList.remove("active")})},!1);const main=parseInt(getComputedStyle(document.body).getPropertyValue("--article-width"),10),toc=parseInt(getComputedStyle(document.body).getPropertyValue("--toc-width"),10),gap=parseInt(getComputedStyle(document.body).getPropertyValue("--gap"),10);function checkTocPosition(){const e=document.body.scrollWidth;e-main-toc*2-gap*4>0?document.getElementById("toc-container").classList.add("wide"):document.getElementById("toc-container").classList.remove("wide")}function getOffsetTop(e){if(!e.getClientRects().length)return 0;let t=e.getBoundingClientRect(),n=e.ownerDocument.defaultView;return t.top+n.pageYOffset}</script><div class=post-content><p>ğŸ‘‰ åœ¨çº¿ä½“éªŒåœ°å€ï¼š<a href=https://tiktokenizer.vercel.app>Tokenization å¯è§†åŒ–å·¥å…·</a></p><hr><p>åŸå§‹çš„æ–‡æœ¬ç»Ÿä¸€è¡¨å¾ä¸º Unicode å­—ç¬¦ä¸²</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>string</span> <span class=o>=</span> <span class=s2>&#34;Hello, ğŸŒ! ä½ å¥½!&#34;</span>
</span></span></code></pre></div><p>è¯­è¨€æ¨¡å‹ä¼šå¯¹ä¸€ç³»åˆ—tokenï¼ˆé€šå¸¸ç”¨æ•´æ•°ç´¢å¼•è¡¨ç¤ºï¼‰ä¸Šçš„å¯èƒ½æ€§è¿›è¡Œå»ºæ¨¡ï¼Œæ„æˆä¸€ä¸ªæ¦‚ç‡åˆ†å¸ƒ</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>indices</span> <span class=o>=</span> <span class=p>[</span><span class=mi>15496</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>995</span><span class=p>,</span> <span class=mi>0</span><span class=p>]</span>
</span></span></code></pre></div><p>æˆ‘ä»¬éœ€è¦ï¼š</p><ul><li>âœ… ä¸€ä¸ªæ–¹æ³•ï¼š<strong>å°†å­—ç¬¦ä¸²ç¼–ç ä¸º token</strong></li><li>âœ… ä¸€ä¸ªæ–¹æ³•ï¼š<strong>å°† token è§£ç å›å­—ç¬¦ä¸²</strong></li></ul><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>class</span> <span class=nc>Tokenizer</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>encode</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>string</span><span class=p>:</span> <span class=nb>str</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=nb>list</span><span class=p>[</span><span class=nb>int</span><span class=p>]:</span>
</span></span><span class=line><span class=cl>        <span class=o>...</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>decode</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>indices</span><span class=p>:</span> <span class=nb>list</span><span class=p>[</span><span class=nb>int</span><span class=p>])</span> <span class=o>-&gt;</span> <span class=nb>str</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=o>...</span>
</span></span></code></pre></div><ul><li><code>vocab_size</code>: è¯è¡¨å¤§å°ï¼Œå³å¯èƒ½å‡ºç°çš„ tokenï¼ˆæ•´æ•° IDï¼‰æ€»æ•°ã€‚</li></ul><hr><h2 id=character-based-tokenization>Character-based tokenization<a hidden class=anchor aria-hidden=true href=#character-based-tokenization>#</a></h2><h3 id=unicode-æ¦‚è¿°>Unicode æ¦‚è¿°<a hidden class=anchor aria-hidden=true href=#unicode-æ¦‚è¿°>#</a></h3><ul><li>ç»Ÿä¸€å…¨çƒå­—ç¬¦ç¼–ç çš„æ ‡å‡†ï¼ˆçº¦ 150,000 ä¸ªå­—ç¬¦ï¼‰</li><li><code>ord(char)</code>ï¼šè·å–å­—ç¬¦çš„åè¿›åˆ¶ç¼–ç </li></ul><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=nb>ord</span><span class=p>(</span><span class=s2>&#34;h&#34;</span><span class=p>)</span>     <span class=c1># 104</span>
</span></span><span class=line><span class=cl><span class=nb>ord</span><span class=p>(</span><span class=s2>&#34;ğŸ˜Š&#34;</span><span class=p>)</span>    <span class=c1># 128522</span>
</span></span></code></pre></div><h3 id=ç¼–è§£ç >ç¼–è§£ç <a hidden class=anchor aria-hidden=true href=#ç¼–è§£ç >#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>class</span> <span class=nc>CharacterTokenizer</span><span class=p>(</span><span class=n>Tokenizer</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;Represent a string as a sequence of Unicode code points.&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>encode</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>string</span><span class=p>:</span> <span class=nb>str</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=nb>list</span><span class=p>[</span><span class=nb>int</span><span class=p>]:</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=nb>list</span><span class=p>(</span><span class=nb>map</span><span class=p>(</span><span class=nb>ord</span><span class=p>,</span> <span class=n>string</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>decode</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>indices</span><span class=p>:</span> <span class=nb>list</span><span class=p>[</span><span class=nb>int</span><span class=p>])</span> <span class=o>-&gt;</span> <span class=nb>str</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=s2>&#34;&#34;</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=nb>map</span><span class=p>(</span><span class=nb>chr</span><span class=p>,</span> <span class=n>indices</span><span class=p>))</span>
</span></span></code></pre></div><p><strong>ç¤ºä¾‹</strong>ï¼š</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>tokenizer</span> <span class=o>=</span> <span class=n>CharacterTokenizer</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>string</span> <span class=o>=</span> <span class=s2>&#34;Hello, ğŸŒ! ä½ å¥½!&#34;</span>  <span class=c1># @inspect string</span>
</span></span><span class=line><span class=cl><span class=n>indices</span> <span class=o>=</span> <span class=n>tokenizer</span><span class=o>.</span><span class=n>encode</span><span class=p>(</span><span class=n>string</span><span class=p>)</span>  <span class=c1># @inspect indices</span>
</span></span><span class=line><span class=cl><span class=n>reconstructed_string</span> <span class=o>=</span> <span class=n>tokenizer</span><span class=o>.</span><span class=n>decode</span><span class=p>(</span><span class=n>indices</span><span class=p>)</span>  <span class=c1># @inspect reconstructed_string</span>
</span></span></code></pre></div><p><strong>è¾“å‡º</strong>ï¼š</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-text data-lang=text><span class=line><span class=cl>string = &#34;Hello, ğŸŒ! ä½ å¥½!&#34;
</span></span><span class=line><span class=cl>indices = [72, 101, 108, 108, 111, 44, 32, 127757, 33, 32, 20320, 22909, 33]
</span></span><span class=line><span class=cl>reconstructed_string = &#34;Hello, ğŸŒ! ä½ å¥½!&#34;
</span></span></code></pre></div><h3 id=å­˜åœ¨çš„é—®é¢˜>å­˜åœ¨çš„é—®é¢˜<a hidden class=anchor aria-hidden=true href=#å­˜åœ¨çš„é—®é¢˜>#</a></h3><ul><li><p>é—®é¢˜ä¸€ï¼šè¿™ä¼šæ˜¯ä¸€ä¸ªç›¸å½“å¤§çš„è¯æ±‡è¡¨ï¼ˆvocabularyï¼‰</p></li><li><p>é—®é¢˜äºŒï¼šå¾ˆå¤šå­—ç¬¦å‡ºç°å‡ ç‡å¾ˆä½ï¼ˆä¾‹å¦‚ğŸŒï¼‰ï¼Œå¯¹è¯æ±‡è¡¨çš„ä½¿ç”¨å¹¶ä¸é«˜æ•ˆ</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>get_compression_ratio</span><span class=p>(</span><span class=n>string</span><span class=p>:</span> <span class=nb>str</span><span class=p>,</span> <span class=n>indices</span><span class=p>:</span> <span class=nb>list</span><span class=p>[</span><span class=nb>int</span><span class=p>])</span> <span class=o>-&gt;</span> <span class=nb>float</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;Given `string` that has been tokenized into `indices`, .&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>num_bytes</span> <span class=o>=</span> <span class=nb>len</span><span class=p>(</span><span class=nb>bytes</span><span class=p>(</span><span class=n>string</span><span class=p>,</span> <span class=n>encoding</span><span class=o>=</span><span class=s2>&#34;utf-8&#34;</span><span class=p>))</span>  <span class=c1># @inspect num_bytes</span>
</span></span><span class=line><span class=cl>    <span class=n>num_tokens</span> <span class=o>=</span> <span class=nb>len</span><span class=p>(</span><span class=n>indices</span><span class=p>)</span>                       <span class=c1># @inspect num_tokens</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>num_bytes</span> <span class=o>/</span> <span class=n>num_tokens</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>vocabulary_size</span> <span class=o>=</span> <span class=nb>max</span><span class=p>(</span><span class=n>indices</span><span class=p>)</span> <span class=o>+</span> <span class=mi>1</span>  <span class=c1># This is a lower bound @inspect vocabulary_size</span>
</span></span><span class=line><span class=cl><span class=n>compression_ratio</span> <span class=o>=</span> <span class=n>get_compression_ratio</span><span class=p>(</span><span class=n>string</span><span class=p>,</span> <span class=n>indices</span><span class=p>)</span>  <span class=c1># @inspect compression_ratio</span>
</span></span></code></pre></div><p><strong>è¾“å‡º</strong>ï¼š</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-text data-lang=text><span class=line><span class=cl>vocabulary_size = 127758
</span></span><span class=line><span class=cl>num_bytes = 20
</span></span><span class=line><span class=cl>num_tokens = 13
</span></span><span class=line><span class=cl>compression_ratio = 1.5384615384615385
</span></span></code></pre></div></li></ul><hr><h2 id=byte-based-tokenization>Byte-based tokenization<a hidden class=anchor aria-hidden=true href=#byte-based-tokenization>#</a></h2><ul><li><p>Unicode å­—ç¬¦ä¸²ï¼ˆStringï¼‰å¯ä»¥è¡¨ç¤ºä¸ºä¸€ä¸²å­—èŠ‚ï¼ˆByteï¼‰ï¼Œå…¶ä¸­å­—èŠ‚ï¼ˆå³å…«ä½äºŒè¿›åˆ¶ï¼‰å¯ä»¥è¡¨ç¤ºä¸º0åˆ°255çš„æ•°å­—</p></li><li><p>æœ€å¸¸è§çš„ Unicode ç¼–ç æ˜¯ UTF-8</p><p><strong>è¾“å…¥</strong>ï¼š</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=nb>bytes</span><span class=p>(</span><span class=s2>&#34;a&#34;</span><span class=p>,</span> <span class=n>encoding</span><span class=o>=</span><span class=s2>&#34;utf-8&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>bytes</span><span class=p>(</span><span class=s2>&#34;ğŸŒ&#34;</span><span class=p>,</span> <span class=n>encoding</span><span class=o>=</span><span class=s2>&#34;utf-8&#34;</span><span class=p>)</span>
</span></span></code></pre></div><p><strong>è¾“å‡º</strong>ï¼š</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-text data-lang=text><span class=line><span class=cl>b&#34;a&#34; # one byte
</span></span><span class=line><span class=cl>b&#34;\xf0\x9f\x8c\x8d&#34;s # multiple bytes
</span></span></code></pre></div></li></ul><h3 id=ç¼–è§£ç -1>ç¼–è§£ç <a hidden class=anchor aria-hidden=true href=#ç¼–è§£ç -1>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>class</span> <span class=nc>ByteTokenizer</span><span class=p>(</span><span class=n>Tokenizer</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;Represent a string as a sequence of bytes.&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>encode</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>string</span><span class=p>:</span> <span class=nb>str</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=nb>list</span><span class=p>[</span><span class=nb>int</span><span class=p>]:</span>
</span></span><span class=line><span class=cl>        <span class=n>string_bytes</span> <span class=o>=</span> <span class=n>string</span><span class=o>.</span><span class=n>encode</span><span class=p>(</span><span class=s2>&#34;utf-8&#34;</span><span class=p>)</span>  <span class=c1># @inspect string_bytes</span>
</span></span><span class=line><span class=cl>        <span class=n>indices</span> <span class=o>=</span> <span class=nb>list</span><span class=p>(</span><span class=nb>map</span><span class=p>(</span><span class=nb>int</span><span class=p>,</span> <span class=n>string_bytes</span><span class=p>))</span>  <span class=c1># @inspect indices</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>indices</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>decode</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>indices</span><span class=p>:</span> <span class=nb>list</span><span class=p>[</span><span class=nb>int</span><span class=p>])</span> <span class=o>-&gt;</span> <span class=nb>str</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>string_bytes</span> <span class=o>=</span> <span class=nb>bytes</span><span class=p>(</span><span class=n>indices</span><span class=p>)</span>  <span class=c1># @inspect string_bytes</span>
</span></span><span class=line><span class=cl>        <span class=n>string</span> <span class=o>=</span> <span class=n>string_bytes</span><span class=o>.</span><span class=n>decode</span><span class=p>(</span><span class=s2>&#34;utf-8&#34;</span><span class=p>)</span>  <span class=c1># @inspect string</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>string</span>
</span></span></code></pre></div><p><strong>ç¤ºä¾‹</strong>ï¼š</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>tokenizer</span> <span class=o>=</span> <span class=n>ByteTokenizer</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>string</span> <span class=o>=</span> <span class=s2>&#34;Hello, ğŸŒ! ä½ å¥½!&#34;</span>  <span class=c1># @inspect string</span>
</span></span><span class=line><span class=cl><span class=n>indices</span> <span class=o>=</span> <span class=n>tokenizer</span><span class=o>.</span><span class=n>encode</span><span class=p>(</span><span class=n>string</span><span class=p>)</span>  <span class=c1># @inspect indices</span>
</span></span><span class=line><span class=cl><span class=n>reconstructed_string</span> <span class=o>=</span> <span class=n>tokenizer</span><span class=o>.</span><span class=n>decode</span><span class=p>(</span><span class=n>indices</span><span class=p>)</span>  <span class=c1># @inspect reconstructed_string</span>
</span></span></code></pre></div><p><strong>è¾“å‡º</strong>ï¼š</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-text data-lang=text><span class=line><span class=cl>string = &#34;Hello, ğŸŒ! ä½ å¥½!&#34;
</span></span><span class=line><span class=cl>string_bytes = &#34;b&#39;Hello, \\xf0\\x9f\\x8c\\x8d!\\xe4\\xbd\\xa0\\xe5\\xa5\\xbd&#39;&#34;
</span></span><span class=line><span class=cl>indices = [72, 101, 108, 108, 111, 44, 32, 240, 159, 140, 141, 33, 32, 228, 189, 160, 229, 165, 189, 33]
</span></span><span class=line><span class=cl>reconstructed_string = &#34;Hello, ğŸŒ! ä½ å¥½!&#34;
</span></span></code></pre></div><h3 id=å­˜åœ¨çš„é—®é¢˜-1>å­˜åœ¨çš„é—®é¢˜<a hidden class=anchor aria-hidden=true href=#å­˜åœ¨çš„é—®é¢˜-1>#</a></h3><ul><li><p>é—®é¢˜ä¸€ï¼šè™½ç„¶è¯æ±‡è¡¨å¾ˆå°ï¼ˆä»…ä¸º256ï¼‰ï¼Œä½†è¿™ä¹Ÿå¯¼è‡´åºåˆ—å¾ˆé•¿ã€‚è€Œåœ¨ Transformer ä¸­ï¼Œè®¡ç®—å¤æ‚åº¦æ˜¯éšç€åºåˆ—é•¿åº¦<strong>äºŒæ¬¡å¢é•¿</strong>çš„</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>vocabulary_size</span> <span class=o>=</span> <span class=mi>256</span>  <span class=c1># This is a lower bound @inspect vocabulary_size</span>
</span></span><span class=line><span class=cl><span class=n>compression_ratio</span> <span class=o>=</span> <span class=n>get_compression_ratio</span><span class=p>(</span><span class=n>string</span><span class=p>,</span> <span class=n>indices</span><span class=p>)</span>  <span class=c1># @inspect compression_ratio</span>
</span></span></code></pre></div><p><strong>è¾“å‡º</strong>ï¼š</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-text data-lang=text><span class=line><span class=cl>num_bytes = 20
</span></span><span class=line><span class=cl>num_tokens = 20
</span></span><span class=line><span class=cl>compression_ratio = 1.0
</span></span></code></pre></div></li></ul><hr><h2 id=word-based-tokenization>Word-based tokenization<a hidden class=anchor aria-hidden=true href=#word-based-tokenization>#</a></h2><p>ä½¿ç”¨ç±»ä¼¼äºä¼ ç»ŸNLPåˆ†è¯æ–¹æ³•åˆ†ç¦»å­—ç¬¦ä¸²ï¼Œ<strong>è¾“å…¥</strong>ï¼š</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>string</span> <span class=o>=</span> <span class=s2>&#34;I&#39;ll say supercalifragilisticexpialidocious!&#34;</span>
</span></span><span class=line><span class=cl><span class=n>segments</span> <span class=o>=</span> <span class=n>regex</span><span class=o>.</span><span class=n>findall</span><span class=p>(</span><span class=sa>r</span><span class=s2>&#34;\w+|.&#34;</span><span class=p>,</span> <span class=n>string</span><span class=p>)</span>  <span class=c1># @inspect segments</span>
</span></span></code></pre></div><p><strong>è¾“å‡º</strong>ï¼š</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-text data-lang=text><span class=line><span class=cl>segments = [&#34;I&#34;, &#34;ll&#34;, &#34;say&#34;, &#34;supercalifragilisticexpialidocious&#34;, &#34;!&#34;]
</span></span></code></pre></div><h3 id=ç¼–è§£ç -2>ç¼–è§£ç <a hidden class=anchor aria-hidden=true href=#ç¼–è§£ç -2>#</a></h3><ul><li>è¦å°†å…¶è½¬æ¢ä¸ºä¸€ä¸ª<code>tokenizer</code>ï¼Œæˆ‘ä»¬éœ€è¦å°†è¿™äº›ç‰‡æ®µæ˜ å°„ä¸ºæ•´æ•°</li><li>æ„å»ºä¸€ä¸ªä»æ¯ä¸ªç‰‡æ®µåˆ°æ•´æ•°çš„æ˜ å°„</li></ul><h3 id=å­˜åœ¨çš„é—®é¢˜-2>å­˜åœ¨çš„é—®é¢˜<a hidden class=anchor aria-hidden=true href=#å­˜åœ¨çš„é—®é¢˜-2>#</a></h3><ul><li>è¯çš„æ•°é‡æ˜¯éå¸¸åºå¤§çš„</li><li>å¾ˆå¤šè¯å¾ˆå°‘å‡ºç°ï¼Œæ¨¡å‹ä¸ä¼šä»è¿™äº›è¯ä¸­å­¦ä¹ åˆ°å¾ˆå¤šå†…å®¹</li><li>å®ƒæ— æ³•æä¾›ä¸€ä¸ªå›ºå®šé•¿åº¦çš„è¯å…¸</li></ul><hr><h2 id=byte-pair-encodingbpe>Byte Pair Encodingï¼ˆBPEï¼‰<a hidden class=anchor aria-hidden=true href=#byte-pair-encodingbpe>#</a></h2><p><strong>ä¸»è¦æ€æƒ³</strong>ï¼šåœ¨åŸå§‹æ–‡æœ¬ä¸Šè®­ç»ƒ<code>tokenizer</code>ï¼Œè‡ªå‘çš„ç”Ÿæˆè¯æ±‡è¡¨</p><p><strong>æ„å›¾</strong>ï¼šå¯¹äºå¸¸è§çš„å­—ç¬¦åºåˆ—ï¼Œå¯ä»¥ä»…ç”¨ä¸€ä¸ªtokenè¡¨ç¤ºï¼›å¯¹äºä¸å¸¸è§çš„å­—ç¬¦åºåˆ—ï¼Œåˆ™ç”¨å¤šä¸ªtokenè¡¨ç¤º</p><p><strong>ç®—æ³•ç®€è¿°</strong>ï¼šé¦–å…ˆå°†æ¯ä¸€ä¸ª<strong>byte</strong>çœ‹ä½œæ˜¯ä¸€ä¸ªtokenï¼Œéšåé€æ¸åˆå¹¶å¸¸å‡ºç°çš„ç›¸é‚»tokenä¸ºä¸€ä¸ªæ–°token</p><h3 id=ç®—æ³•æµç¨‹>ç®—æ³•æµç¨‹<a hidden class=anchor aria-hidden=true href=#ç®—æ³•æµç¨‹>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>merge</span><span class=p>(</span><span class=n>indices</span><span class=p>:</span> <span class=nb>list</span><span class=p>[</span><span class=nb>int</span><span class=p>],</span> <span class=n>pair</span><span class=p>:</span> <span class=nb>tuple</span><span class=p>[</span><span class=nb>int</span><span class=p>,</span> <span class=nb>int</span><span class=p>],</span> <span class=n>new_index</span><span class=p>:</span> <span class=nb>int</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=nb>list</span><span class=p>[</span><span class=nb>int</span><span class=p>]:</span>  <span class=c1># @inspect indices, @inspect pair, @inspect new_index</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;Return `indices`, but with all instances of `pair` replaced with `new_index`.&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>new_indices</span> <span class=o>=</span> <span class=p>[]</span>  <span class=c1># @inspect new_indices</span>
</span></span><span class=line><span class=cl>    <span class=n>i</span> <span class=o>=</span> <span class=mi>0</span>  <span class=c1># @inspect i</span>
</span></span><span class=line><span class=cl>    <span class=k>while</span> <span class=n>i</span> <span class=o>&lt;</span> <span class=nb>len</span><span class=p>(</span><span class=n>indices</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=n>i</span> <span class=o>+</span> <span class=mi>1</span> <span class=o>&lt;</span> <span class=nb>len</span><span class=p>(</span><span class=n>indices</span><span class=p>)</span> <span class=ow>and</span> <span class=n>indices</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>==</span> <span class=n>pair</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span> <span class=ow>and</span> <span class=n>indices</span><span class=p>[</span><span class=n>i</span> <span class=o>+</span> <span class=mi>1</span><span class=p>]</span> <span class=o>==</span> <span class=n>pair</span><span class=p>[</span><span class=mi>1</span><span class=p>]:</span>
</span></span><span class=line><span class=cl>            <span class=n>new_indices</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>new_index</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>i</span> <span class=o>+=</span> <span class=mi>2</span>
</span></span><span class=line><span class=cl>        <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>new_indices</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>indices</span><span class=p>[</span><span class=n>i</span><span class=p>])</span>
</span></span><span class=line><span class=cl>            <span class=n>i</span> <span class=o>+=</span> <span class=mi>1</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>new_indices</span>
</span></span></code></pre></div><h3 id=bpe-ç¼–ç å™¨>BPE ç¼–ç å™¨<a hidden class=anchor aria-hidden=true href=#bpe-ç¼–ç å™¨>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>class</span> <span class=nc>BPETokenizer</span><span class=p>(</span><span class=n>Tokenizer</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;BPE tokenizer given a set of merges and a vocabulary.&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>params</span><span class=p>:</span> <span class=n>BPETokenizerParams</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>params</span> <span class=o>=</span> <span class=n>params</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>encode</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>string</span><span class=p>:</span> <span class=nb>str</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=nb>list</span><span class=p>[</span><span class=nb>int</span><span class=p>]:</span>
</span></span><span class=line><span class=cl>        <span class=n>indices</span> <span class=o>=</span> <span class=nb>list</span><span class=p>(</span><span class=nb>map</span><span class=p>(</span><span class=nb>int</span><span class=p>,</span> <span class=n>string</span><span class=o>.</span><span class=n>encode</span><span class=p>(</span><span class=s2>&#34;utf-8&#34;</span><span class=p>)))</span>  <span class=c1># @inspect indices</span>
</span></span><span class=line><span class=cl>        <span class=c1># Note: this is a very slow implementation</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>pair</span><span class=p>,</span> <span class=n>new_index</span> <span class=ow>in</span> <span class=bp>self</span><span class=o>.</span><span class=n>params</span><span class=o>.</span><span class=n>merges</span><span class=o>.</span><span class=n>items</span><span class=p>():</span>  <span class=c1># @inspect pair, @inspect new_index</span>
</span></span><span class=line><span class=cl>            <span class=n>indices</span> <span class=o>=</span> <span class=n>merge</span><span class=p>(</span><span class=n>indices</span><span class=p>,</span> <span class=n>pair</span><span class=p>,</span> <span class=n>new_index</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>indices</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>decode</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>indices</span><span class=p>:</span> <span class=nb>list</span><span class=p>[</span><span class=nb>int</span><span class=p>])</span> <span class=o>-&gt;</span> <span class=nb>str</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>bytes_list</span> <span class=o>=</span> <span class=nb>list</span><span class=p>(</span><span class=nb>map</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>params</span><span class=o>.</span><span class=n>vocab</span><span class=o>.</span><span class=n>get</span><span class=p>,</span> <span class=n>indices</span><span class=p>))</span>  <span class=c1># @inspect bytes_list</span>
</span></span><span class=line><span class=cl>        <span class=n>string</span> <span class=o>=</span> <span class=sa>b</span><span class=s2>&#34;&#34;</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=n>bytes_list</span><span class=p>)</span><span class=o>.</span><span class=n>decode</span><span class=p>(</span><span class=s2>&#34;utf-8&#34;</span><span class=p>)</span>  <span class=c1># @inspect string</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>string</span>
</span></span></code></pre></div><h3 id=è®­ç»ƒ-bpe>è®­ç»ƒ BPE<a hidden class=anchor aria-hidden=true href=#è®­ç»ƒ-bpe>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>train_bpe</span><span class=p>(</span><span class=n>string</span><span class=p>:</span> <span class=nb>str</span><span class=p>,</span> <span class=n>num_merges</span><span class=p>:</span> <span class=nb>int</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>BPETokenizerParams</span><span class=p>:</span>  <span class=c1># @inspect string, @inspect num_merges</span>
</span></span><span class=line><span class=cl>    <span class=c1># Start with the list of bytes of string.</span>
</span></span><span class=line><span class=cl>    <span class=n>indices</span> <span class=o>=</span> <span class=nb>list</span><span class=p>(</span><span class=nb>map</span><span class=p>(</span><span class=nb>int</span><span class=p>,</span> <span class=n>string</span><span class=o>.</span><span class=n>encode</span><span class=p>(</span><span class=s2>&#34;utf-8&#34;</span><span class=p>)))</span>  <span class=c1># @inspect indices</span>
</span></span><span class=line><span class=cl>    <span class=n>merges</span><span class=p>:</span> <span class=nb>dict</span><span class=p>[</span><span class=nb>tuple</span><span class=p>[</span><span class=nb>int</span><span class=p>,</span> <span class=nb>int</span><span class=p>],</span> <span class=nb>int</span><span class=p>]</span> <span class=o>=</span> <span class=p>{}</span>  <span class=c1># index1, index2 =&gt; merged index</span>
</span></span><span class=line><span class=cl>    <span class=n>vocab</span><span class=p>:</span> <span class=nb>dict</span><span class=p>[</span><span class=nb>int</span><span class=p>,</span> <span class=nb>bytes</span><span class=p>]</span> <span class=o>=</span> <span class=p>{</span><span class=n>x</span><span class=p>:</span> <span class=nb>bytes</span><span class=p>([</span><span class=n>x</span><span class=p>])</span> <span class=k>for</span> <span class=n>x</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>256</span><span class=p>)}</span>  <span class=c1># index -&gt; bytes</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>num_merges</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=c1># Count the number of occurrences of each pair of tokens</span>
</span></span><span class=line><span class=cl>        <span class=n>counts</span> <span class=o>=</span> <span class=n>defaultdict</span><span class=p>(</span><span class=nb>int</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>index1</span><span class=p>,</span> <span class=n>index2</span> <span class=ow>in</span> <span class=nb>zip</span><span class=p>(</span><span class=n>indices</span><span class=p>,</span> <span class=n>indices</span><span class=p>[</span><span class=mi>1</span><span class=p>:]):</span>  <span class=c1># For each adjacent pair</span>
</span></span><span class=line><span class=cl>            <span class=n>counts</span><span class=p>[(</span><span class=n>index1</span><span class=p>,</span> <span class=n>index2</span><span class=p>)]</span> <span class=o>+=</span> <span class=mi>1</span>  <span class=c1># @inspect counts</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># Find the most common pair.</span>
</span></span><span class=line><span class=cl>        <span class=n>pair</span> <span class=o>=</span> <span class=nb>max</span><span class=p>(</span><span class=n>counts</span><span class=p>,</span> <span class=n>key</span><span class=o>=</span><span class=n>counts</span><span class=o>.</span><span class=n>get</span><span class=p>)</span>  <span class=c1># @inspect pair</span>
</span></span><span class=line><span class=cl>        <span class=n>index1</span><span class=p>,</span> <span class=n>index2</span> <span class=o>=</span> <span class=n>pair</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># Merge that pair.</span>
</span></span><span class=line><span class=cl>        <span class=n>new_index</span> <span class=o>=</span> <span class=mi>256</span> <span class=o>+</span> <span class=n>i</span>  <span class=c1># @inspect new_index</span>
</span></span><span class=line><span class=cl>        <span class=n>merges</span><span class=p>[</span><span class=n>pair</span><span class=p>]</span> <span class=o>=</span> <span class=n>new_index</span>  <span class=c1># @inspect merges</span>
</span></span><span class=line><span class=cl>        <span class=n>vocab</span><span class=p>[</span><span class=n>new_index</span><span class=p>]</span> <span class=o>=</span> <span class=n>vocab</span><span class=p>[</span><span class=n>index1</span><span class=p>]</span> <span class=o>+</span> <span class=n>vocab</span><span class=p>[</span><span class=n>index2</span><span class=p>]</span>  <span class=c1># @inspect vocab</span>
</span></span><span class=line><span class=cl>        <span class=n>indices</span> <span class=o>=</span> <span class=n>merge</span><span class=p>(</span><span class=n>indices</span><span class=p>,</span> <span class=n>pair</span><span class=p>,</span> <span class=n>new_index</span><span class=p>)</span>  <span class=c1># @inspect indices</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>BPETokenizerParams</span><span class=p>(</span><span class=n>vocab</span><span class=o>=</span><span class=n>vocab</span><span class=p>,</span> <span class=n>merges</span><span class=o>=</span><span class=n>merges</span><span class=p>)</span>
</span></span></code></pre></div><p><strong>ç¤ºä¾‹</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>text</span> <span class=o>=</span> <span class=s2>&#34;the cat in the hat&#34;</span>  <span class=c1># @inspect string</span>
</span></span><span class=line><span class=cl><span class=n>params</span> <span class=o>=</span> <span class=n>train_bpe</span><span class=p>(</span><span class=n>text</span><span class=p>,</span> <span class=n>num_merges</span><span class=o>=</span><span class=mi>3</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>string</span> <span class=o>=</span> <span class=s2>&#34;the quick brown fox&#34;</span>  <span class=c1># @inspect string</span>
</span></span><span class=line><span class=cl><span class=n>tokenizer</span> <span class=o>=</span> <span class=n>BPETokenizer</span><span class=p>(</span><span class=n>params</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>indices</span> <span class=o>=</span> <span class=n>tokenizer</span><span class=o>.</span><span class=n>encode</span><span class=p>(</span><span class=n>string</span><span class=p>)</span>  <span class=c1># @inspect indices</span>
</span></span><span class=line><span class=cl><span class=n>reconstructed_string</span> <span class=o>=</span> <span class=n>tokenizer</span><span class=o>.</span><span class=n>decode</span><span class=p>(</span><span class=n>indices</span><span class=p>)</span>  <span class=c1># @inspect reconstructed_string</span>
</span></span></code></pre></div><p>ä»£ç é€»è¾‘ä¸ºï¼š</p><ol><li>åˆå§‹åŒ–è¯æ±‡è¡¨ï¼Œç”¨0-255è¡¨å¾byte</li><li>ä¾æ¬¡å¯»æ‰¾æœ€å¤šæ¬¡å‡ºç°çš„ç›¸é‚»byte<ul><li>(116, 104) &ndash;> 256 å³ (&rsquo;t&rsquo;, &lsquo;h&rsquo;) &ndash;> &rsquo;th&rsquo;</li><li>(256, 101) &ndash;> 257 å³ (&rsquo;th&rsquo;, &rsquo;e&rsquo;) &ndash;> &rsquo;the'</li><li>(257, 32) &ndash;> 258 å³ ï¼ˆ&rsquo;the&rsquo;, &rsquo; &lsquo;ï¼‰&ndash;> &rsquo;the '</li></ul></li><li>è¯æ±‡è¡¨é•¿åº¦æ›´æ–°è‡³259</li><li>ç”¨æ–°è¯æ±‡è¡¨å¯¹å­—ç¬¦ä¸²è¿›è¡Œç¼–ç </li></ol></div><footer class=post-footer><p style=font-size:medium;margin-bottom:5px;font-weight:700>categories</p><ul class=post-tags><li><a href=http://localhost:1313/cspaulia-blog/categories/large-language-model/>Large Language Model</a></li><li><a href=http://localhost:1313/cspaulia-blog/categories/nlp/>NLP</a></li></ul><p style=font-size:medium;margin-bottom:5px;font-weight:700>tags</p><ul class=post-tags><li><a href=http://localhost:1313/cspaulia-blog/tags/tokenization/>Tokenization</a></li><li><a href=http://localhost:1313/cspaulia-blog/tags/llm/>LLM</a></li></ul><nav class=paginav><a class=next href=http://localhost:1313/cspaulia-blog/posts/metric/><span class=title>Next Â»</span><br><span>è®°å½•100ç§è¯„ä»·æŒ‡æ ‡</span></a></nav><ul class=share-buttons><li><a target=_blank rel="noopener noreferrer" aria-label="share Tokenization on x" href="https://x.com/intent/tweet/?text=Tokenization&amp;url=http%3a%2f%2flocalhost%3a1313%2fcspaulia-blog%2fposts%2ftokenization%2f&amp;hashtags=Tokenization%2cLLM"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Tokenization on facebook" href="https://facebook.com/sharer/sharer.php?u=http%3a%2f%2flocalhost%3a1313%2fcspaulia-blog%2fposts%2ftokenization%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Tokenization on telegram" href="https://telegram.me/share/url?text=Tokenization&amp;url=http%3a%2f%2flocalhost%3a1313%2fcspaulia-blog%2fposts%2ftokenization%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentColor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></li></ul></footer></article></main><footer class=footer><span>&copy; 2025 <a href=http://localhost:1313/cspaulia-blog/>cspaulia-blog</a></span> Â·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>