[{"content":"一篇非常棒的博客，它总结了几种流行的大模型之间的架构差异\n1. 原始Transformer vs 现代变体 下表总结了原始Transformer（Vaswani et al., 2017）与现代大语言模型（LLM）中的主流Transformer变体在架构和训练细节上的主要区别：\n方面 原始Transformer (2017) 现代LLM中的变体 归一化顺序 后归一化（Post-LN） 前归一化（Pre-LN） 激活函数 ReLU SwiGLU（GELU、SiLU、Swish等） Dropout 广泛使用 训练大模型时常常减小或去除 归一化类型 LayerNorm RMSNorm（LayerNorm、ScaleNorm等） 线性层 添加偏置 不添加偏置 注意力头 多头注意力（固定头数） GQA、MQA等 位置编码 绝对位置编码（sinusoidal） RoPE等 其它 - FlashAttention, MoE, 分层并行等 1.1. 前归一化 vs 后归一化 几乎所有的现代语言模型均采用前归一化（除了BERT），能使训练更加稳定\n左图为前归一化（pre-norm），右图为后归一化（post-norm）\n新！：左图为前归一化（pre-norm），右图为双归一化（\u0026lsquo;double\u0026rsquo; norm，使用者包括 Grok，Gemma 2）\n新！：Olom 2 仅使用非残差部分的后归一化\n1.2. LayerNorm vs RMSNorm 原始 Transformer：LayerNorm (GPT3/2/1，OPT，GPT-J，BLOOM)\n$$ y = \\frac{x - \\textbf{E}[x]}{\\sqrt{\\textbf{Var}[x] + \\epsilon}} * \\gamma + \\beta $$\n现代语言模型：RMSNorm（LLaMA-family，PaLM，T5）\n$$ y = \\frac{x}{\\sqrt{\\lVert x \\rVert^2_2 + \\epsilon}} * \\gamma $$\nRMSNorm的优势：运行速度更快，而并不影响精度\n更少的 Operations（无需计算均值） 更少的参数（没有偏置项需要存储） 1.3. FFN：有偏置 vs 无偏置 原始 Transformer：有偏置\n$$ \\textbf{FFN}(x) = \\max(0,xW_1+b_1)W_2+b_2 $$\n现代语言模型：无偏置\n$$ \\textbf{FFN}(x) = \\sigma(xW_1)W_2 $$\n无偏置的优势：更小的存储开销以及稳定的优化\n1.4. 激活函数 Activation Model ReLU Original transformer, T5, Gopher, Chinchilla, OPT GeLU GPT1/2/3, GPTJ, GPT-Neox, BLOOM GeGLU T5 v1.1, mT5, LaMDA, Phi3, Gemma 2, Gemma 3 SwiGLU LLaMa 1/2/3, PaLM, Mistral, OlMo, most models post 2023 激活函数的介绍详见 Post\n1.5. 位置编码 1.5.1. 余弦位置编码（Sinusoidal Positional Encoding） 主要思想：用不同频率的正弦、余弦波来编码不同维度的位置信息\n对于序列中第 $pos$ 个位置、向量维度 $i$，编码方式为:\n$$ \\begin{aligned} PE_{(pos,2i)} = sin(\\frac{pos}{10000^{2i/d_{model}}}) \\ PE_{(pos,2i+1)} = cos(\\frac{pos}{10000^{2i/d_{model}}}) \\end{aligned} $$\n其中：\n$pos$ 表示位置（从0开始） $i$ 表示维度索引 $d_{model}$ 表示模型的隐藏层维度 10000 是一个经验常数，控制频率范围 相对位置的捕捉 假设模型关注两个 token：位置 $pos_1$ 和 $pos_2$ ，那他们的编码分别是：\n$$ \\begin{aligned} E_1 = [sin(\\frac{pos_1}{10000^{0}}), cos(\\frac{pos_1}{10000^{0}}), sin(\\frac{pos_1}{10000^{2/d_{model}}}), cos(\\frac{pos_1}{10000^{2/d_{model}}}), \\dots ] \\\\ E_2 = [sin(\\frac{pos_2}{10000^{0}}), cos(\\frac{pos_2}{10000^{0}}), sin(\\frac{pos_2}{10000^{2/d_{model}}}), cos(\\frac{pos_2}{10000^{2/d_{model}}}), \\dots ] \\end{aligned} $$\n我们在模型内部做如下操作：\n$$ E_1 \\cdot E_2 = sin(\\frac{pos_1}{10000^{0}})sin(\\frac{pos_2}{10000^{0}}) + cos(\\frac{pos_1}{10000^{0}})cos(\\frac{pos_2}{10000^{0}}) + \\dots $$\n利用和差化积公式：\n$$ \\sin a \\sin b + \\cos a \\cos b = \\cos(a - b) $$\n可得到：\n$$ E_1 \\cdot E_2 = \\cos(\\frac{pos_1 - pos_2}{10000^{0}}) + \\cos(\\frac{pos_1 - pos_2}{10000^{2/d_{model}}}) + \\dots $$\n即可得到两个位置的相对距离\n1.5.2. 绝对位置编码（Absolute Positional Encoding）/ 可学习位置编码（Learnable Positional Encoding） 我个人认为绝对位置编码是一种概念，它表达将 token 的位置信息直接编码，而不是将 token 之间的相对位置进行编码\n可学习式位置嵌入学习一个嵌入矩阵：\n$$ P = [u_0, u_1, u_2, \\dots, u_{L-1}] \\in \\mathbb{R}^{L \\times d_{model}} $$\n其中：\n$L$ 是最大序列长度 每一行的 $u_i$ 是位置 $i$ 的可训练嵌入向量 输入到模型的最终向量：\n$$ Embed(x, i) = v_x + u_i $$\n其中 $v_x$ 是 token $x$ 的词嵌入向量\n1.5.3. 相对位置编码（Relative Positional Encoding） 绝对位置编码的缺点：\n泛化差：训练时的序列长度是固定的，比如 512；超出这个长度就无法使用 缺乏相对感知：模型知道第 5 个词、第 10 个词，但不知道它们“相隔 5 个位置” 然而自然语言的顺序关系往往是相对的：\n“the cat” 和 “the big cat” 的依赖关系中，“cat” 距离 “the” 只有几步之差\n因此，相对位置编码的目标是：让模型直接学习 “第 i 个 token 与第 j 个 token 的距离（i−j）” 对注意力的影响\n相对位置编码通过在注意力打分中显式地加入位置差信息:\n$$ e_{ij} = \\frac{(x_i W_Q)(x_j W_K + a^K_{ij})^T}{\\sqrt{d_k}} $$\n其中 $a_{ij}^K$ 是一个向量，表示 token i 和 token j 之间的相对位置信息\n1.5.4. RoPE（Rotary Position Embedding） 我们该如何让 添加位置编码后的嵌入向量 $x$ 和 $y$ 在完成点积后，只关注它们的相对位置呢？也就是要实现如下目标：\n$$ \\langle f(x, i), f(y, j) \\rangle = g(x, y, i-j) \\tag{1} $$ 其中 $\\langle \\cdot, \\cdot \\rangle$ 表示内积运算\n余弦位置编码：不满足（1）式: 在余弦位置编码中，token 的嵌入可以表征为 $Embed(x, i) = v_x + E_i$，其中 $v_x$ 是 token 的词嵌入向量，$E_i$ 是位置编码; $\\langle Embed(x, i), Embed(y, j) \\rangle = \\langle v_x + E_i, v_y + E_j \\rangle = \\langle v_x, v_y \\rangle + \\langle v_x, E_j \\rangle + \\langle E_i, v_y \\rangle + \\langle E_i, E_j \\rangle$，有许多内积项依赖于绝对位置 $i$ 和 $j$，而不仅仅是它们的差值 $i-j$ 绝对位置编码：不满足（1）式 相对位置编码：不满足（1）式中的内积形式： 几何解释消失：原来的点积可以看成两个向量夹角的余弦相似度（几何上可解释），加入 $a_{ij}$ 后，这个解释就失效 对称性破坏：$e_{ij}$ 与 $e_{ji}$ 不再一致，使模型捕捉方向信息 注意力的归一化解释变弱：softmax 之前的 logits 不再仅由向量相似度决定，额外偏置可能干扰注意力稳定性 RoPE 的核心思想是：通过复数旋转（或二维平面旋转）把位置嵌入到每个向量维度中\n$$ \\begin{aligned} x_p \u0026amp;= [x_{p,0}, x_{p,1}, \\dots, x_{p,d-1}]\\\\ f_{{q,k}}(x_p,p) \u0026amp;= \\mathbf{R}^d_{\\Theta,p},W_{{q,k}},x_p\\\\ \\mathbf{R}^d_{\\Theta,p} \u0026amp;= \\begin{bmatrix} \\cos(p\\theta_0) \u0026amp; -\\sin(p\\theta_0) \u0026amp; \u0026amp; \u0026amp; \\\\ \\sin(p\\theta_0) \u0026amp; \\cos(p\\theta_0) \u0026amp; \u0026amp; \u0026amp; \\\\ \u0026amp; \u0026amp; \\cos(p\\theta_1) \u0026amp; -\\sin(p\\theta_1) \u0026amp; \\\\ \u0026amp; \u0026amp; \\sin(p\\theta_1) \u0026amp; \\cos(p\\theta_1) \u0026amp; \\\\ \u0026amp; \u0026amp; \u0026amp; \u0026amp; \\ddots \\\\ \u0026amp; \u0026amp; \u0026amp; \u0026amp; \u0026amp; \\cos(p\\theta_{d/2-1}) \u0026amp; -\\sin(p\\theta_{d/2-1}) \\\\ \u0026amp; \u0026amp; \u0026amp; \u0026amp; \u0026amp; \\sin(p\\theta_{d/2-1}) \u0026amp; \\cos(p\\theta_{d/2-1}) \\end{bmatrix} \\end{aligned} $$\n其中 $\\theta_k = 10000^{-2k/d}$\n接下来证明RoPE符合（1）式：\n对于 token $x$ 的两个相邻嵌入维度 $2i$ 和 $2i+1$，有：\n$$ \\tilde{x}_{p}^{(k)} = \\begin{bmatrix} cos(p\\theta_k) \u0026amp; -sin(p\\theta_k) \\\\ sin(p\\theta_k) \u0026amp; cos(p\\theta_k) \\end{bmatrix} \\begin{bmatrix} x_{p,2k} \\\\ x_{p,2k+1} \\end{bmatrix} =(x_{p,2k}+ix_{p,2k+1})e^{ip\\theta_k} $$\n因此有：\n$$ \\langle \\tilde{x}_{p}^{(k)}, \\tilde{y}_{q}^{(k)} \\rangle = \\tilde{x}_{p}^{(k)} \\cdot \\overline{\\tilde{y}}_{q}^{(k)} = (x_{p,2k}+ix_{p,2k+1})(y_{q,2k}-iy_{q,2k+1})e^{i(p-q)\\theta_k} $$\n符合（1）式中的要求\n2. 超参数 2.1. 前馈网络中的特征维度 假设 $d_{ff}$ 是前馈网络的隐藏层维度，$d_{model}$ 是模型的隐藏层维度\n$$ d_{ff} = 4d_{model} $$\n此时，标准 FFN 的参数量为：\n第一层：$d_{model} \\times d_{ff} = 4d_{model}^2$ 第二层：$d_{ff} \\times d_{model} = 4d_{model}^2$ 总计：$8d_{model}^2$ 对于包含GLU类激活函数的 FFN，参数量为：\nGLU中的content部分：$d_{model} \\times d\u0026rsquo;_{ff}$ GLU中的gate部分：$d_{model} \\times d\u0026rsquo;_{ff}$ 第二层：$d\u0026rsquo;_{ff} \\times d_{model}$ 总计：$3d_{model} \\times d\u0026rsquo;_{ff}$ 为了使包含GLU类激活函数的 FFN 与标准 FFN 的参数量相同，我们需要满足：\n$$ 3d_{model} \\times d\u0026rsquo;_{ff} = 8d_{model}^2 $$\n即\n$$ d\u0026rsquo;_{ff} = \\frac{8}{3}d_{model} $$\n下表总结了一些流行大模型中前馈网络隐藏层维度与模型隐藏层维度的比值：\nModel $( d_{ff} / d_{model} )$ PaLM 4.00 Mistral 7B 3.50 LLaMA-2 70B 3.50 LLaMA 70B 2.68 Qwen 14B 2.67 DeepSeek 67B 2.68 Yi 34B 2.85 T5 v1.1 2.50 2.2. 注意力头数与每头维度 我们尽量使得 $d_{head} \u0026gt; d_{model} / num_{heads}$，很多模型选择令 $d_{head} = d_{model} / num_{heads}$\nModel Num heads Head dim Model dim Ratio GPT3 96 128 12288 1 T5 128 128 1024 16 T5 v1.1 64 64 4096 1 LaMDA 128 128 8192 2 PaLM 48 258 18432 1.48 LLaMA2 64 128 8192 1 2.3. 模型宽高比（aspect ratio） 这里的宽高比指的是：\n$$ d_{model} / num_{layers} $$\nModel ( d_{model} / n_{layer} ) BLOOM 205 T5 v1.1 171 PaLM (540B) 156 GPT3 / OPT / Mistral / Qwen 128 LLaMA / LLaMA2 / Chinchila 102 T5 (11B) 43 GPT2 33 太深的模型很难并行化，并且具有很高的延迟\n2.4. 字典大小（vocabulary size） 单语言：3-5万个 token 多语言：10-25万个 token 2.5 Dropout 和 权重衰减（weight decay） 老模型会更多的采用Dropout； 新模型会更多的采用权重衰减，其作用更多的在于与loss的互动（后期更快的loss下降），而非防止过拟合 Model Dropout* Weight decay Original transformer 0.1 0 GPT2 0.1 0.1 T5 0.1 0 GPT3 0.1 0.1 T5 v1.1 0 0 PaLM 0 (variable) OPT 0.1 0.1 LLaMA 0 0.1 Qwen 14B 0.1 0.1 3. 模型训练稳定性技巧 模型的训练，应当避免出现“尖刺”，如下图蓝色曲线所示：\nz-loss 观察出现在 LLM 的最后一层的softmax，softmax 的定义为：\n$$ P(y=i|x) = \\frac{e^{z_i}}{\\sum_j e^{z_j}} = \\frac{e^{z_i}}{Z} $$\n因此在 Cross-Entropy Loss 中，我们有：\n$$ Loss_{CE} = -\\log P(y=i|x) = -\\log \\frac{e^{z_i}}{\\sum_j e^{z_j}} = -z_i + \\log Z $$\n当 $Z$ 为0时，会导致 $Loss_{CE}$ 过大，造成训练的不稳定\n因此我们想办法，令 $Z$ 趋近于 1，即 $\\log Z$ 趋近于 0，我们可以添加一个 z-loss 项：\n$$ Loss_{z} = ((\\log Z)^2 - 0)^2 = (\\log Z)^2 $$\n最终有：\n$$ Loss = Loss_{CE} + \\lambda Loss_{z} $$\n其中 $\\lambda$ 是一个很小的值，一般为 $1e-3$ 或 $1e-4$\n4. 模型结构优化 4.1. KV Cache 图片来源于网络\n常规的注意力计算：\n$$ Q = X W_Q, \\quad K = X W_K, \\quad V = X W_V $$\n假设 $X \\in \\mathbb{R}^{b \\times T \\times D}$，$W_{\\{Q, K, V\\}} \\in \\mathbb{R}^{D \\times (hd)}$，其中 $T$ 是序列长度，$h$ 为注意力头数，$d$ 是每个注意力头的隐藏层维度，设 $D = hd$，则计算量为\n计算KQV：$3 \\times 2bTD^2 = 6bT(hd)^2$ 计算$Q \\times K$：$2bhT^2d$ 计算softmax：$n \\times bhT^2$（softmax包含 n 次计算操作） 计算$Output_{softmax} \\times V$：$2bhT^2d$ 计算输出线性层：$2bTD^2$ 总计算量 $\\approx 8bTD^2 + 4bhT^2d$（忽略softmax） 总存储开销为\n权重参数开销： $W_{\\{Q, K, V\\}}$ 存储开销：$3 \\times D(hd) = 3(hd)^2$ 输出线性层存储开销：$(hd)D = (hd)^2$ 中间激活开销： 输入存储：$bTD$ KQV存储：$3 \\times bhTd$ softmax后得到的注意力权重存储：$bhT^2$ 输出存储：$bTD$ （即下一层的输入，不计入本层开销） 总存储开销 $\\approx 4(hd)^2 + bTD + 3bhTd + bhT^2$ 使用 KV Cache 的注意力计算：\n训练时，使用 KV Cache 并不影响计算量，因此训练时往往不使用 KV Cache；\n但在推理时，假设输入序列长度为 $t$，则预测下一个 token 时，计算量为 $\\approx 8btD^2 + 4bht^2d$，若不使用 KV Cache，则预测下下个 token 的计算量为 $\\approx 8b(t+1)D^2 + 4bh(t+1)^2d$，这个计算量会随着序列长度的增加而显著增加；\n而使用 KV Cache 后，预测下一个 token 的计算量为：\nKQV计算：由于无需重新计算$Q_{1:(t-1)}, K_{1:(t-1)}, V_{1:(t-1)}$，只需要计算$Q_{t}, K_{t}, V_{t}$，因此计算量为$3 \\times 2bD^2$ 计算$Q_{t} \\times K_{1:t}$：$2bhtd$ 计算softmax：$n \\times bht$ 计算$Output_{softmax} \\times V_{1:t}$：$2bhtd$ 计算输出线性层：$2bD^2$ 总计算量 $\\approx 8bD^2 + 4bhtd$（忽略softmax） 计算量随序列长度的增加轻微增加。\n而使用 KV Cache 后，存储开销会稍稍增加。因为在推理阶段不使用 KV Cache，总存储开销仅为权重参数开销 $4(hd)^2$，而使用 KV Cache 后，总存储开销为权重参数开销 $4(hd)^2$ 加上 KV Cache 的存储开销 $2bhtd$，因此总存储开销 $\\approx 4(hd)^2 + 2bhtd$。\n4.2. MQA 和 GQA 为了减少 KV Cache 的存储开销，一个简单的思路就是让注意力头共享 K 和 V\n若 $h$ 个注意力头共享一个 K 和 V，则为 MQA（Multi-query Attention） 若将 $h$ 个注意力头划分为 $g$ 组，每组 $h/g$ 个头共享 K 和 V，则为 GQA（Grouped-query Attention） 如下图所示：\n模型 训练时结构 推理时结构 备注 GPT-3 / GPT-4 MHA MHA / GQA（部分优化版） GPT-4 reportedly uses GQA PaLM 2 GQA GQA 原生训练结构 Claude 3 GQA GQA Anthropic 公开结构说明 LLaMA 2 MHA GQA (converted) Meta 后期转换版 Mistral GQA GQA 端到端使用 GQA Falcon MQA MQA 优化长序列推理 Gemini 1.5 GQA GQA Google 用于多模态大模型 MQA 和 GQA 与 MHA 相比，计算复杂度不变，但存储开销减少，假设 $h$ 个注意力头共享 $k$ 个 K 和 V：\n权重参数开销： $W_{\\{Q\\}}$ 存储开销：$D(hd) = (hd)^2$ $W_{\\{K, V\\}}$ 存储开销：$2 \\times D(kd) = 2(hd)(kd)$ 输出线性层存储开销：$(hd)D = (hd)^2$ 中间激活开销： 输入存储：$bTD$ Q存储：$bhTd$ KV存储：$2bkdT$ softmax后得到的注意力权重存储：$bhT^2$ 输出存储：$bTD$ （即下一层的输入，不计入本层开销） 总存储开销 $\\approx 2(hd)^2 + 2hkd^2 + 2bTD + 2bkdT + bhT^2$ 4.3. 稀疏注意力（Sparse Attention） 稀疏注意力（Sparse Attention）：可以参考博客\n参考文献 stanford-cs336 lecture 3 ","permalink":"https://cspaulia.github.io/cspaulia-blog/posts/transformer_in_llm/","summary":"\u003cp\u003e一篇非常棒的\u003ca href=\"https://magazine.sebastianraschka.com/p/the-big-llm-architecture-comparison\"\u003e博客\u003c/a\u003e，它总结了几种流行的大模型之间的架构差异\u003c/p\u003e\n\u003ch2 id=\"1-原始transformer-vs-现代变体\"\u003e1. 原始Transformer vs 现代变体\u003c/h2\u003e\n\u003cp\u003e下表总结了原始Transformer（Vaswani et al., 2017）与现代大语言模型（LLM）中的主流Transformer变体在架构和训练细节上的主要区别：\u003c/p\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003e方面\u003c/th\u003e\n          \u003cth\u003e原始Transformer (2017)\u003c/th\u003e\n          \u003cth\u003e现代LLM中的变体\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e归一化顺序\u003c/td\u003e\n          \u003ctd\u003e后归一化（Post-LN）\u003c/td\u003e\n          \u003ctd\u003e前归一化（Pre-LN）\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e激活函数\u003c/td\u003e\n          \u003ctd\u003eReLU\u003c/td\u003e\n          \u003ctd\u003eSwiGLU（GELU、SiLU、Swish等）\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eDropout\u003c/td\u003e\n          \u003ctd\u003e广泛使用\u003c/td\u003e\n          \u003ctd\u003e训练大模型时常常减小或去除\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e归一化类型\u003c/td\u003e\n          \u003ctd\u003eLayerNorm\u003c/td\u003e\n          \u003ctd\u003eRMSNorm（LayerNorm、ScaleNorm等）\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e线性层\u003c/td\u003e\n          \u003ctd\u003e添加偏置\u003c/td\u003e\n          \u003ctd\u003e不添加偏置\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e注意力头\u003c/td\u003e\n          \u003ctd\u003e多头注意力（固定头数）\u003c/td\u003e\n          \u003ctd\u003eGQA、MQA等\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e位置编码\u003c/td\u003e\n          \u003ctd\u003e绝对位置编码（sinusoidal）\u003c/td\u003e\n          \u003ctd\u003eRoPE等\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e其它\u003c/td\u003e\n          \u003ctd\u003e-\u003c/td\u003e\n          \u003ctd\u003eFlashAttention, MoE, 分层并行等\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch3 id=\"11-前归一化-vs-后归一化\"\u003e1.1. 前归一化 vs 后归一化\u003c/h3\u003e\n\u003cp\u003e几乎所有的现代语言模型均采用前归一化（除了BERT），能使训练更加稳定\u003c/p\u003e\n\u003cp\u003e左图为前归一化（pre-norm），右图为后归一化（post-norm）\u003c/p\u003e\n\u003cimg src=\"pre-post-norm.png\" alt=\"pre-vs-post\" width=\"300\"/\u003e\n\u003cp\u003e\u003cstrong\u003e新！\u003c/strong\u003e：左图为前归一化（pre-norm），右图为双归一化（\u0026lsquo;double\u0026rsquo; norm，使用者包括 Grok，Gemma 2）\u003c/p\u003e\n\u003cimg src=\"pre-post-norm.png\" alt=\"pre-vs-post\" width=\"300\"/\u003e\n\u003cp\u003e\u003cstrong\u003e新！\u003c/strong\u003e：Olom 2 仅使用非残差部分的后归一化\u003c/p\u003e\n\u003chr\u003e\n\u003ch3 id=\"12-layernorm-vs-rmsnorm\"\u003e1.2. LayerNorm vs RMSNorm\u003c/h3\u003e\n\u003cp\u003e原始 Transformer：\u003cstrong\u003eLayerNorm\u003c/strong\u003e (GPT3/2/1，OPT，GPT-J，BLOOM)\u003c/p\u003e\n\u003cp\u003e$$\ny = \\frac{x - \\textbf{E}[x]}{\\sqrt{\\textbf{Var}[x] + \\epsilon}} * \\gamma + \\beta\n$$\u003c/p\u003e","title":"LM Architecture and Training"},{"content":"1. 生成对象 1.1. 将生成对象表征为向量 图像： 尺度维度：高度 $H$ 和 宽度 $W$ 颜色维度：三维颜色通道 RGB $$ z \\in \\mathbb{R}^{H \\times W \\times 3} $$\n视频： 时间维度：时间帧 $T$ 每一帧为图像 $$ z \\in \\mathbb{R}^{T \\times H \\times W \\times 3} $$\n分子结构： N 个原子 每个原子包含三个维度 $$ z \\in \\mathbb{R}^{N \\times 3} $$\n我们可以将我们想要生成的目标表征为向量：\n$$ z \\in \\mathbb{R}^{d} $$\n1.2. 生成——从数据分布中采样 数据分布：我们想要生成的对象的分布$p_{data}$\n概率密度：$p_{data}: \\mathbb{R}^d \\to \\mathbb{R} \\ge 0, z \\mapsto p_{data}$\n⚠ 注意我们并不知道实际的概率密度 \u0026times; 生成：意味着从数据分布中进行采样 $z \\sim p_{data}$，采样 $z$ 如下：\n1.3. 数据集——由数据分布中的样本组成 数据集：数据分布中有限数量的样本的集合 $z_1, \\cdots, z_N \\sim p_{data}$\n1.4. 条件生成 条件生成：意味着从条件数据分布中进行采样 $z \\sim p_{data}(\\cdot | y)$\n2. 流与扩散模型 2.1. 流模型 2.1.1. 预备知识 轨迹（Trajectory） $X: [0, 1] \\to \\mathbb{R}^d, t \\mapsto X_t$ 向量场（Vector Feild） $u: R^d \\times [0,1] \\to \\mathbb{R}^d, (x, t) \\mapsto u_t(x)$ 其中 $x$ 表示点的位置，$u_t$ 表示向量方向 常微分方程（Ordinary Differential Equation, ODE） 初始条件 $X_0 = x_0$ 常微分方程/动力学方程 $dX_t/dt = u_t(X_t)$ $dX_t/dt$ 即为轨迹的切线，可以理解为速度，因此ODE描述了粒子在向量场中的运动\n2.1.2. 流的定义 流（Flow） $\\phi: \\mathbb{R}^d \\times [0, 1] \\to \\mathbb{R}^d, (t, x) \\mapsto \\phi_t(x)$ 其中 $\\phi_t(x)$ 表示时间 $t$ 时刻，位置为 $x$ 的粒子沿着ODE轨迹运动到的新位置 $\\phi_0(x_0) = x_0$ $\\frac{d}{dt}\\phi_t(x_0) = u_t(\\phi_t(x_0))$ 流本质是针对许多初始条件的常微分方程解的集合\nFlow 可视化：\n线性 ODE：\n一个简单的向量场： $$ u_t(x) = - \\theta x $$\n流由常微分方程定义： $$ \\frac{d}{dt} \\phi_t(x) = - \\theta \\phi_t(x) $$ $$ \\frac{d \\phi_t(x)}{\\phi_t(x)} = - \\theta dt $$ $$ \\int \\frac{d \\phi_t(x)}{\\phi_t(x)} = \\int - \\theta dt $$ $$ \\log \\phi_t(x) = - \\theta t + C(x) $$ $$ \\phi_t(x) = e^{-\\theta t + C(x)} = e^{C(x)} e^{-\\theta t} $$\n用初值条件确定常数 $C(x)$： $$ \\phi_0(x) = e^{C(x)} e^{0} = e^{C(x)} = x \\Rightarrow e^{C(x)} = x \\Rightarrow C(x) = \\log x $$\n最终流的表达式为： $$ \\phi_t(x) = x e^{-\\theta t} $$\n证明符合流的定义： $$ \\phi_0(x) = e^{C(x)} e^{0} = e^{C(x)} = x \\Rightarrow e^{C(x)} = x $$ $$ \\frac{d}{dt} \\phi_t(x) = \\frac{d}{dt} (x e^{-\\theta t}) = -\\theta x e^{-\\theta t} = -\\theta \\phi_t(x) $$\n算法 1 利用欧拉方法求解 ODE 输入: 向量场 $u_t$，初始位置 $x_0$，时间步长 $n$ 1: 设 $t =0$ 2: 设步大小 $h = 1/n$ 3: 设 $X_0 = x_0$ 4: for $i = 0$ to $n-1$ do 5: $~~~~$令 $X_{t+h} = X_t + h \\cdot u_{t}(X_t)$ 6: $~~~~$令 $t = t + h$ 7: end for 输出: $X_0, X_h, X_{2h}, \\cdots, X_1$ 2.1.3. 流模型的定义 $p_{init} \\xrightarrow{ODE} p_{data}$\n神经网络 $u_t^{\\theta}: \\mathbb{R}^d \\times [0,1] \\to \\mathbb{R}^d$ 其中 $\\theta$ 代表参数 随机初始采样： $X_0 \\sim p_{init}$ 模拟 ODE： $X_t = u_t^{\\theta}(X_t)$ 目标： $X_1 \\sim p_{data}$ 算法 1 利用欧拉方法从流模型中采样 输入: 神经网络向量场$u_t^{\\theta}$，时间步长 $n$ 1: 设 $t =0$ 2: 设步大小 $h = 1/n$ 3: 完成一次采样 $X_0 \\sim p_{init}$ 4: for $i = 0$ to $n-1$ do 5: $~~~~$令 $X_{t+h} = X_t + h \\cdot u_{t}^{\\theta}(X_t)$ 6: $~~~~$令 $t = t + h$ 7: end for 输出: $X_1$ 2.2. 扩散模型 随机过程 随机变量 $X_t, 0 \\leq t \\leq 1$ 随机轨迹 $X: [0, 1] \\to \\mathbb{R}^d, t \\mapsto X_t$ 向量场 $u: R^d \\times [0,1] \\to \\mathbb{R}^d, (x, t) \\mapsto u_t(x)$ 扩散系数 $\\sigma: [0,1] \\to \\mathbb{R}, t \\mapsto \\sigma_t$ 随机微分方程（Stochastic Differential Equation, SDE） 初始条件 $X_0 = x_0$ 随机微分方程/动力学方程 $dX_t = u_t(X_t)dt + \\sigma_t dW_t$ 其中 $u_t(X_t)dt$ 是 ODE，$\\sigma_t dW_t$ 是随机性部分(噪声)，$W_t$ 是标准布朗运动（维纳过程）。 2.2.1. 布朗运动 随机过程：\n$W_0 = 0$ 高斯增量：对于任意 $0 \\leq s \u0026lt; t \\leq 1$，$W_t - W_s \\sim \\mathcal{N}(0, (t-s)I_d)$ 独立增量：对于任意 $0 \\leq t_0 \u0026lt; t_1 \u0026lt; \\cdots \u0026lt; t_n \\leq 1$，增量 $W_{t_1} - W_{t_0}, W_{t_2} - W_{t_1}, \\cdots, W_{t_n} - W_{t_{n-1}}$ 相互独立 2.2.2. X_t 的解析 ODE 中的 $X_t$ 可解析为：\n$$ \\frac{d}{dt} X_t = u_t(X_t) \\longleftrightarrow X_{t+h} = X_t + h \\cdot u_t(X_t) + h \\cdot R_t(h) $$\n其中 $\\lim_{h \\to 0} R_t(h) = 0$，$h \\cdot R_t(h)$ 是高阶无穷小，有时记作 $o(h)$。右边的式子可视作泰勒展开。\n推导过程： $$ \\frac{d}{dt} X_t = u_t(X_t) $$ $$ \\lim_{h \\to 0} \\frac{X_{t+h} - X_t}{h} = u_t(X_t) $$ $$ \\frac{X_{t+h} - X_t}{h} = u_t(X_t) + R_t(h) $$ $$ X_{t+h} = X_t + h \\cdot u_t(X_t) + h \\cdot R_t(h) $$\nSDE 中的 $X_t$ 可解析为：\n$$ dX_t = u_t(X_t)dt + \\sigma_t dW_t \\longleftrightarrow X_{t+h} = X_t + h \\cdot u_t(X_t) + \\sigma_t (W_{t+h} - W_t) + h \\cdot R_t(h), $$\n其中 $\\lim_{h \\to 0} \\sqrt{E[|R_t(h)|^2]} = 0$。由于布朗运动不可导，SDE 的展开余项通常用均方收敛（$L^2$）来定义。$W_{t+h} - W_t \\sim \\mathcal{N}(0, hI_d)$，因此可将其写为 $\\sqrt{h} \\cdot \\epsilon$，其中 $\\epsilon \\sim \\mathcal{N}(0, I_d)$。\n算法 2 利用欧拉-马里亚玛方法从扩散模型中采样，模拟 SDE 输入: 向量场$u_t$，扩散系数 $\\sigma_t$，时间步长 $n$ 1: 设 $t =0$ 2: 设步大小 $h = 1/n$ 3：设 $X_0 = x_0$ 4: for $i = 0$ to $n-1$ do 5: $~~~~$完成一次采样 $\\epsilon \\in \\mathcal{N}(0, I_d)$ 6: $~~~~$令 $X_{t+h} = X_t + h \\cdot u_{t}(X_t) + \\sigma_t \\sqrt{h} \\cdot \\epsilon$ 7: $~~~~$令 $t = t + h$ 8: end for 输出: $X_0, X_h, X_{2h}, \\cdots, X_1$ 2.2.3. 扩散模型的定义 $p_{init} \\xrightarrow{SDE} p_{data}$\n神经网络 $u_t^{\\theta}: \\mathbb{R}^d \\times [0,1] \\to \\mathbb{R}^d$ 其中 $\\theta$ 代表参数 扩散系数 $\\sigma_t$ （通常是固定的） 随机初始采样： $X_0 \\sim p_{init}$ 模拟 SDE： $dX_t = u_t^{\\theta}(X_t)dt + \\sigma_t dW_t$ 目标： $X_1 \\sim p_{data}$ ","permalink":"https://cspaulia.github.io/cspaulia-blog/posts/flow/","summary":"\u003ch2 id=\"1-生成对象\"\u003e1. 生成对象\u003c/h2\u003e\n\u003ch3 id=\"11-将生成对象表征为向量\"\u003e1.1. 将生成对象表征为向量\u003c/h3\u003e\n\u003col\u003e\n\u003cli\u003e图像：\n\u003cul\u003e\n\u003cli\u003e尺度维度：高度 $H$ 和 宽度 $W$\u003c/li\u003e\n\u003cli\u003e颜色维度：三维颜色通道 RGB\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e$$\nz \\in \\mathbb{R}^{H \\times W \\times 3}\n$$\u003c/p\u003e\n\u003col start=\"2\"\u003e\n\u003cli\u003e视频：\n\u003cul\u003e\n\u003cli\u003e时间维度：时间帧 $T$\u003c/li\u003e\n\u003cli\u003e每一帧为图像\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e$$\nz \\in \\mathbb{R}^{T \\times H \\times W \\times 3}\n$$\u003c/p\u003e\n\u003col start=\"3\"\u003e\n\u003cli\u003e分子结构：\n\u003cul\u003e\n\u003cli\u003eN 个原子\u003c/li\u003e\n\u003cli\u003e每个原子包含三个维度\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e$$\nz \\in \\mathbb{R}^{N \\times 3}\n$$\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e我们可以将我们想要生成的目标表征为向量：\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e$$\nz \\in \\mathbb{R}^{d}\n$$\u003c/p\u003e\n\u003chr\u003e\n\u003ch3 id=\"12-生成从数据分布中采样\"\u003e1.2. 生成——从数据分布中采样\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e数据分布\u003c/strong\u003e：我们想要生成的对象的分布$p_{data}$\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e概率密度\u003c/strong\u003e：$p_{data}: \\mathbb{R}^d \\to \\mathbb{R} \\ge 0, z \\mapsto p_{data}$\u003c/p\u003e\n\u003cdiv class=\"alert alert-warning\"\u003e\n    \u003cdiv class=\"alert-icon\"\u003e⚠\u003c/div\u003e\n    \u003cdiv class=\"alert-content\"\u003e\u003cdiv class=\"alert-title\"\u003e注意\u003c/div\u003e\u003cdiv class=\"alert-message\"\u003e我们并不知道实际的概率密度\u003c/div\u003e\n    \u003c/div\u003e\u003cbutton class=\"alert-close\" onclick=\"closeAlert(this)\"\u003e\u0026times;\u003c/button\u003e\u003c/div\u003e\n\u003cp\u003e\u003cstrong\u003e生成\u003c/strong\u003e：意味着从数据分布中进行采样 $z \\sim p_{data}$，采样 $z$ 如下：\u003c/p\u003e","title":"流匹配与扩散模型"},{"content":"1. Post Training 三阶段 来源于 InstructGPT[1]\n收集数据并训练监督策略 从提示词数据集中采样一个提示词 标注者对数据进行标注（该标注即为期望输出） 该标注数据用于对 LLM 进行监督训练 收集对比数据并训练奖励模型 采样一个提示词及多个模型的输出 标注者从“最好”到“最差”对这些输出进行排序 该标注数据用于对奖励模型进行训练 在训练好的奖励模型的加持下利用强化学习优化策略 从数据集中采用一个新的提示词 利用策略生成一个输出 奖励模型计算输出的奖励分数（Reward） 根据奖励分数利用 PPO 等强化学习方法对策略进行更新 2. SFT 数据集的构建 2.1. 数据集中的问题 来自 FLAN 数据集的一个例子:\nWhat is this text about? OPTIONS: - World - Sport - Business - Science/Tech\n自然的对话一般不包含这样的选项 来自 OpenAssistant 的例子:\nQuestion: Can you write a short introduction about the relevance of the term\u0026quot;monopsony\u0026quot; in economics? Please use examples related to potential monopsonies in the labour market and cite relevant research.\nAnswer: \u0026ldquo;Monopsony\u0026rdquo; refers to a market structure where there is only one buyer for a particular good or service. In economics, this term is particularly relevant in the labor market, where a monopsony employer has significant power over the wages and working conditions of their employees. [\u0026hellip;]. Overall, the concept of monopsony is essential to understanding the dynamics of labor markets and the impact of market power on workers. Further research is needed to understand the extent and impact of monopsonies on the economy and to develop policies to address this issue. References: Bivens, J., \u0026amp; Mishel, L.(2013). The Pay of Corporate Executives and Financial Professionals as Evidence of Rents in Top 1 Percent Incomes. Journal of Economic Perspectives, 27(3), 57-78.\n人类标注者很难撰写如此长而详细的答案 输出中的符号（甚至风格）如何抉择 是否输出参考文献 如何输出准确的参考文献：我们往往希望模型能够输出更加严谨、学术的输出，因此我们会在数据集的回答中加入参考文献，但是模型可能只学到了“输出内容要加上参考文献”，这会导致模型产生幻觉（Hallucination） 是否输出复杂的知识 数据集的规模大小 数据集的安全问题 如何决定模型输出的长短：通过下图你可以发现，不同指令数据的输入和输出长度区别是很大的 2.2. SFT 数据集构建经验 SFT 在模型已经具备某些能力的前提下，通过数据来“抽取”这些能力的表现效果最好；但如果试图用 SFT 去“添加”模型原本不具备的新行为，往往效果不佳 并不是所有事实正确的数据都会提升模型表现，有时即使是高质量的事实数据，也可能干扰模型已有的分布或对齐，反而让性能下降 某些类型的数据（例如安全性、遵循指令、风格等）哪怕只有少量，也能对模型带来巨大提升，不过，模型的长尾行为（覆盖面广、稀疏分布的场景）则更依赖于大量数据来改善 2.3. 在预训练中使用指令微调（Instruction Tuning） 在网页或预训练数据集上进行预训练 将指令微调数据混入预训练中 额外进行一个简短的指令微调 2.4. \u0026lsquo;Midtraining\u0026rsquo; / \u0026lsquo;Two-phase Training\u0026rsquo; 这种方案[2]好似已被大部分 LLM 公司采纳（但没有详细的文档）：\n在 Stable 阶段采用纯预训练数据集训练（如上图左侧所示）； 在 Decay 阶段采用预训练+指令微调混合数据集进行训练（如上图右侧所示） 3. RLHF（Reinforcement Learning with Human Feedback） 3.1. 从模仿（Imitation）到优化（optimization） 模仿（Imitation，即SFT）：根据一些参考分布 $p^*(y|x)$ 调整模型的输出分布，使得输出分布 $\\hat{p}(y|x) \\approx p^*(y|x)$\n从纯生成建模的角度看，SFT 就是让生成模型学会模仿参考分布 训练需要来自参考策略的数据（比如人工标注的数据集），否则无法“模仿” 优化（Optimization，即RLHF）：不断调整输出分布$\\hat{p}(y|x)$，使得 $\\max\\limits_{p} E_p[R(y,x)]$，其中 $R(y,x)$ 为奖励（Reward）\n优化的不是抽象的“真实分布”，而是一个我们能定义并测量的奖励函数（在 RLHF 里，这个奖励函数来自人类反馈，比如人类排序、偏好比较，或者训练出的 reward model） 在这个阶段，我们不再把语言模型看作“近似真实分布$p^*(y|x)$的模型”（像 SFT 那样），而是把它当作一个 策略 policy，用来最大化奖励信号 3.2. 需要RLHF的原因 成本：SFT 的成本非常高昂，尤其是标注成本 G-V Gap (Generation-Value Gap)：人们写的内容（生成分布 G）和 人们实际偏好的内容（价值模型 V 的视角）并不总是一致 在一项过去的实验[3]中发现，一些标注者在对比自己写的摘要和模型写的摘要时，有时会更喜欢模型写的摘要，也就是说人类标注并不是最优的\n3.3. 如何获得RLHF的数据 方案一：（在网页上）让模型输出 N 个结果，让标注者（用户）对结果进行排序\n存在的问题： 标注结果可能是低质量的、不正确的，甚至是用大预言模型生成的，这取决于标注者本身 RLHF 标注者的分布会极大的影响模型的行为 如果标注者中亚洲人多，则模型会倾向于输出亚洲风格的结果\n不同的标注者关注点不同 有些标注者更关注格式，有些标注者更关注内容\n方案二：使用大语言模型（如GPT-4）对模型（可以是多个不同的模型）输出的 N 个结果进行排序，我们常常称之为 AI Feedback\n3.4. 实现RLHF的方法 3.4.1. 人类反馈下的PPO（PPO with Human Feedback） 原始的PPO算法 = Policy Gradient + Off Policy，其优化目标为：\n$$ \\max L^{CLIP}(\\theta) - \\beta KL[\\pi_\\theta||\\pi_{old}] $$\n其中$L^{CLIP}(\\theta) = \\mathbb{E}_t \\Big[ \\min \\big( r_t(\\theta) \\hat{A}_t,; \\text{clip}(r_t(\\theta), 1-\\epsilon, 1+\\epsilon)\\hat{A}_t \\big) \\Big]$，\n其中$r_t(\\theta) = \\frac{\\pi_\\theta(a_t \\mid s_t)}{\\pi_{\\theta_{\\text{old}}}(a_t \\mid s_t)}$，\n人类反馈下的PPO的优化目标为：\n$$ L^{RLHF}(\\theta) = \\mathbb{E}_{x \\sim D, y \\sim \\pi} [ r(x,y) ] - \\beta D_{KL} \\left[ \\pi(y|x) || \\pi_{\\text{ref}}(y|x) \\right] $$\n其中，\n$r(x,y)$：是奖励模型对输出$y$在输入$x$下的奖励评分 $\\pi(y∣x)$：是当前训练的策略（即RLHF中训练的模型），表示在输入$x$下生成$y$的概率分布 $\\pi_{\\text{ref}}(y∣x)$：是参考策略，通常是一个冻结的 SFT 模型，用于对比当前模型的生成结果，保证不会过度偏离基准模型 $D_{KL} \\left[ \\pi(y|x) || \\pi_{\\text{ref}}(y|x) \\right]$：是当前策略与参考策略之间的 KL 散度，用于约束新策略不能偏离参考策略太远 问题一：为什么传统PPO中优化$\\mathbb{E}_t [r_t(\\theta) \\hat{A}_t]$，而RLHF优化$\\mathbb{E}_{x, y} [ r(x,y) ]$？\n在传统的强化学习任务中，我们往往会从离线策略中获得优势函数$\\hat{A}_t$，因此优化目标为$\\max \\mathbb{E}_t [r_t(\\theta) \\hat{A}_t]$ 在LLM基于人类反馈的强化学习任务，我们选择利用奖励模型（Reward model）直接对在线的LLM的输出进行打分，因此无需使用$r_t(\\theta)$进行重要性采样修正 问题二：传统PPO中的$\\pi_{old}$和RLHF PPO中的$\\pi_{\\text{ref}}$有什么区别？\n$\\pi_{old}$：上一次迭代的策略，用于收集数据和做重要性采样，会不断更新，通常就是“前一版策略” $\\pi_{\\text{ref}}$：一个固定的参考策略，一般是 SFT（监督微调模型），也就是在 RLHF 训练前冻结的模型，不会更新 3.4.2. DPO DPO训练目标与PPO一致：\n$$ \\max L^{RLHF}(\\theta) = \\mathbb{E}_{x \\sim D, y \\sim \\pi} [ r(x,y) ] - \\beta D_{KL} \\left[ \\pi(y|x) || \\pi_{\\text{ref}}(y|x) \\right] $$\n由该优化目标可得最优Policy为：\n$$ \\pi(y|x) = \\frac{1}{Z(x)}\\pi_{\\text{ref}}(y|x)\\exp(\\frac{1}{\\beta}r(x,y)) $$\n其中，$Z(x) = \\sum\\limits_y \\pi_{\\text{ref}}(y|x)\\exp(\\frac{1}{\\beta}r(x,y))$\n点击展开公式推导 $$ \\begin{align} \u0026amp;\\max\\limits_\\pi \\mathbb{E}_{x \\sim D, y \\sim \\pi} [ r(x,y) ] - \\beta D_{KL} \\left[ \\pi(y|x) || \\pi_{\\text{ref}}(y|x) \\right] \\\\ = \u0026amp;\\max\\limits_\\pi \\mathbb{E}_{x \\sim D, y \\sim \\pi} [ r(x,y) ] - \\mathbb{E}_{x \\sim D, y \\sim \\pi} [ \\beta \\log \\frac{\\pi(y|x)}{\\pi_{\\text{ref}}(y|x)} ] \\\\ = \u0026amp;\\max\\limits_\\pi \\mathbb{E}_{x \\sim D, y \\sim \\pi} [ r(x,y) - \\beta \\log \\frac{\\pi(y|x)}{\\pi_{\\text{ref}}(y|x)} ] \\\\ = \u0026amp;\\min\\limits_\\pi \\mathbb{E}_{x \\sim D, y \\sim \\pi} [ \\beta \\log \\frac{\\pi(y|x)}{\\pi_{\\text{ref}}(y|x)} - r(x,y) ] \\\\ = \u0026amp;\\min\\limits_\\pi \\mathbb{E}_{x \\sim D, y \\sim \\pi} [ \\log \\frac{\\pi(y|x)}{\\pi_{\\text{ref}}(y|x)} - \\log \\exp(\\frac{1}{\\beta}r(x,y)) ] \\\\ = \u0026amp;\\min\\limits_\\pi \\mathbb{E}_{x \\sim D, y \\sim \\pi} [ \\log \\frac{\\pi(y|x)}{\\pi_{\\text{ref}}(y|x)\\exp(\\frac{1}{\\beta}r(x,y))}] \\\\ = \u0026amp;\\min\\limits_\\pi \\mathbb{E}_{x \\sim D, y \\sim \\pi} [ \\log \\frac{\\pi(y|x)}{\\pi_{\\text{ref}}(y|x)\\exp(\\frac{1}{\\beta}r(x,y))\\frac{1}{Z(x)} Z(x)}] \\\\ = \u0026amp;\\min\\limits_\\pi \\mathbb{E}_{x \\sim D, y \\sim \\pi} [ \\log \\frac{\\pi(y|x)}{\\frac{1}{Z(x)}\\pi_{\\text{ref}}(y|x)\\exp(\\frac{1}{\\beta}r(x,y))} - \\log Z(x)] \\\\ \\end{align} $$\n其中$Z(x) = \\sum\\limits_y \\pi_{\\text{ref}}(y|x)\\exp(\\frac{1}{\\beta}r(x,y))$，\n令$\\pi^\\star(y|x) = \\frac{1}{Z(x)}\\pi_{\\text{ref}}(y|x)\\exp(\\frac{1}{\\beta}r(x,y)) = \\frac{\\pi_{\\text{ref}}(y|x)\\exp(\\frac{1}{\\beta}r(x,y))}{\\sum\\limits_y \\pi_{\\text{ref}}(y|x)\\exp(\\frac{1}{\\beta}r(x,y))}$，则有\n$$ \\begin{align} \u0026amp;\\min\\limits_\\pi \\mathbb{E}_{x \\sim D, y \\sim \\pi} [ \\log \\frac{\\pi(y|x)}{\\frac{1}{Z(x)}\\pi_{\\text{ref}}(y|x)\\exp(\\frac{1}{\\beta}r(x,y))} - \\log Z(x)] \\\\ = \u0026amp;\\min\\limits_\\pi \\mathbb{E}_{x \\sim D, y \\sim \\pi} [ \\log \\frac{\\pi(y|x)}{\\pi^\\star(y|x)} - \\log Z(x)] \\\\ = \u0026amp;\\min\\limits_\\pi \\mathbb{E}_{x \\sim D, y \\sim \\pi} [ \\log \\frac{\\pi(y|x)}{\\pi^\\star(y|x)}] \\\\ = \u0026amp;\\min\\limits_\\pi \\mathbb{E}_{x \\sim D, y \\sim \\pi} [D_{KL} (\\pi(y|x) || \\pi^\\star(y|x))] \\\\ \\end{align} $$\n最优解为$\\pi(y|x) = \\pi^\\star(y|x) = \\frac{1}{Z(x)}\\pi_{\\text{ref}}(y|x)\\exp(\\frac{1}{\\beta}r(x,y))$\n将最优policy带入Bradley-Terry模型建模的最大似然估计中，即可得到DPO损失函数为：\n$$ Loss_{DPO} = - \\ln \\sigma \\left( \\beta \\ln \\frac{\\pi(y^+ \\mid x)}{\\pi_{ref}(y^+ \\mid x)} - \\beta \\ln \\frac{\\pi(y^- \\mid x)}{\\pi_{ref}(y^- \\mid x)} \\right) $$\n其中$y^+$：是 人类偏好（或高质量的生成样本），是被标注为“更优”的样本，$y^-$：是 负偏好（或低质量的生成样本），是被标注为“较差”的样本\n点击展开Bradley-Terry模型简介 Bradley-Terry模型：\n$$ P(i\u0026gt;j) = \\frac{\\alpha_i}{\\alpha_i + \\alpha_j} $$\n$P(i\u0026gt;j)$表示第$i$个元素战胜第$j$个元素的概率，一般的loss函数为\n$$ Loss = -\\mathbb{E}_{(\\alpha_x, \\alpha_y) \\sim D} [ \\ln \\frac{\\alpha_i}{\\alpha_i + \\alpha_j}] $$\n大模型中的Bradley-Terry模型：\n$$ P(y_1\u0026gt;y_2) = \\frac{r(x,y_1)}{r(x,y_1) + r(x,y_2)} $$\n其中$x$为输入的prompt，$y$为输出，$r(x,y)$为奖励得分，为防止$r(x,y)$为负数，加入指数函数：\n$$ P(y_1\u0026gt;y_2) = \\frac{\\exp(r(x,y_1))}{\\exp(r(x,y_1)) + \\exp(r(x,y_2))} $$\n其Loss为\n$$ \\begin{align} \\text{Loss} \u0026amp;= - \\mathbb{E}_{(x, y^+, y^-) \\sim D} [ \\ln ( \\frac{\\exp(r(x, y^+))}{\\exp(r(x, y^+)) + \\exp(r(x, y^-))} ) ] \\\\ \u0026amp;= - \\mathbb{E}_{(x, y^+, y^-) \\sim D} [ \\ln ( \\frac{1}{1 + \\exp(r(x, y^-)) - r(x, y^+)} ) ] \\\\ \u0026amp;= - \\mathbb{E}_{(x, y^+, y^-) \\sim D} [ \\ln \\sigma ( r(x, y^+) - r(x, y^-) ) ] \\end{align} $$\n其中$\\sigma (x) = \\frac{1}{1+\\exp(-x)}$为sigmoid函数\n点击展开公式推导 $$ \\begin{align} \u0026amp;\\pi(y \\mid x) = \\frac{1}{Z(x)} \\pi_{ref}(y \\mid x) \\exp( \\frac{1}{\\beta} r(x, y)) \\\\ \\Rightarrow \u0026amp;\\exp( \\frac{1}{\\beta} r(x, y) ) = \\frac{\\pi(y \\mid x)}{\\pi_{ref}(y \\mid x)} Z(x) \\\\ \\Rightarrow \u0026amp;r(x, y) = \\beta \\ln ( \\frac{\\pi(y \\mid x)}{\\pi_{ref}(y \\mid x)} Z(x) ) \\\\ \\Rightarrow \u0026amp;r(x, y) = \\beta \\ln ( \\frac{\\pi(y \\mid x)}{\\pi_{ref}(y \\mid x)} ) + \\beta \\ln Z(x) \\\\ \\end{align} $$\n将奖励评分送入Bradley-Terry模型得到：\n$$ \\begin{align} Loss \u0026amp; = - \\ln \\sigma ( r(x, y^+) - r(x, y^-) ) \\\\ \u0026amp; = - \\ln \\sigma (\\beta \\ln ( \\frac{\\pi(y^+ \\mid x)}{\\pi_{ref}(y^+ \\mid x)} ) + \\beta \\ln Z(x) - \\beta \\ln ( \\frac{\\pi(y^- \\mid x)}{\\pi_{ref}(y^- \\mid x)} ) - \\beta \\ln Z(x)) \\\\ \u0026amp; = - \\ln \\sigma (\\beta \\ln ( \\frac{\\pi(y^+ \\mid x)}{\\pi_{ref}(y^+ \\mid x)} ) - \\beta \\ln ( \\frac{\\pi(y^- \\mid x)}{\\pi_{ref}(y^- \\mid x)} )) \\end{align} $$\n参考文献 Ouyang L, Wu J, Jiang X, et al. Training language models to follow instructions with human feedback[J]. Advances in neural information processing systems, 2022, 35: 27730-27744. Hu S, Tu Y, Han X, et al. Minicpm: Unveiling the potential of small language models with scalable training strategies[J]. arXiv preprint arXiv:2404.06395, 2024. Zhang T, Ladhak F, Durmus E, et al. Benchmarking large language models for news summarization[J]. Transactions of the Association for Computational Linguistics, 2024, 12: 39-57. stanford-cs336 lecture 15 ","permalink":"https://cspaulia.github.io/cspaulia-blog/posts/sft_rlhf/","summary":"\u003ch2 id=\"1-post-training-三阶段\"\u003e1. Post Training 三阶段\u003c/h2\u003e\n\u003cblockquote\u003e\n\u003cp\u003e来源于 InstructGPT\u003ca href=\"#ref1\"\u003e[1]\u003c/a\u003e\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e\u003cimg alt=\"stages\" loading=\"lazy\" src=\"/cspaulia-blog/posts/sft_rlhf/stage.png\"\u003e\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e收集数据并训练\u003cstrong\u003e监督\u003c/strong\u003e策略\n\u003cul\u003e\n\u003cli\u003e从提示词数据集中采样一个提示词\u003c/li\u003e\n\u003cli\u003e标注者对数据进行标注（该标注即为期望输出）\u003c/li\u003e\n\u003cli\u003e该标注数据用于对 LLM 进行监督训练\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e收集\u003cstrong\u003e对比数据\u003c/strong\u003e并训练\u003cstrong\u003e奖励模型\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003e采样一个提示词及多个模型的输出\u003c/li\u003e\n\u003cli\u003e标注者从“最好”到“最差”对这些输出进行排序\u003c/li\u003e\n\u003cli\u003e该标注数据用于对奖励模型进行训练\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e在\u003cstrong\u003e训练好的奖励模型\u003c/strong\u003e的加持下利用\u003cstrong\u003e强化学习\u003c/strong\u003e优化策略\n\u003cul\u003e\n\u003cli\u003e从数据集中采用一个新的提示词\u003c/li\u003e\n\u003cli\u003e利用策略生成一个输出\u003c/li\u003e\n\u003cli\u003e奖励模型计算输出的奖励分数（Reward）\u003c/li\u003e\n\u003cli\u003e根据奖励分数利用 PPO 等强化学习方法对策略进行更新\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003chr\u003e\n\u003ch2 id=\"2-sft-数据集的构建\"\u003e2. SFT 数据集的构建\u003c/h2\u003e\n\u003ch3 id=\"21-数据集中的问题\"\u003e2.1. 数据集中的问题\u003c/h3\u003e\n\u003cblockquote\u003e\n\u003cp\u003e来自 FLAN 数据集的一个例子:\u003c/p\u003e\n\u003cp\u003eWhat is this text about? OPTIONS: - World - Sport - Business - Science/Tech\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cul\u003e\n\u003cli\u003e自然的对话一般不包含这样的选项\u003c/li\u003e\n\u003c/ul\u003e\n\u003cblockquote\u003e\n\u003cp\u003e来自 OpenAssistant 的例子:\u003c/p\u003e\n\u003cp\u003eQuestion: Can you write a short introduction about the relevance of the term\u0026quot;monopsony\u0026quot; in economics? Please use examples related to potential monopsonies in the labour market and cite relevant research.\u003c/p\u003e","title":"SFT and RLHF"},{"content":"深度学习主要资源 内存（GB）：存储参数、梯度、优化器状态、激活值等。 计算量（FLOPs）：浮点运算次数，衡量训练所需的计算资源。 1. 张量基础与内存管理 1.1. 张量的创建与存储 张量是存储参数、梯度、优化器状态、数据、激活值的基本单元 PyTorch 支持多种方式创建张量（如 torch.zeros、torch.ones、torch.randn 等） x = torch.tensor([[1., 2, 3], [4, 5, 6]]) # @inspect x x = torch.zeros(4, 8) # 4x8 matrix of all zeros @inspect x x = torch.ones(4, 8) # 4x8 matrix of all ones @inspect x x = torch.randn(4, 8) # 4x8 matrix of iid Normal(0, 1) samples @inspect x 你也可以先分配空间，再分配数值 x = torch.empty(4, 8) # 4x8 matrix of uninitialized values @inspect x nn.init.trunc_normal_(x, mean=0, std=1, a=-2, b=2) # @inspect x 张量的内存由元素数量和数据类型共同决定 1.2. 常见数据类型 参数、梯度、激活以及优化状态几乎均存储为浮点数\n1.2.1 float32（单精度） 默认类型，4 字节，动态范围大。\n内存是由(i)数值的数量和(ii)数值的类型决定的\nx = torch.zeros(4, 8) # @inspect x assert x.dtype == torch.float32 # Default type assert x.numel() == 4 * 8 assert x.element_size() == 4 # Float is 4 bytes assert get_memory_usage(x) == 4 * 8 * 4 # 128 bytes 1.2.2 float16（半精度） 2 字节，节省内存但动态范围小，易下溢\nx = torch.zeros(4, 8, dtype=torch.float16) # @inspect x assert x.element_size() == 2 # Float is 2 bytes 动态范围不佳（易下溢）\nx = torch.tensor([1e-8], dtype=torch.float16) # @inspect x assert x == 0 # Underflow! 1.2.3 bfloat16 2 字节，动态范围与 float32 相同，精度略低\n不易下溢：\nx = torch.tensor([1e-8], dtype=torch.bfloat16) # @inspect x assert x != 0 # No underflow! 不同数据类型的动态范围以及内存使用的比较:\nfloat32_info = torch.finfo(torch.float32) # @inspect float32_info float16_info = torch.finfo(torch.float16) # @inspect float16_info bfloat16_info = torch.finfo(torch.bfloat16) # @inspect bfloat16_info 输出：\nfloat32 info=\u0026#34;finfo(resolution=1e-06,min=-3.40282e+38,max=3.40282e+38, eps=1.19209e-07,smallest normal=1.17549e-38,tiny=1.17549e-38dtype=float32)\u0026#34; float1l6 info=\u0026#34;finfo(resolution=0.001,min=-65504,max=65504, eps=0.000976562,sma1lest norma1=6.10352e-05,tiny=6.10352e-05,dtype=float16)\u0026#34; bfloat16 info=\u0026#34;finfo(resolution=0.01, min=-3.38953e+38,max=3.38953e+38, eps=0.0078125,smallest normal=1.17549e38, tiny=1.17549e-38,dtype=bfloat16)\u0026#34; 1.2.4 fp8 FP8使用文档\n1 字节，极致压缩，适合新一代硬件（如 H100）\nH100s支持两种类型的FP8: E4M3 (range [-448, 448]) and E5M2 ([-57344, 57344])\n1.2.5 混合精度训练 TODO: 更新混合精度训练\n使用不同的数据类型是有一定的代价的：\n高精度：更准确和稳定，但是需要更多内存和更多计算力 低精度：不准确也不稳定，但是内存和算力需求减小 一种混合精度训练方法：\n前向传播（激活过程）时使用 bfloat16, fp8 对参数和梯度使用 float32 混合精度训练论文/混合精度训练pytorch文档/混合精度训练nvidia文档\n2. 计算资源 2.1. 张量操作 2.1.1. 存储与视图 张量是内存指针+元数据（描述如何从张量中获取数据，如步幅 stride） pytorch中对stride的定义\n对于一个张量：\nx = torch.tensor([ [0., 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], ]) 为了获取张量的下一行（dim 0），需跳过存储中的4个元素\nassert x.stride(0) == 4 为了获取张量的下一列（dim 1），需跳过存储中的1个元素\nassert x.stride(1) == 1 通过步幅寻找张量中的元素\nr, c = 1, 2 index = r * x.stride(0) + c * x.stride(1) # @inspect index assert index == 6 2.1.2. 张量切片 许多张量操作仅仅提供了一个张量的不同视图（view），它们往往不进行复制（copy）操作，这使得在某个张量上进行操作会影响其他张量\nx = torch.tensor([[1., 2, 3], [4, 5, 6]]) # @inspect x 操作一 获得 row 0\ndef same_storage(x: torch.Tensor, y: torch.Tensor): return x.untyped_storage().data_ptr() == y.untyped_storage().data_ptr() y = x[0] # @inspect y assert torch.equal(y, torch.tensor([1., 2, 3])) assert same_storage(x, y) 操作二 获得 column 1\ny = x[:, 1] # @inspect y assert torch.equal(y, torch.tensor([2, 5])) assert same_storage(x, y) 操作三 将 2x3 矩阵转换为 3x2 矩阵（view）\ny = x.view(3, 2) # @inspect y assert torch.equal(y, torch.tensor([[1, 2], [3, 4], [5, 6]])) assert same_storage(x, y) 操作四 转置矩阵（transpose）\ny = x.transpose(1, 0) # @inspect y assert torch.equal(y, torch.tensor([[1, 4], [2, 5], [3, 6]])) assert same_storage(x, y) 操作五 修改x时也会修改y\nx[0][0] = 100 # @inspect x, @inspect y assert y[0][0] == 100 操作六 存储连续性（contiguous）\n一些转换操作（view）会导致张量访问不连续，这会导致无法进行后续的转换操作\nx = torch.tensor([[1., 2, 3], [4, 5, 6]]) # @inspect x y = x.transpose(1, 0) # @inspect y assert not y.is_contiguous() try: y.view(2, 3) assert False except RuntimeError as e: assert \u0026#34;view size is not compatible with input tensor\u0026#39;s size and stride\u0026#34; in str(e) 可以强制一个张量变为连续，这会导致开辟新的存储空间\ny = x.transpose(1, 0).contiguous().view(2, 3) # @inspect y assert not same_storage(x, y) 2.1.3. 张量元素级操作（elementwise） 这些操作会将操作应用于张量中的每一个元素，并返回一个大小相同的张量\nx = torch.tensor([1, 4, 9]) assert torch.equal(x.pow(2), torch.tensor([1, 16, 81])) assert torch.equal(x.sqrt(), torch.tensor([1, 2, 3])) assert torch.equal(x.rsqrt(), torch.tensor([1, 1 / 2, 1 / 3])) # i -\u0026gt; 1/sqrt(x_i) assert torch.equal(x + x, torch.tensor([2, 8, 18])) assert torch.equal(x * 2, torch.tensor([2, 8, 18])) assert torch.equal(x / 0.5, torch.tensor([2, 8, 18])) triu构建一个矩阵的上三角，这个操作在计算因果注意力掩码（causal attention mask）时非常有用\nx = torch.ones(3, 3).triu() # @inspect x assert torch.equal(x, torch.tensor([ [1, 1, 1], [0, 1, 1], [0, 0, 1]], )) 2.1.4. 张量乘法 x = torch.ones(16, 32) w = torch.ones(32, 2) y = x @ w assert y.size() == torch.Size([16, 2]) 通常来说，我们会将乘法操作应用于 batch 的每一个示例（example），以及序列（sequence）中的每一个 token 中\nx = torch.ones(4, 8, 16, 32) ## [batch, sequence, H, W] w = torch.ones(32, 2) y = x @ w assert y.size() == torch.Size([4, 8, 16, 2]) 2.2. 张量 einops 2.2.1. 使用 einops 的动机 x = torch.ones(2, 2, 3) # batch, sequence, hidden @inspect x y = torch.ones(2, 2, 3) # batch, sequence, hidden @inspect y z = x @ y.transpose(-2, -1) # batch, sequence, sequence @inspect z 什么是维度 -2， -1？\n很容易搞混张量维度\neinops是一个 python 库，用于命名张量维度并操作张量\neinops文档\n2.2.2. jaxtyping命名矩阵维度 如何定义张量维度\n老方法\nx = torch.ones(2, 2, 1, 3) # batch seq heads hidden @inspect x 新方法（jaxtyping）\nx: Float[torch.Tensor, \u0026#34;batch seq heads hidden\u0026#34;] = torch.ones(2, 2, 1, 3) # @inspect x 2.2.3. einops操作 操作一 einsum Einsum 是具有良好记录功能的通用矩阵乘法\n定义两个张量\nx: Float[torch.Tensor, \u0026#34;batch seq1 hidden\u0026#34;] = torch.ones(2, 3, 4) # @inspect x y: Float[torch.Tensor, \u0026#34;batch seq2 hidden\u0026#34;] = torch.ones(2, 3, 4) # @inspect y 老方法\nz = x @ y.transpose(-2, -1) # batch, sequence, sequence @inspect z 新方法（jaxtyping）\nz = einsum(x, y, \u0026#34;batch seq1 hidden, batch seq2 hidden -\u0026gt; batch seq1 seq2\u0026#34;) # @inspect z z = einsum(x, y, \u0026#34;... seq1 hidden, ... seq2 hidden -\u0026gt; ... seq1 seq2\u0026#34;) # @inspect z 输出中未命名的维度将被求和\n操作二 reduce 你可以通过一些操作减少一个tensor的维度，例如sum、mean、max、min\n定义一个张量\nx: Float[torch.Tensor, \u0026#34;batch seq hidden\u0026#34;] = torch.ones(2, 3, 4) # @inspect x 老方法\ny = x.mean(dim=-1) # @inspect y 新方法（jaxtyping）\ny = reduce(x, \u0026#34;... hidden -\u0026gt; ...\u0026#34;, \u0026#34;sum\u0026#34;) # @inspect y 操作三 rearrange 有时候，有一个维度表征了两个维度，你希望操作两个维度中的一个\n定义一个张量\nx: Float[torch.Tensor, \u0026#34;batch seq total_hidden\u0026#34;] = torch.ones(2, 3, 8) # @inspect x 其中total_hidden是heads * hidden1的展平表征\nw: Float[torch.Tensor, \u0026#34;hidden1 hidden2\u0026#34;] = torch.ones(4, 4) 将total_hidden拆分成heads和hidden1\nx = rearrange(x, \u0026#34;... (heads hidden1) -\u0026gt; ... heads hidden1\u0026#34;, heads=2) # @inspect x 将heads和hidden1合并\nx = rearrange(x, \u0026#34;... heads hidden2 -\u0026gt; ... (heads hidden2)\u0026#34;) # @inspect x 2.3. 张量操作 flops 一个浮点运算（FLOP, floating-point operation）是一次基础操作，例如加法（$x+y$）或乘法（$x \\cdot y$）\n⚠ 警告两个极其令人困惑的缩写词（发音完全相同！）\nFLOPs：浮点运算（衡量计算量） FLOP/s：每秒浮点运算次数（也写作FLOPS），用于衡量硬件的速度 \u0026times; 训练 GPT-3（2020） 需要 3.14e23 FLOPs\n训练 GPT-4（2023） 需要大约 2e25 FLOPs\nA100 处理 torch.bfloat16 或 torch.float16 的峰值性能是 312 teraFLOP/s，处理 torch.float32 的峰值性能为 19.5 teraFLOP/s\nH100 处理 torch.bfloat16 或 torch.float16 的峰值性能是 1979 teraFLOP/s，但实际会有50%的性能折损；处理 torch.float32 的峰值性能为 67.5 teraFLOP/s\n8 张 H100 两周可以完成：\ntotal_flops = 8 * (60 * 60 * 24 * 7) * h100_flop_per_sec # @inspect total_flops 输出：\ntotal_flops = 4.788e+21 2.3.1. FLOPs计算 线性模型：对于一个维度为 B x D 的矩阵和一个 D x K 的矩阵，其所需的 FLOPs 为\nx = torch.ones(B, D, device=device) w = torch.randn(D, K, device=device) y = x @ w actual_num_flops = 2 * B * D * K # @inspect actual_num_flops 对于一个三元组 (i, j, k)，需要一次乘法 (x[i][j] * w[j][k]) 和一次加法，最终实现矩阵相乘运算\n元素级操作：一个 m x n 的矩阵需要 O(m x n) FLOPs\n加法操作：两个 m x n 的矩阵完成加法需要 m x n FLOPs\n总结，矩阵乘法是深度学习中 FLOP 需求最大的，你只需要统计深度学习中所需的乘法操作即可大致计算出所需 FLOPs\n2.3.2. 模型 FLOPs 使用量（Model FLOPs utilization，MFU） 定义： (actual FLOP/s) / (promised FLOP/s)，忽略通信开销\n实际上，MFU \u0026gt;= 0.5 就已经很棒了（如果模型中乘法运算主导的话往往会更高）\n2.3.3. 总结 矩阵乘法占主导地位：(2 x m x n x p) FLOPs\nFLOP/s 取决于硬件（H100 \u0026raquo; A100）和数据类型（bfloat16 \u0026raquo; float32）\n模型 FLOPs 利用率（MFU）：(实际 FLOP/s) / (承诺 FLOP/s)\n2.4. 梯度与反向传播 2.4.1. 梯度基础 假设我们有一个简单的线性模型\n$$ y = 0.5 \\cdot (x \\times w - 5)^2 $$\n前向传播：计算损失\nx = torch.tensor([1., 2, 3]) w = torch.tensor([1., 1, 1], requires_grad=True) # Want gradient pred_y = x @ w loss = 0.5 * (pred_y - 5).pow(2) 反向传播：计算梯度\nloss.backward() assert loss.grad is None assert pred_y.grad is None assert x.grad is None assert torch.equal(w.grad, torch.tensor([1, 2, 3])) 2.4.2. 梯度 FLOPs 计算梯度 FLOPs，我们以线性模型为例\nx = torch.ones(B, D, device=device) w1 = torch.randn(D, D, device=device, requires_grad=True) w2 = torch.randn(D, K, device=device, requires_grad=True) h1 = x @ w1 h2 = h1 @ w2 loss = h2.pow(2).mean() 回顾一下前向传播的 FLOPs 计算：\nMultiply x[i][j] * w1[j][k] Add to h1[i][k] Multiply h1[i][j] * w2[j][k] Add to h2[i][k] num_forward_flops = (2 * B * D * D) + (2 * B * D * K) # @inspect num_forward_flops 反向传播路径：loss \u0026ndash;\u0026gt; h2 \u0026ndash;\u0026gt; w2 \u0026ndash;\u0026gt; h1 \u0026ndash;\u0026gt; w1 \u0026ndash;\u0026gt; x\n对于参数 w2，根据链式法则，可以得出其梯度为\n$$ \\text{w2.grad} = \\frac{\\partial loss}{\\partial w2} = \\frac{\\partial loss}{\\partial h2} \\cdot \\frac{\\partial h2}{\\partial w2} $$ $$ w2.grad[j,k] = \\frac{\\partial loss}{\\partial w2[j, k]} = \\sum_{i=0}^{N-1} \\frac{\\partial loss}{\\partial h2[i, k]} \\cdot \\frac{\\partial h2[i, k]}{\\partial w2[j, k]} = \\sum_{i=0}^{N-1} h2.grad[i,k] \\cdot h1[i,j] $$\n对于每一个三元组 (i,j,k)，都要做一次乘法和加法，所以\nnum_backward_flops += 2 * B * D * K # @inspect num_backward_flops 而这其中，有四个参数需要计算梯度，所以最终需要的 FLOPs 为\nnum_backward_flops = (2 + 2) * B * D * K + (2 + 2) * B * D * D # @inspect num_backward_flops i 总结 前向传播：2 (# data points) (# parameters) FLOPs 反向传播：4 (# data points) (# parameters) FLOPs 总合：6 (# data points) (# parameters) FLOPs \u0026times; 3. 模型 3.1. 模型参数 模型参数均以nn.Parameter对象的形式存储于 Pytorch\ninput_dim = 16384 output_dim = 32 w = nn.Parameter(torch.randn(input_dim, output_dim)) assert isinstance(w, torch.Tensor) # Behaves like a tensor assert type(w.data) == torch.Tensor # Access the underlying tensor 3.1.1. 参数初始化 假设我们随机初始化权重 w，并与 x 做乘法操作\nx = nn.Parameter(torch.randn(input_dim)) output = x @ w # @inspect output assert output.size() == torch.Size([output_dim]) 输出：\noutput = [ 18.919979095458984, ... ] 由于 $output[k] = x \\times w[:, k]$，所以 output 中的每一个元素的大小均与 input_dim 线性相关\n当 input_dim 过大时，会导致参数梯度爆炸，倒是模型训练不稳定\n我们希望初始值与 input_dim 无关，为此，我们将参数统一放缩 1/sqrt(input_dim)\nw = nn.Parameter(torch.randn(input_dim, output_dim) / np.sqrt(input_dim)) output = x @ w # @inspect output 输出：\noutput = [ -1.5302726030349731, ... ] 简单来说，这就是 Xavier 初始化\n为了更加安全，我们将正态分布截断为[-3, 3]，以避免出现任何异常值\nw = nn.Parameter(nn.init.trunc_normal_(torch.empty(input_dim, output_dim), std=1 / np.sqrt(input_dim), a=-3, b=3)) 3.1.2. 构建模型 以线性模型为例\nclass Linear(nn.Module): \u0026#34;\u0026#34;\u0026#34;Simple linear layer.\u0026#34;\u0026#34;\u0026#34; def __init__(self, input_dim: int, output_dim: int): super().__init__() self.weight = nn.Parameter(torch.randn(input_dim, output_dim) / np.sqrt(input_dim)) def forward(self, x: torch.Tensor) -\u0026gt; torch.Tensor: return x @ self.weight class Cruncher(nn.Module): def __init__(self, dim: int, num_layers: int): super().__init__() self.layers = nn.ModuleList([ Linear(dim, dim) for i in range(num_layers) ]) self.final = Linear(dim, 1) def forward(self, x: torch.Tensor) -\u0026gt; torch.Tensor: # Apply linear layers B, D = x.size() for layer in self.layers: x = layer(x) # Apply final head x = self.final(x) assert x.size() == torch.Size([B, 1]) # Remove the last dimension x = x.squeeze(-1) assert x.size() == torch.Size([B]) return x B = 8 # Batch size x = torch.randn(B, D, device=device) y = model(x) assert y.size() == torch.Size([B]) 模型参数\nparam_sizes = [ (name, param.numel()) for name, param in model.state_dict().items() ] assert param_sizes == [ (\u0026#34;layers.0.weight\u0026#34;, D * D), (\u0026#34;layers.1.weight\u0026#34;, D * D), (\u0026#34;final.weight\u0026#34;, D), ] num_parameters = get_num_parameters(model) assert num_parameters == (D * D) + (D * D) + D 3.2. 模型训练 3.2.1. 随机性 随机性在许多地方都会出现：参数初始化、dropout、数据排序等。 为了确保可重复性，我们建议您在每次使用随机性时都传入不同的随机种子 确定性在调试时特别有用，这样您可以定位并解决问题 设置随机种子有三个地方，为了安全起见，您应该一次性全部设置好 # Torch seed = 0 torch.manual_seed(seed) # NumPy import numpy as np np.random.seed(seed) # Python import random random.seed(seed) 3.2.2. 数据加载 在语言模型中，数据可以表征为整数的序列（以 token 的形式输出）\n可以使用 numpy 数组进行序列化\norig_data = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10], dtype=np.int32) orig_data.tofile(\u0026#34;data.npy\u0026#34;) 你可以使用 numpy 数组加载数据\n如果你不希望一次性将所有数据载入内存（有些数据集巨大无比，例如 LLaMA 包含 2.8TB 数据），可以使用 memmap 将需要访问的部分载入内存\ndata = np.memmap(\u0026#34;data.npy\u0026#34;, dtype=np.int32) assert np.array_equal(data, orig_data) 一个数据加载器（dataloader）会生成一个 batch 的数据用于训练\ndef get_batch(data: np.array, batch_size: int, sequence_length: int, device: str) -\u0026gt; torch.Tensor: # Sample batch_size random positions into data. start_indices = torch.randint(len(data) - sequence_length, (batch_size,)) assert start_indices.size() == torch.Size([batch_size]) # Index into the data. x = torch.tensor([data[start:start + sequence_length] for start in start_indices]) assert x.size() == torch.Size([batch_size, sequence_length]) # Pinned memory if torch.cuda.is_available(): x = x.pin_memory() x = x.to(device, non_blocking=True) return x B = 2 # Batch size L = 4 # Length of sequence x = get_batch(data, batch_size=B, sequence_length=L, device=get_device()) assert x.size() == torch.Size([B, L]) 默认情况下，CPU 张量存储在分页内存（paged memory）中，我们可以显式地将其固定（pin），运行代码x = x.pin_memory()\n这允许我们并行完成两项任务：\n从数据中提取下一个 batch 到 CPU 上 在 GPU 上处理 x 3.2.3. 优化器 Optimizer 依旧请出老朋友线性模型\nB = 2 D = 4 num_layers = 2 model = Cruncher(dim=D, num_layers=num_layers).to(get_device()) 定义 AdaGrad 优化器\nmomentum = SGD + exponential averaging of grad AdaGrad = SGD + averaging by grad^2 RMSProp = AdaGrad + exponentially averaging of grad^2 Adam = RMSProp + momentum AdaGrad\nclass AdaGrad(torch.optim.Optimizer): def __init__(self, params: Iterable[nn.Parameter], lr: float = 0.01): super(AdaGrad, self).__init__(params, dict(lr=lr)) def step(self): for group in self.param_groups: lr = group[\u0026#34;lr\u0026#34;] for p in group[\u0026#34;params\u0026#34;]: # Optimizer state state = self.state[p] grad = p.grad.data # Get squared gradients g2 = sum_{i\u0026lt;t} g_i^2 g2 = state.get(\u0026#34;g2\u0026#34;, torch.zeros_like(grad)) # Update optimizer state g2 += torch.square(grad) state[\u0026#34;g2\u0026#34;] = g2 # Update parameters p.data -= lr * grad / torch.sqrt(g2 + 1e-5) optimizer = AdaGrad(model.parameters(), lr=0.01) state = model.state_dict() # @inspect state 计算梯度\nx = torch.randn(B, D, device=get_device()) y = torch.tensor([4., 5.], device=get_device()) pred_y = model(x) loss = F.mse_loss(input=pred_y, target=y) loss.backward() 优化一个 step\noptimizer.step() state = model.state_dict() # @inspect state 释放内存（可选）\noptimizer.zero_grad(set_to_none=True) 关于内存 参数所需的内存\ndef get_num_parameters(model: nn.Module) -\u0026gt; int: return sum(param.numel() for param in model.parameters()) num_parameters = (D * D * num_layers) + D # @inspect num_parameters assert num_parameters == get_num_parameters(model) 输出\nnum_parameters = 36 激活函数所需的内存\nnum_activations = B * D * num_layers # @inspect num_activations 输出\nnum_parameters = 16 梯度所需的内存\nnum_gradients = num_parameters # @inspect num_gradients 输出\nnum_parameters = 36 优化器 state 所需的内存\nnum_optimizer_states = num_parameters # @inspect num_optimizer_states 输出\nnum_parameters = 36 总共需要（假设数据均以 float32 存储，需要 4 Bytes）\ntotal_memory = 4 * (num_parameters + num_activations + num_gradients + num_optimizer_states) # @inspect total_memory 输出\nnum_parameters = 496 3.2.4. 训练循环（loop） def train(name: str, get_batch, D: int, num_layers: int, B: int, num_train_steps: int, lr: float): model = Cruncher(dim=D, num_layers=0).to(get_device()) optimizer = SGD(model.parameters(), lr=0.01) for t in range(num_train_steps): # Get data x, y = get_batch(B=B) # Forward (compute loss) pred_y = model(x) loss = F.mse_loss(pred_y, y) # Backward (compute gradients) loss.backward() # Update parameters optimizer.step() optimizer.zero_grad(set_to_none=True) train(\u0026#34;simple\u0026#34;, get_batch, D=D, num_layers=0, B=4, num_train_steps=10, lr=0.01) 3.2.5. checkpoint 在训练阶段，阶段性的保存模型以及优化器状态（state）到硬盘中是非常有用的\ncheckpoint = { \u0026#34;model\u0026#34;: model.state_dict(), \u0026#34;optimizer\u0026#34;: optimizer.state_dict(), } torch.save(checkpoint, \u0026#34;model_checkpoint.pt\u0026#34;) 加载 checkpoint\nloaded_checkpoint = torch.load(\u0026#34;model_checkpoint.pt\u0026#34;) 3.2.6. 混合精度训练 数据类型的选择（float32、bfloat16、fp8）存在权衡 更高精度：更准确/稳定，占用更多内存，计算量更大 精度较低：精度/稳定性较低，内存占用较少，计算量较少 如何兼顾两者优势？ 解决方案：默认使用float32，但在可能的情况下使用{bfloat16, fp8} 具体计划： 在前向传播（激活函数）中使用{bfloat16, fp8} 使用float32进行其余操作（参数、梯度） 混合精度训练 Pytorch 提供自动混合精度（AMP）库 NVIDIA 的 Transformer Engine 支持 FP8 用于线性层 在训练过程中广泛使用 FP8 参考文献 stanford-cs336 lecture 2 ","permalink":"https://cspaulia.github.io/cspaulia-blog/posts/primitives/","summary":"\u003ch2 id=\"深度学习主要资源\"\u003e深度学习主要资源\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e内存\u003c/strong\u003e（GB）：存储参数、梯度、优化器状态、激活值等。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e计算量\u003c/strong\u003e（FLOPs）：浮点运算次数，衡量训练所需的计算资源。\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch2 id=\"1-张量基础与内存管理\"\u003e1. 张量基础与内存管理\u003c/h2\u003e\n\u003ch3 id=\"11-张量的创建与存储\"\u003e1.1. 张量的创建与存储\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e张量是存储参数、梯度、优化器状态、数据、激活值的基本单元\u003c/li\u003e\n\u003cli\u003ePyTorch 支持多种方式创建张量（如 \u003ccode\u003etorch.zeros\u003c/code\u003e、\u003ccode\u003etorch.ones\u003c/code\u003e、\u003ccode\u003etorch.randn\u003c/code\u003e 等）\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003ex\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003etorch\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003etensor\u003c/span\u003e\u003cspan class=\"p\"\u003e([[\u003c/span\u003e\u003cspan class=\"mf\"\u003e1.\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"mi\"\u003e2\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"mi\"\u003e3\u003c/span\u003e\u003cspan class=\"p\"\u003e],\u003c/span\u003e \u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"mi\"\u003e4\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"mi\"\u003e5\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"mi\"\u003e6\u003c/span\u003e\u003cspan class=\"p\"\u003e]])\u003c/span\u003e  \u003cspan class=\"c1\"\u003e# @inspect x\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003ex\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003etorch\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ezeros\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"mi\"\u003e4\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"mi\"\u003e8\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e  \u003cspan class=\"c1\"\u003e# 4x8 matrix of all zeros @inspect x\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003ex\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003etorch\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eones\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"mi\"\u003e4\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"mi\"\u003e8\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e  \u003cspan class=\"c1\"\u003e# 4x8 matrix of all ones @inspect x\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003ex\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003etorch\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003erandn\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"mi\"\u003e4\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"mi\"\u003e8\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e  \u003cspan class=\"c1\"\u003e# 4x8 matrix of iid Normal(0, 1) samples @inspect x\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e你也可以先分配空间，再分配数值\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003ex\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003etorch\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eempty\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"mi\"\u003e4\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"mi\"\u003e8\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e  \u003cspan class=\"c1\"\u003e# 4x8 matrix of uninitialized values @inspect x\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003enn\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003einit\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003etrunc_normal_\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ex\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003emean\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003estd\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ea\u003c/span\u003e\u003cspan class=\"o\"\u003e=-\u003c/span\u003e\u003cspan class=\"mi\"\u003e2\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eb\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"mi\"\u003e2\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e  \u003cspan class=\"c1\"\u003e# @inspect x\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/li\u003e\n\u003cli\u003e张量的内存由\u003cstrong\u003e元素数量\u003c/strong\u003e和\u003cstrong\u003e数据类型\u003c/strong\u003e共同决定\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch3 id=\"12-常见数据类型\"\u003e1.2. 常见数据类型\u003c/h3\u003e\n\u003cp\u003e参数、梯度、激活以及优化状态几乎均存储为浮点数\u003c/p\u003e\n\u003ch4 id=\"121-float32单精度\"\u003e1.2.1 float32（单精度）\u003c/h4\u003e\n\u003cp\u003e默认类型，4 字节，动态范围大。\u003c/p\u003e\n\u003cp align=\"center\"\u003e\n  \u003cimg src=\"fp32.png\" alt=\"fp32\" /\u003e\n\u003c/p\u003e\n\u003cp\u003e内存是由(i)数值的数量和(ii)数值的类型决定的\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003ex\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003etorch\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ezeros\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"mi\"\u003e4\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"mi\"\u003e8\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e  \u003cspan class=\"c1\"\u003e# @inspect x\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"k\"\u003eassert\u003c/span\u003e \u003cspan class=\"n\"\u003ex\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003edtype\u003c/span\u003e \u003cspan class=\"o\"\u003e==\u003c/span\u003e \u003cspan class=\"n\"\u003etorch\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003efloat32\u003c/span\u003e  \u003cspan class=\"c1\"\u003e# Default type\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"k\"\u003eassert\u003c/span\u003e \u003cspan class=\"n\"\u003ex\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003enumel\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e \u003cspan class=\"o\"\u003e==\u003c/span\u003e \u003cspan class=\"mi\"\u003e4\u003c/span\u003e \u003cspan class=\"o\"\u003e*\u003c/span\u003e \u003cspan class=\"mi\"\u003e8\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"k\"\u003eassert\u003c/span\u003e \u003cspan class=\"n\"\u003ex\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eelement_size\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e \u003cspan class=\"o\"\u003e==\u003c/span\u003e \u003cspan class=\"mi\"\u003e4\u003c/span\u003e  \u003cspan class=\"c1\"\u003e# Float is 4 bytes\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"k\"\u003eassert\u003c/span\u003e \u003cspan class=\"n\"\u003eget_memory_usage\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ex\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"o\"\u003e==\u003c/span\u003e \u003cspan class=\"mi\"\u003e4\u003c/span\u003e \u003cspan class=\"o\"\u003e*\u003c/span\u003e \u003cspan class=\"mi\"\u003e8\u003c/span\u003e \u003cspan class=\"o\"\u003e*\u003c/span\u003e \u003cspan class=\"mi\"\u003e4\u003c/span\u003e  \u003cspan class=\"c1\"\u003e# 128 bytes\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch4 id=\"122-float16半精度\"\u003e1.2.2 float16（半精度）\u003c/h4\u003e\n\u003cp\u003e2 字节，节省内存但动态范围小，易下溢\u003c/p\u003e","title":"基本原语（primitives）与资源计算"},{"content":"👉 在线体验地址：Tokenization 可视化工具\n原始的文本统一表征为 Unicode 字符串\nstring = \u0026#34;Hello, 🌍! 你好!\u0026#34; 语言模型会对一系列token（通常用整数索引表示）上的可能性进行建模，构成一个概率分布\nindices = [15496, 11, 995, 0] 我们需要：\n✅ 一个方法：将字符串编码为 token ✅ 一个方法：将 token 解码回字符串 class Tokenizer: def encode(self, string: str) -\u0026gt; list[int]: ... def decode(self, indices: list[int]) -\u0026gt; str: ... vocab_size: 词表大小，即可能出现的 token（整数 ID）总数。 1. Character-based tokenization 1.1. Unicode 概述 统一全球字符编码的标准（约 150,000 个字符） ord(char)：获取字符的十进制编码 ord(\u0026#34;h\u0026#34;) # 104 ord(\u0026#34;😊\u0026#34;) # 128522 1.2. 编解码 class CharacterTokenizer(Tokenizer): \u0026#34;\u0026#34;\u0026#34;Represent a string as a sequence of Unicode code points.\u0026#34;\u0026#34;\u0026#34; def encode(self, string: str) -\u0026gt; list[int]: return list(map(ord, string)) def decode(self, indices: list[int]) -\u0026gt; str: return \u0026#34;\u0026#34;.join(map(chr, indices)) 示例：\ntokenizer = CharacterTokenizer() string = \u0026#34;Hello, 🌍! 你好!\u0026#34; # @inspect string indices = tokenizer.encode(string) # @inspect indices reconstructed_string = tokenizer.decode(indices) # @inspect reconstructed_string 输出：\nstring = \u0026#34;Hello, 🌍! 你好!\u0026#34; indices = [72, 101, 108, 108, 111, 44, 32, 127757, 33, 32, 20320, 22909, 33] reconstructed_string = \u0026#34;Hello, 🌍! 你好!\u0026#34; 1.3. 存在的问题 问题一：这会是一个相当大的词汇表（vocabulary）\n问题二：很多字符出现几率很低（例如🌍），对词汇表的使用并不高效\ndef get_compression_ratio(string: str, indices: list[int]) -\u0026gt; float: \u0026#34;\u0026#34;\u0026#34;Given `string` that has been tokenized into `indices`, .\u0026#34;\u0026#34;\u0026#34; num_bytes = len(bytes(string, encoding=\u0026#34;utf-8\u0026#34;)) # @inspect num_bytes num_tokens = len(indices) # @inspect num_tokens return num_bytes / num_tokens vocabulary_size = max(indices) + 1 # This is a lower bound @inspect vocabulary_size compression_ratio = get_compression_ratio(string, indices) # @inspect compression_ratio 输出：\nvocabulary_size = 127758 num_bytes = 20 num_tokens = 13 compression_ratio = 1.5384615384615385 2. Byte-based tokenization Unicode 字符串（String）可以表示为一串字节（Byte），其中字节（即八位二进制）可以表示为0到255的数字\n最常见的 Unicode 编码是 UTF-8\n输入：\nbytes(\u0026#34;a\u0026#34;, encoding=\u0026#34;utf-8\u0026#34;) bytes(\u0026#34;🌍\u0026#34;, encoding=\u0026#34;utf-8\u0026#34;) 输出：\nb\u0026#34;a\u0026#34; # one byte b\u0026#34;\\xf0\\x9f\\x8c\\x8d\u0026#34;s # multiple bytes 2.1. 编解码 class ByteTokenizer(Tokenizer): \u0026#34;\u0026#34;\u0026#34;Represent a string as a sequence of bytes.\u0026#34;\u0026#34;\u0026#34; def encode(self, string: str) -\u0026gt; list[int]: string_bytes = string.encode(\u0026#34;utf-8\u0026#34;) # @inspect string_bytes indices = list(map(int, string_bytes)) # @inspect indices return indices def decode(self, indices: list[int]) -\u0026gt; str: string_bytes = bytes(indices) # @inspect string_bytes string = string_bytes.decode(\u0026#34;utf-8\u0026#34;) # @inspect string return string 示例：\ntokenizer = ByteTokenizer() string = \u0026#34;Hello, 🌍! 你好!\u0026#34; # @inspect string indices = tokenizer.encode(string) # @inspect indices reconstructed_string = tokenizer.decode(indices) # @inspect reconstructed_string 输出：\nstring = \u0026#34;Hello, 🌍! 你好!\u0026#34; string_bytes = \u0026#34;b\u0026#39;Hello, \\\\xf0\\\\x9f\\\\x8c\\\\x8d!\\\\xe4\\\\xbd\\\\xa0\\\\xe5\\\\xa5\\\\xbd\u0026#39;\u0026#34; indices = [72, 101, 108, 108, 111, 44, 32, 240, 159, 140, 141, 33, 32, 228, 189, 160, 229, 165, 189, 33] reconstructed_string = \u0026#34;Hello, 🌍! 你好!\u0026#34; 2.2. 存在的问题 问题一：虽然词汇表很小（仅为256），但这也导致序列很长。而在 Transformer 中，计算复杂度是随着序列长度二次增长的\nvocabulary_size = 256 # This is a lower bound @inspect vocabulary_size compression_ratio = get_compression_ratio(string, indices) # @inspect compression_ratio 输出：\nnum_bytes = 20 num_tokens = 20 compression_ratio = 1.0 3. Word-based tokenization 使用类似于传统NLP分词方法分离字符串，输入：\nstring = \u0026#34;I\u0026#39;ll say supercalifragilisticexpialidocious!\u0026#34; segments = regex.findall(r\u0026#34;\\w+|.\u0026#34;, string) # @inspect segments 输出：\nsegments = [\u0026#34;I\u0026#34;, \u0026#34;ll\u0026#34;, \u0026#34;say\u0026#34;, \u0026#34;supercalifragilisticexpialidocious\u0026#34;, \u0026#34;!\u0026#34;] 3.1. 编解码 要将其转换为一个tokenizer，我们需要将这些片段映射为整数 构建一个从每个片段到整数的映射 3.2. 存在的问题 词的数量是非常庞大的 很多词很少出现，模型不会从这些词中学习到很多内容 它无法提供一个固定长度的词典 4. Byte Pair Encoding（BPE） 主要思想：在原始文本上训练tokenizer，自发的生成词汇表\n意图：对于常见的字符序列，可以仅用一个token表示；对于不常见的字符序列，则用多个token表示\n算法简述：首先将每一个byte看作是一个token，随后逐渐合并常出现的相邻token为一个新token\n4.1. 算法流程 def merge(indices: list[int], pair: tuple[int, int], new_index: int) -\u0026gt; list[int]: # @inspect indices, @inspect pair, @inspect new_index \u0026#34;\u0026#34;\u0026#34;Return `indices`, but with all instances of `pair` replaced with `new_index`.\u0026#34;\u0026#34;\u0026#34; new_indices = [] # @inspect new_indices i = 0 # @inspect i while i \u0026lt; len(indices): if i + 1 \u0026lt; len(indices) and indices[i] == pair[0] and indices[i + 1] == pair[1]: new_indices.append(new_index) i += 2 else: new_indices.append(indices[i]) i += 1 return new_indices 4.2. BPE 编码器 class BPETokenizer(Tokenizer): \u0026#34;\u0026#34;\u0026#34;BPE tokenizer given a set of merges and a vocabulary.\u0026#34;\u0026#34;\u0026#34; def __init__(self, params: BPETokenizerParams): self.params = params def encode(self, string: str) -\u0026gt; list[int]: indices = list(map(int, string.encode(\u0026#34;utf-8\u0026#34;))) # @inspect indices # Note: this is a very slow implementation for pair, new_index in self.params.merges.items(): # @inspect pair, @inspect new_index indices = merge(indices, pair, new_index) return indices def decode(self, indices: list[int]) -\u0026gt; str: bytes_list = list(map(self.params.vocab.get, indices)) # @inspect bytes_list string = b\u0026#34;\u0026#34;.join(bytes_list).decode(\u0026#34;utf-8\u0026#34;) # @inspect string return string 4.3. 训练 BPE def train_bpe(string: str, num_merges: int) -\u0026gt; BPETokenizerParams: # @inspect string, @inspect num_merges # Start with the list of bytes of string. indices = list(map(int, string.encode(\u0026#34;utf-8\u0026#34;))) # @inspect indices merges: dict[tuple[int, int], int] = {} # index1, index2 =\u0026gt; merged index vocab: dict[int, bytes] = {x: bytes([x]) for x in range(256)} # index -\u0026gt; bytes for i in range(num_merges): # Count the number of occurrences of each pair of tokens counts = defaultdict(int) for index1, index2 in zip(indices, indices[1:]): # For each adjacent pair counts[(index1, index2)] += 1 # @inspect counts # Find the most common pair. pair = max(counts, key=counts.get) # @inspect pair index1, index2 = pair # Merge that pair. new_index = 256 + i # @inspect new_index merges[pair] = new_index # @inspect merges vocab[new_index] = vocab[index1] + vocab[index2] # @inspect vocab indices = merge(indices, pair, new_index) # @inspect indices return BPETokenizerParams(vocab=vocab, merges=merges) 示例:\ntext = \u0026#34;the cat in the hat\u0026#34; # @inspect string params = train_bpe(text, num_merges=3) string = \u0026#34;the quick brown fox\u0026#34; # @inspect string tokenizer = BPETokenizer(params) indices = tokenizer.encode(string) # @inspect indices reconstructed_string = tokenizer.decode(indices) # @inspect reconstructed_string 代码逻辑为：\n初始化词汇表，用0-255表征byte 依次寻找最多次出现的相邻byte (116, 104) \u0026ndash;\u0026gt; 256 即 (\u0026rsquo;t\u0026rsquo;, \u0026lsquo;h\u0026rsquo;) \u0026ndash;\u0026gt; \u0026rsquo;th\u0026rsquo; (256, 101) \u0026ndash;\u0026gt; 257 即 (\u0026rsquo;th\u0026rsquo;, \u0026rsquo;e\u0026rsquo;) \u0026ndash;\u0026gt; \u0026rsquo;the' (257, 32) \u0026ndash;\u0026gt; 258 即 （\u0026rsquo;the\u0026rsquo;, \u0026rsquo; \u0026lsquo;）\u0026ndash;\u0026gt; \u0026rsquo;the ' 词汇表长度更新至259 用新词汇表对字符串进行编码 参考文献 stanford-cs336 lecture 1 ","permalink":"https://cspaulia.github.io/cspaulia-blog/posts/tokenization/","summary":"\u003cp\u003e👉 在线体验地址：\u003ca href=\"https://tiktokenizer.vercel.app\"\u003eTokenization 可视化工具\u003c/a\u003e\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003e原始的文本统一表征为 Unicode 字符串\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003estring\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;Hello, 🌍! 你好!\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e语言模型会对一系列token（通常用整数索引表示）上的可能性进行建模，构成一个概率分布\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003eindices\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"mi\"\u003e15496\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"mi\"\u003e11\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"mi\"\u003e995\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e我们需要：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e✅ 一个方法：\u003cstrong\u003e将字符串编码为 token\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003e✅ 一个方法：\u003cstrong\u003e将 token 解码回字符串\u003c/strong\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"k\"\u003eclass\u003c/span\u003e \u003cspan class=\"nc\"\u003eTokenizer\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003eencode\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003estring\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"nb\"\u003estr\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"o\"\u003e-\u0026gt;\u003c/span\u003e \u003cspan class=\"nb\"\u003elist\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"nb\"\u003eint\u003c/span\u003e\u003cspan class=\"p\"\u003e]:\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"o\"\u003e...\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003edecode\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eindices\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"nb\"\u003elist\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"nb\"\u003eint\u003c/span\u003e\u003cspan class=\"p\"\u003e])\u003c/span\u003e \u003cspan class=\"o\"\u003e-\u0026gt;\u003c/span\u003e \u003cspan class=\"nb\"\u003estr\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"o\"\u003e...\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cul\u003e\n\u003cli\u003e\u003ccode\u003evocab_size\u003c/code\u003e: 词表大小，即可能出现的 token（整数 ID）总数。\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch2 id=\"1-character-based-tokenization\"\u003e1. Character-based tokenization\u003c/h2\u003e\n\u003ch3 id=\"11-unicode-概述\"\u003e1.1. Unicode 概述\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e统一全球字符编码的标准（约 150,000 个字符）\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eord(char)\u003c/code\u003e：获取字符的十进制编码\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"nb\"\u003eord\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;h\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e     \u003cspan class=\"c1\"\u003e# 104\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"nb\"\u003eord\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;😊\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e    \u003cspan class=\"c1\"\u003e# 128522\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"12-编解码\"\u003e1.2. 编解码\u003c/h3\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"k\"\u003eclass\u003c/span\u003e \u003cspan class=\"nc\"\u003eCharacterTokenizer\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eTokenizer\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"s2\"\u003e\u0026#34;\u0026#34;\u0026#34;Represent a string as a sequence of Unicode code points.\u0026#34;\u0026#34;\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003eencode\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003estring\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"nb\"\u003estr\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"o\"\u003e-\u0026gt;\u003c/span\u003e \u003cspan class=\"nb\"\u003elist\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"nb\"\u003eint\u003c/span\u003e\u003cspan class=\"p\"\u003e]:\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"nb\"\u003elist\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"nb\"\u003emap\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"nb\"\u003eord\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003estring\u003c/span\u003e\u003cspan class=\"p\"\u003e))\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003edecode\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eindices\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"nb\"\u003elist\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"nb\"\u003eint\u003c/span\u003e\u003cspan class=\"p\"\u003e])\u003c/span\u003e \u003cspan class=\"o\"\u003e-\u0026gt;\u003c/span\u003e \u003cspan class=\"nb\"\u003estr\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;\u0026#34;\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ejoin\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"nb\"\u003emap\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"nb\"\u003echr\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eindices\u003c/span\u003e\u003cspan class=\"p\"\u003e))\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e\u003cstrong\u003e示例\u003c/strong\u003e：\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003etokenizer\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eCharacterTokenizer\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003estring\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;Hello, 🌍! 你好!\u0026#34;\u003c/span\u003e  \u003cspan class=\"c1\"\u003e# @inspect string\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003eindices\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003etokenizer\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eencode\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003estring\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e  \u003cspan class=\"c1\"\u003e# @inspect indices\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003ereconstructed_string\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003etokenizer\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003edecode\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eindices\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e  \u003cspan class=\"c1\"\u003e# @inspect reconstructed_string\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e\u003cstrong\u003e输出\u003c/strong\u003e：\u003c/p\u003e","title":"Tokenization"},{"content":"分类评估指标 TP / TN / FP / FN 基本概念\n假设我们做的是“检测是否生病”的任务，模型预测结果 vs 实际情况如下表：\n实际情况\\预测结果 预测为阳性（生病） 预测为阴性（没病） 实际是阳性（生病） ✅ TP（真正） ❌ FN（假负） 实际是阴性（没病） ❌ FP（假正） ✅ TN（真负） TP (True Positive)：预测“有病”，实际也“有病” → 判断正确 TN (True Negative)：预测“没病”，实际也“没病” → 判断正确 FP (False Positive)：预测“有病”，实际却“没病” → 误报 FN (False Negative)：预测“没病”，实际却“有病” → 漏报（更严重） 准确率（Accuracy） 模型判断正确的总体比例 $$ Accuracy = \\frac{(TP + TN)}{(TP + TN + FP + FN)} $$\n召回率（Recall） 在所有真正例中，模型识别出来的比例（不漏掉） $$ Recall = \\frac{TP}{(TP + FN)} $$\n精确率（Precision） 模型预测为正中，确实为正的比例（不冤枉） $$ Precision = \\frac{TP}{(TP + FP)} $$\nF1-score 精确率和召回率的调和平均 $$ F1 = \\frac{2 × (Precision × Recall)}{(Precision + Recall)} $$\n多分类变体 Macro-F1：所有类别的 F1 取算术平均。 Micro-F1：基于全局总 TP/FP/FN 计算 F1。 Weighted-F1：按各类别的样本数量加权平均 F1。 排序质量评估指标 平均准确率（Average Precision，AP） 一句话解释：一个类别的平均“精确率”，以某一类别的目标检测为例：\n1. 对预测框按置信分数从高到低排序 每个预测结果都有：\n位置框（bounding box） 分数（confidence） 预测标签 按预测分数从高到低排序\n2. 判断每个预测是 TP 还是 FP 依次遍历预测框：\n如果与某个尚未匹配的真实框 IoU ≥ 阈值（如 0.5），则为 TP 否则为 FP 记录每个预测的 TP/FP 标记\n3. 计算累计 Precision \u0026amp; Recall 遍历每个预测点，从第一个开始，每预测一个都更新：\n累积 TP 数（TP_i） 累积 FP 数（FP_i） 然后算：\nprecision_i = TP_i / (TP_i + FP_i) recall_i = TP_i / GT_total # GT_total 为总的真实框数量 4. 画 PR 曲线 \u0026amp; 计算面积 逐步积分:\n# Recall, Precision 已按 recall 升序排列 AP = 0 for i in range(1, len(recall)): AP += precision[i] * (recall[i] - recall[i-1]) mAP（mean Average Precision） 所有类别的 AP 平均值\n$$ mAP = \\sum_i AP_i $$\nmAP@IoU=0.5（mAP@0.5） 预测的框和真实框的 IoU（交并比）≥ 0.5 时，才算正确（TP） 然后计算每个类的 AP，再平均，就是 mAP@0.5 mAP@0.5:0.95 IoU 从 0.5 到 0.95，每隔 0.05 计算一次（共 10 个 IoU 阈值） 平均这 10 个 AP → 得到最终 mAP mAP@k 常用于 图像检索 / 推荐系统 / 多标签排序：\n表示在每次检索的前 k 个结果 中，计算 AP，然后对所有查询求平均\n举例 你搜索“狗”，模型返回前10张图片：\n有6张是狗，4张不是，且狗分布在第1、2、3、6、7、9位 你计算这些位置上的 Precision，再求平均 → 得到 AP@10 对所有用户查询求平均 → 得到 mAP@10 Caption任务指标 SPICE 为什么需要 SPICE？ 传统指标如：\nBLEU：关注 n-gram 匹配（像机器翻译） ROUGE：关注召回率（适合摘要） CIDEr：考虑 TF-IDF 加权的 n-gram 匹配 它们都看的是“词”和“短语”重不重复，却忽略了语义结构是否对。\n而 SPICE 的理念是：\n“人类评价图像描述时，看的是你有没有说出对的对象、属性和关系。”\nSPICE 计算方法 核心思想： 把句子转换为一个语义图（scene graph）：对象 + 属性 + 关系，然后比较机器描述和参考描述的语义图有多相似\n语义图结构定义 一句话被表示为一组三元组（triples）：\nG = {object, attribute, relation} 例如：\nSentence: \u0026#34;A red car is parked beside a white house\u0026#34; G = { (object: car), (object: house), (attribute: car, red), (attribute: house, white), (relation: car, beside, house) } 数学公式定义 输入：\n$G$: 生成句子的语义三元组集合（Graph of candidate） $R$: 所有参考句子的语义三元组集合（Graph of references） 目标：\n计算 $F_1$ score between $G$ and $R$ 匹配集合：\nPrecision: $$ P = \\frac{|\\mathcal{G} \\cap \\mathcal{R}|}{|\\mathcal{G}|} $$ ​\nRecall: $$ R = \\frac{|\\mathcal{G} \\cap \\mathcal{R}|}{|\\mathcal{R}|} $$\nF1-score: $$ F_1 = \\frac{2PR}{P + R} $$\n即：$\\text{SPICE} = F_1(G, R)$\n分别统计：\n对象匹配（object F1）\n属性匹配（attribute F1）\n关系匹配（relation F1）\n甚至是颜色、数量、大小等细分类别\n最终 SPICE 得分是它们的加权平均：\n$$ \\text{SPICE}=\\sum_i w_i \\cdot F_1^i $$\n其中 $F_1^i$ 是每种语义类别（对象、属性等）的 F1，$w_i$ 是每类的权重\n","permalink":"https://cspaulia.github.io/cspaulia-blog/posts/metric/","summary":"\u003ch2 id=\"分类评估指标\"\u003e分类评估指标\u003c/h2\u003e\n\u003cblockquote\u003e\n\u003cp\u003eTP / TN / FP / FN 基本概念\u003c/p\u003e\n\u003cp\u003e假设我们做的是“检测是否生病”的任务，模型预测结果 vs 实际情况如下表：\u003c/p\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003e实际情况\\预测结果\u003c/th\u003e\n          \u003cth\u003e预测为阳性（生病）\u003c/th\u003e\n          \u003cth\u003e预测为阴性（没病）\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e实际是阳性（生病）\u003c/td\u003e\n          \u003ctd\u003e✅ TP（真正）\u003c/td\u003e\n          \u003ctd\u003e❌ FN（假负）\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e实际是阴性（没病）\u003c/td\u003e\n          \u003ctd\u003e❌ FP（假正）\u003c/td\u003e\n          \u003ctd\u003e✅ TN（真负）\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eTP (True Positive)\u003c/strong\u003e：预测“有病”，实际也“有病” → 判断正确\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eTN (True Negative)\u003c/strong\u003e：预测“没病”，实际也“没病” → 判断正确\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eFP (False Positive)\u003c/strong\u003e：预测“有病”，实际却“没病” → 误报\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eFN (False Negative)\u003c/strong\u003e：预测“没病”，实际却“有病” → 漏报（更严重）\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/blockquote\u003e\n\u003chr\u003e\n\u003ch3 id=\"准确率accuracy\"\u003e准确率（Accuracy）\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e模型判断正确的总体比例\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e$$\nAccuracy = \\frac{(TP + TN)}{(TP + TN + FP + FN)}\n$$\u003c/p\u003e\n\u003chr\u003e\n\u003ch3 id=\"召回率recall\"\u003e召回率（Recall）\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e在所有真正例中，模型识别出来的比例（不漏掉）\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e$$\nRecall = \\frac{TP}{(TP + FN)}\n$$\u003c/p\u003e\n\u003chr\u003e\n\u003ch3 id=\"精确率precision\"\u003e精确率（Precision）\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e模型预测为正中，确实为正的比例（不冤枉）\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e$$\nPrecision = \\frac{TP}{(TP + FP)}\n$$\u003c/p\u003e","title":"记录100种评价指标"},{"content":"GPT-1 出发点 目前尚不清楚哪种类型的优化目标最有效地学习对迁移有效的文本表示（个人理解对于不同的NLP任务，不知道哪种优化目标是最好的）\n方法 半监督的方法 Transformer（用于处理长期依赖性的更多结构化记忆）\u0026ndash;\u0026gt; 强大的迁移性能🔤 1. 非监督预训练（Unsupervised pre-training） 优化目标：\n给定一组 unsupervised corpus of tokens $U = \\{u_1, \\cdots , u_n\\}$\n$$ L_1(U) = \\sum_i \\log{P(u_i | u_{i-k}, \\cdots, u_{i-1}; \\Theta)}, i \\in {1,\\cdots, n} $$\nk是上下文窗口的大小，使用具有参数$θ$的神经网络对条件概率$P$进行建模； 这里的 $P(u_i | u_{i-k}, \\cdots, u_{i-1}; \\Theta)$ 指的是已知模型参数$θ$与前 n 个token的情况下，预测出第 i 个token的概率 由于GPT使用的是非监督预训练方法，在给定一段文本中的 k 个token时，就是要让模型顺利的预测出第 i 个token。因此将每个token的预测概率 $P(u_i | u_{i-k}, \\cdots, u_{i-1}; \\Theta)$ 求和并最大化，就是该模型的优化目标，该目标适用于任何任务。（解决出发点问题）\n模型架构：\nmulti-layer Transformer decoder\n$$ \\begin{aligned} h_0 \u0026amp;= UW_e + W_p \\\\ h_i \u0026amp;= \\text{transformer block}(h_{i-1}) \\\\ P(u) \u0026amp;= \\text{softmax}(h_n W_e^T) \\end{aligned} $$\nWe is the token embedding matrix\nWp is the position embedding matrix\n2. 基于监督的微调（Supervised fine-tuning） 假设有一标注过的数据集，其包含：\na sequence of input tokens, $x1, \\cdots , xm$ label $y$ 获得最后一层Transformer块的激活层输出$h^m_l$\n$$ P(y|x^1, \\dots, x^m) = \\text{softmax}(h_l^m W_y) $$\n$$ L_2(\\hat{C}) = \\sum_{(x, y)} \\log P(y|x^1, \\dots, x^m) $$\n和目标函数 L1 构造类似，不过是令预测标签概率最大\n$$ L_3(\\hat{C}) = L_2(\\hat{C}) + \\lambda * L_1(\\hat{C}) $$\n微调任务中的优化目标函数由L1和L2组成。\n3. 不同任务的输入构造（Task-specific input transformations） 简单讲讲相似度任务。由于GPT是单向的模型（Transformer是一个词一个词的生成的），所以在处理相似度任务时，Text 1 和 Text 2 的先后顺序很重要，可以按照不同的排列顺序排放，利用GPT计算相似度取平均相似度。\nGPT-2 出发点 创建Machine Learning系统的主要方法是收集一个用于训练的数据集，在某一特定领域使用某一特定数据集是导致模型缺乏泛化性能的主要原因。\n方法 Multitask learning 多任务学习 \u0026ndash;\u0026gt; 语言模型可以在zero-shot设置中执行下游任务，在没有任何参数或架构修改的情况下\npre-training + supervised finetuning\n模型的优化目标为 p(output|input, task)，具体可以描述为 {task(视作prompt), input, output}：\n例1：a translation training example can be written as the sequence (translate to french, english text, french text) 例2：reading comprehension training example can be written as (answer the question, document, question, answer) 训练数据 Reddit网站上至少包含 3 karma的文章，爬取了4500万个链接，最终获得800万个文件，包含40GB的文本内容 模型 与GPT大致一致\nGPT-3 出发点 大多数语言模型在任务不可知的情况下，仍然需要特定于任务的数据集和特定于任务的微调\n需要针对任务的、包含标注实例的大数据集 在微调数据集上的效果好并不代表模型的泛化性能良好 方法 meta-learning：训练一个泛化性不错的模型\nin-context learning：在后续过程中，即使已知一些训练样本，也不更新模型权重（个人理解就是在提问过程中包含一些训练样本）：\nzero-shot one-shot few-shot 模型及其架构 使用与GPT-2相同的模型和架​​构 Sparse Transformer 8种不同尺寸 参考文献 GPT，GPT-2，GPT-3 论文精读【论文精读】 Improving language understanding by generative pre-training Language models are unsupervised multitask learners Language Models are Few-Shot Learners ","permalink":"https://cspaulia.github.io/cspaulia-blog/posts/gpt/","summary":"\u003ch2 id=\"gpt-1\"\u003eGPT-1\u003c/h2\u003e\n\u003ch3 id=\"出发点\"\u003e出发点\u003c/h3\u003e\n\u003cp\u003e目前尚不清楚哪种类型的优化目标最有效地学习对迁移有效的文本表示（个人理解对于不同的NLP任务，不知道哪种优化目标是最好的）\u003c/p\u003e\n\u003ch3 id=\"方法\"\u003e方法\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e半监督的方法\u003c/li\u003e\n\u003cli\u003eTransformer（用于处理长期依赖性的更多结构化记忆）\u0026ndash;\u0026gt; 强大的迁移性能🔤\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4 id=\"1-非监督预训练unsupervised-pre-training\"\u003e1. 非监督预训练（Unsupervised pre-training）\u003c/h4\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e优化目标：\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e给定一组 unsupervised corpus of tokens $U = \\{u_1, \\cdots , u_n\\}$\u003c/p\u003e\n\u003cp\u003e$$\nL_1(U) = \\sum_i \\log{P(u_i | u_{i-k}, \\cdots, u_{i-1}; \\Theta)}, i \\in {1,\\cdots, n}\n$$\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003ek是上下文窗口的大小，使用具有参数$θ$的神经网络对条件概率$P$进行建模；\u003c/li\u003e\n\u003cli\u003e这里的 $P(u_i | u_{i-k}, \\cdots, u_{i-1}; \\Theta)$ 指的是已知模型参数$θ$与前 n 个token的情况下，预测出第 i 个token的概率\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e由于GPT使用的是非监督预训练方法，在给定一段文本中的 k 个token时，就是要让模型顺利的预测出第 i 个token。因此将每个token的预测概率 $P(u_i | u_{i-k}, \\cdots, u_{i-1}; \\Theta)$ 求和并最大化，就是该模型的优化目标，该目标适用于任何任务。（解决出发点问题）\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e模型架构：\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003emulti-layer Transformer decoder\u003c/p\u003e\n\u003cp\u003e$$\n\\begin{aligned}\nh_0 \u0026amp;= UW_e + W_p \\\\\nh_i \u0026amp;= \\text{transformer block}(h_{i-1}) \\\\\nP(u) \u0026amp;= \\text{softmax}(h_n W_e^T)\n\\end{aligned}\n$$\u003c/p\u003e","title":"GPT系列"},{"content":"LoRA LORA是一种低资源微调大模型方法，出自论文LoRA: Low-Rank Adaptation of Large Language Models。 使用LORA，训练参数仅为整体参数的万分之一、GPU显存使用量减少2/3且不会引入额外的推理耗时.\n核心思想 低秩分解: 不直接更新预训练模型的权重,而是学习低秩分解矩阵 参数效率: 显著减少需要训练的参数数量 原始权重保持: 保持预训练模型的权重不变,只训练额外的低秩矩阵 技术原理 1. 高效微调基本原理 full fine-tuing\n以语言模型为例，在微调过程中模型加载预训练参数$\\Phi_0$进行初始化,并通过最大化条件语言模型概率进行参数更新$\\Phi_0 + \\Delta \\Phi$，即：\n$$ \\max_{\\Phi} \\sum_{(x,y)\\in\\mathcal{Z}} \\sum^{\\lvert y \\rvert}_{t=1} \\log{(P^{\\Phi}(y_t|x,y \u0026lt; t))} $$\n这种微调方式主要的缺点是我们学习到的参数增量$\\Delta \\Phi$的维度和预训练参数$\\Phi_0$是一致的，这种微调方式所需的资源很多，一般被称为full fine-tuing。\n高效微调\n研究者认为可以用更少的参数表示上述要学习的参数增量$\\Delta \\Phi = \\Delta \\Phi(\\Theta)$，其中$\\lvert \\Theta \\rvert \\ll \\lvert \\Phi_0 \\rvert$，原先寻找的优化目标变为寻找：\n$$ \\max_{\\Theta} \\sum_{(x,y)\\in\\mathcal{Z}} \\sum^{\\lvert y \\rvert}_{t=1} \\log{(P^{\\Phi_0 + \\Delta \\Phi(\\Theta)}(y_t|x,y \u0026lt; t))} $$\n这种仅微调一部分参数的方法称为高效微调。针对高效微调，研究者有很多的实现方式(如Adapter、prefixtuing等)。本文作者旨在使用一个低秩矩阵来编码，相比于其他方法，LORA不会增加推理耗时且更便于优化。\n2. 数学表达 Aghajanyan的研究表明：预训练模型拥有极小的内在维度(instrisic dimension)，即存在一个极低维度的参数，微调它和在全参数空间中微调能起到相同的效果。\n给定原始权重矩阵 $W_{\\theta} \\in \\mathbb{R}^{d \\times k}$, LoRA 通过以下方式进行参数更新:\n$$ W = W_{\\theta} + BA $$\n其中:\n$B \\in \\mathbb{R}^{d \\times r}$，初始化为0矩阵 $A \\in \\mathbb{R}^{r \\times k}$，初始化为高斯分布矩阵 $r \\ll \\min{(k, d)}$，r 是秩 (rank),通常远小于 d 和 k 初始化$W = W_{\\theta} + \\mathbf{0} \\times A = W_{\\theta}$ 3. 低秩分解的优势 参数量减少: 从 $d \\times k$ 减少到 $r \\times (d+k)$ 内存效率: 可以使用更小的显存进行训练 计算效率: 降低了计算复杂度 参考文献 LoRA: Low-Rank Adaptation of Large Language Models LORA微调系列(一)：LORA和它的基本原理 ","permalink":"https://cspaulia.github.io/cspaulia-blog/posts/lora/","summary":"\u003ch2 id=\"lora\"\u003eLoRA\u003c/h2\u003e\n\u003cp align=\"center\"\u003e\n  \u003cimg src=\"lora_overview.png\" alt=\"lora_overview\" width=60% /\u003e\n\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eLORA是一种低资源\u003cstrong\u003e微调\u003c/strong\u003e大模型方法，出自论文\u003ca href=\"https://arxiv.org/pdf/2106.09685\"\u003eLoRA: Low-Rank Adaptation of Large Language Models\u003c/a\u003e。\n使用LORA，训练参数仅为整体参数的万分之一、GPU显存使用量减少2/3且不会引入额外的推理耗时.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003ch3 id=\"核心思想\"\u003e核心思想\u003c/h3\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003e低秩分解\u003c/strong\u003e: 不直接更新预训练模型的权重,而是学习低秩分解矩阵\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e参数效率\u003c/strong\u003e: 显著减少需要训练的参数数量\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e原始权重保持\u003c/strong\u003e: 保持预训练模型的权重不变,只训练额外的低秩矩阵\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3 id=\"技术原理\"\u003e技术原理\u003c/h3\u003e\n\u003ch4 id=\"1-高效微调基本原理\"\u003e1. 高效微调基本原理\u003c/h4\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003efull fine-tuing\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e以语言模型为例，在微调过程中模型加载预训练参数$\\Phi_0$进行初始化,并通过最大化条件语言模型概率进行参数更新$\\Phi_0 + \\Delta \\Phi$，即：\u003c/p\u003e\n\u003cp\u003e$$\n\\max_{\\Phi} \\sum_{(x,y)\\in\\mathcal{Z}} \\sum^{\\lvert y \\rvert}_{t=1} \\log{(P^{\\Phi}(y_t|x,y \u0026lt; t))}\n$$\u003c/p\u003e\n\u003cp\u003e这种微调方式主要的缺点是我们学习到的参数增量$\\Delta \\Phi$的维度和预训练参数$\\Phi_0$是一致的，这种微调方式所需的资源很多，一般被称为\u003cstrong\u003efull fine-tuing\u003c/strong\u003e。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e高效微调\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e研究者认为可以用更少的参数表示上述要学习的参数增量$\\Delta \\Phi = \\Delta \\Phi(\\Theta)$，其中$\\lvert \\Theta \\rvert \\ll \\lvert \\Phi_0 \\rvert$，原先寻找的优化目标变为寻找：\u003c/p\u003e\n\u003cp\u003e$$\n\\max_{\\Theta} \\sum_{(x,y)\\in\\mathcal{Z}} \\sum^{\\lvert y \\rvert}_{t=1} \\log{(P^{\\Phi_0 + \\Delta \\Phi(\\Theta)}(y_t|x,y \u0026lt; t))}\n$$\u003c/p\u003e\n\u003cp\u003e这种仅微调一部分参数的方法称为\u003cstrong\u003e高效微调\u003c/strong\u003e。针对高效微调，研究者有很多的实现方式(如Adapter、prefixtuing等)。本文作者旨在使用一个低秩矩阵来编码，相比于其他方法，LORA不会增加推理耗时且更便于优化。\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4 id=\"2-数学表达\"\u003e2. 数学表达\u003c/h4\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\u003ca href=\"https://arxiv.org/abs/2012.13255\"\u003eAghajanyan的研究\u003c/a\u003e表明：预训练模型拥有极小的内在维度(instrisic dimension)，即存在一个极低维度的参数，微调它和在全参数空间中微调能起到相同的效果。\u003c/p\u003e","title":"LoRA: 大模型低秩适配方法详解"},{"content":"自定义post_meta显示 最后编辑(Lastmod)\n在config.yaml中添加：\nfrontmatter: date: - date - publishDate - lastmod lastmod: - :git - :fileModTime - lastmod - date - publishDate 最后编辑时间會根據frontmatter中的順序取值\n:git：會去抓git提交紀錄的日期，且必須於config.yml中啟用enableGitInfo = true(沒試成功) :fileModTime：根據本機的文件最後修改紀錄 lastmod：可以在文章的frontmatter區塊中直接設定 date：可以在文章的frontmatter區塊中直接設定 publishDate：文章發布的日期 修改 post_meta.html 文件\n\u0026lt;!-- layouts/partials/post_meta.html --\u0026gt; {{ $scratch := newScratch }} {{ if not .Date.IsZero }} {{ $scratch.Add \u0026#34;meta\u0026#34; (slice (printf `\u0026lt;span class=\u0026#34;post-meta-item\u0026#34;\u0026gt;\u0026lt;svg xmlns=\u0026#34;http://www.w3.org/2000/svg\u0026#34; width=\u0026#34;16\u0026#34; height=\u0026#34;16\u0026#34; viewBox=\u0026#34;0 0 24 24\u0026#34; fill=\u0026#34;none\u0026#34; stroke=\u0026#34;currentColor\u0026#34; stroke-width=\u0026#34;2\u0026#34; stroke-linecap=\u0026#34;round\u0026#34; stroke-linejoin=\u0026#34;round\u0026#34;\u0026gt;\u0026lt;rect x=\u0026#34;3\u0026#34; y=\u0026#34;4\u0026#34; width=\u0026#34;18\u0026#34; height=\u0026#34;18\u0026#34; rx=\u0026#34;2\u0026#34; ry=\u0026#34;2\u0026#34;\u0026gt;\u0026lt;/rect\u0026gt;\u0026lt;line x1=\u0026#34;16\u0026#34; y1=\u0026#34;2\u0026#34; x2=\u0026#34;16\u0026#34; y2=\u0026#34;6\u0026#34;\u0026gt;\u0026lt;/line\u0026gt;\u0026lt;line x1=\u0026#34;8\u0026#34; y1=\u0026#34;2\u0026#34; x2=\u0026#34;8\u0026#34; y2=\u0026#34;6\u0026#34;\u0026gt;\u0026lt;/line\u0026gt;\u0026lt;line x1=\u0026#34;3\u0026#34; y1=\u0026#34;10\u0026#34; x2=\u0026#34;21\u0026#34; y2=\u0026#34;10\u0026#34;\u0026gt;\u0026lt;/line\u0026gt;\u0026lt;/svg\u0026gt; %s\u0026lt;/span\u0026gt;` (.Date | time.Format (default \u0026#34;January 2, 2006\u0026#34; site.Params.DateFormat)))) }} {{ end }} {{ if not .Lastmod.IsZero }} {{ $scratch.Add \u0026#34;meta\u0026#34; (slice (printf `\u0026lt;span class=\u0026#34;post-meta-item\u0026#34;\u0026gt;\u0026lt;svg xmlns=\u0026#34;http://www.w3.org/2000/svg\u0026#34; width=\u0026#34;16\u0026#34; height=\u0026#34;16\u0026#34; viewBox=\u0026#34;0 0 24 24\u0026#34; fill=\u0026#34;none\u0026#34; stroke=\u0026#34;currentColor\u0026#34; stroke-width=\u0026#34;2\u0026#34; stroke-linecap=\u0026#34;round\u0026#34; stroke-linejoin=\u0026#34;round\u0026#34;\u0026gt;\u0026lt;path d=\u0026#34;M12 19l7-7 3 3-7 7-3-3z\u0026#34;\u0026gt;\u0026lt;/path\u0026gt;\u0026lt;path d=\u0026#34;M18 13l-1.5-7.5L2 2l3.5 14.5L13 18l5-5z\u0026#34;\u0026gt;\u0026lt;/path\u0026gt;\u0026lt;path d=\u0026#34;M2 2l7.586 7.586\u0026#34;\u0026gt;\u0026lt;/path\u0026gt;\u0026lt;circle cx=\u0026#34;11\u0026#34; cy=\u0026#34;11\u0026#34; r=\u0026#34;2\u0026#34;\u0026gt;\u0026lt;/circle\u0026gt;\u0026lt;/svg\u0026gt; %s\u0026lt;/span\u0026gt;` (.Lastmod | time.Format (default \u0026#34;January 2, 2006\u0026#34; site.Params.DateFormat)))) }} {{ end }} {{ if (.Param \u0026#34;ShowWordCount\u0026#34;) }} {{ $scratch.Add \u0026#34;meta\u0026#34; (slice (printf `\u0026lt;span class=\u0026#34;post-meta-item\u0026#34;\u0026gt;\u0026lt;svg xmlns=\u0026#34;http://www.w3.org/2000/svg\u0026#34; width=\u0026#34;16\u0026#34; height=\u0026#34;16\u0026#34; viewBox=\u0026#34;0 0 24 24\u0026#34; fill=\u0026#34;none\u0026#34; stroke=\u0026#34;currentColor\u0026#34; stroke-width=\u0026#34;2\u0026#34; stroke-linecap=\u0026#34;round\u0026#34; stroke-linejoin=\u0026#34;round\u0026#34;\u0026gt;\u0026lt;path d=\u0026#34;M14 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V8z\u0026#34;\u0026gt;\u0026lt;/path\u0026gt;\u0026lt;path d=\u0026#34;M14 2v6h6\u0026#34;\u0026gt;\u0026lt;/path\u0026gt;\u0026lt;line x1=\u0026#34;8\u0026#34; y1=\u0026#34;13\u0026#34; x2=\u0026#34;16\u0026#34; y2=\u0026#34;13\u0026#34;\u0026gt;\u0026lt;/line\u0026gt;\u0026lt;line x1=\u0026#34;8\u0026#34; y1=\u0026#34;17\u0026#34; x2=\u0026#34;16\u0026#34; y2=\u0026#34;17\u0026#34;\u0026gt;\u0026lt;/line\u0026gt;\u0026lt;line x1=\u0026#34;8\u0026#34; y1=\u0026#34;9\u0026#34; x2=\u0026#34;12\u0026#34; y2=\u0026#34;9\u0026#34;\u0026gt;\u0026lt;/line\u0026gt;\u0026lt;/svg\u0026gt; %s\u0026lt;/span\u0026gt;` (i18n \u0026#34;words\u0026#34; .WordCount | default (printf \u0026#34;%d words\u0026#34; .WordCount)))) }} {{ end }} {{ if (.Param \u0026#34;ShowReadingTime\u0026#34;) }} {{ $scratch.Add \u0026#34;meta\u0026#34; (slice (printf `\u0026lt;span class=\u0026#34;post-meta-item\u0026#34;\u0026gt;\u0026lt;svg xmlns=\u0026#34;http://www.w3.org/2000/svg\u0026#34; width=\u0026#34;16\u0026#34; height=\u0026#34;16\u0026#34; viewBox=\u0026#34;0 0 24 24\u0026#34; fill=\u0026#34;none\u0026#34; stroke=\u0026#34;currentColor\u0026#34; stroke-width=\u0026#34;2\u0026#34; stroke-linecap=\u0026#34;round\u0026#34; stroke-linejoin=\u0026#34;round\u0026#34;\u0026gt;\u0026lt;circle cx=\u0026#34;12\u0026#34; cy=\u0026#34;12\u0026#34; r=\u0026#34;10\u0026#34;\u0026gt;\u0026lt;/circle\u0026gt;\u0026lt;polyline points=\u0026#34;12 6 12 12 16 14\u0026#34;\u0026gt;\u0026lt;/polyline\u0026gt;\u0026lt;/svg\u0026gt; %s\u0026lt;/span\u0026gt;` (i18n \u0026#34;read_time\u0026#34; .ReadingTime | default (printf \u0026#34;%d min\u0026#34; .ReadingTime)))) }} {{ end }} {{ with (partial \u0026#34;author.html\u0026#34; .) }} {{ $scratch.Add \u0026#34;meta\u0026#34; (slice (printf `\u0026lt;span class=\u0026#34;post-meta-item\u0026#34;\u0026gt;\u0026lt;svg xmlns=\u0026#34;http://www.w3.org/2000/svg\u0026#34; width=\u0026#34;16\u0026#34; height=\u0026#34;16\u0026#34; viewBox=\u0026#34;0 0 24 24\u0026#34; fill=\u0026#34;none\u0026#34; stroke=\u0026#34;currentColor\u0026#34; stroke-width=\u0026#34;2\u0026#34; stroke-linecap=\u0026#34;round\u0026#34; stroke-linejoin=\u0026#34;round\u0026#34;\u0026gt;\u0026lt;path d=\u0026#34;M20 21v-2a4 4 0 0 0-4-4H8a4 4 0 0 0-4 4v2\u0026#34;\u0026gt;\u0026lt;/path\u0026gt;\u0026lt;circle cx=\u0026#34;12\u0026#34; cy=\u0026#34;7\u0026#34; r=\u0026#34;4\u0026#34;\u0026gt;\u0026lt;/circle\u0026gt;\u0026lt;/svg\u0026gt; %s\u0026lt;/span\u0026gt;` .)) }} {{ end }} {{ with ($scratch.Get \u0026#34;meta\u0026#34;) }} {{ delimit . \u0026#34; ｜ \u0026#34; | safeHTML }} {{ end }} 添加 CSS 样式来调整图标的显示效果\n/* assests/css/extended/blank.css */ .post-meta-item { display: inline-flex; align-items: center; gap: 4px; } .post-meta-item svg { stroke: var(--secondary); } 列表页面隐藏 （可选）\n若不希望列表页出现ReadingTime，则复制一份layouts/partials/post_meta.html，命名为post_meta_list.html，将post_meta_list.html中的如下代码删去\n\u0026lt;!-- layouts/partials/post_meta_list.html --\u0026gt; \u0026lt;!-- 删掉 --\u0026gt; {{ if (.Param \u0026#34;ShowReadingTime\u0026#34;) }} ... {{ end }} 并在layouts/_default/list.html中将：\n\u0026lt;!-- layouts/_default/list.html --\u0026gt; {{- partial \u0026#34;post_meta.html\u0026#34; . -}} 修改为\n\u0026lt;!-- layouts/_default/list.html --\u0026gt; {{- partial \u0026#34;post_meta_list.html\u0026#34; . -}} 代码块改进 代码块缩进设置 在 blank.css 中添加以下代码：\n/* assets/css/extended/blank.css */ .post-content pre { /* 代码块缩进样式 */ margin-left: 2em; /* 缩进距离 */ } .post-content li pre { /* 列表中的代码块额外缩进 */ margin-left: 4em; /* 列表中的代码块缩进更多 */ } PaperMod 主题的语法高亮设置 config.yaml中设置正确的语法高亮：\nparams: # ...existing code... assets: disableHLJS: false # 启用 highlight.js # 设置代码高亮主题 syntax_highlighter: \u0026#34;highlight.js\u0026#34; 高亮代码语法如下：\nprint(\u0026#34;第一行\u0026#34;) print(\u0026#34;第二行\u0026#34;) print(\u0026#34;**这一行会高亮**\u0026#34;) print(\u0026#34;第四行\u0026#34;) 限制代码块长度 限制代码块长度，超出部分滚动\n/* assets/css/extended/blank.css */ .post-content pre { /* 代码块缩进样式 */ max-height: 400px; /* 最大高度，可自定义 */ overflow: auto; /* 超出部分滚动 */ } 设置滚动条大小\n.post-content pre::-webkit-scrollbar { width: 10px; /* 更细的滚动条 */ height: 10px; } 博客文章封面图片缩小并移到侧边 复制list.html\n从themes/PaperMod/layouts/_default/list.html中复制一份list.html放置于layouts/_default/list.html，并将\n\u0026lt;!-- layouts/_default/list.html --\u0026gt; \u0026lt;article class=\u0026#34;{{ $class }}\u0026#34;\u0026gt; {{- $isHidden := (.Param \u0026#34;cover.hiddenInList\u0026#34;) | default (.Param \u0026#34;cover.hidden\u0026#34;) | default false }} {{- partial \u0026#34;cover.html\u0026#34; (dict \u0026#34;cxt\u0026#34; . \u0026#34;IsSingle\u0026#34; false \u0026#34;isHidden\u0026#34; $isHidden) }} \u0026lt;header class=\u0026#34;entry-header\u0026#34;\u0026gt; \u0026lt;h2 class=\u0026#34;entry-hint-parent\u0026#34;\u0026gt; {{- .Title }} {{- if .Draft }} \u0026lt;span class=\u0026#34;entry-hint\u0026#34; title=\u0026#34;Draft\u0026#34;\u0026gt; \u0026lt;svg xmlns=\u0026#34;http://www.w3.org/2000/svg\u0026#34; height=\u0026#34;20\u0026#34; viewBox=\u0026#34;0 -960 960 960\u0026#34; fill=\u0026#34;currentColor\u0026#34;\u0026gt; \u0026lt;path d=\u0026#34;M160-410v-60h300v60H160Zm0-165v-60h470v60H160Zm0-165v-60h470v60H160Zm360 580v-123l221-220q9-9 20-13t22-4q12 0 23 4.5t20 13.5l37 37q9 9 13 20t4 22q0 11-4.5 22.5T862.09-380L643-160H520Zm300-263-37-37 37 37ZM580-220h38l121-122-18-19-19-18-122 121v38Zm141-141-19-18 37 37-18-19Z\u0026#34; /\u0026gt; \u0026lt;/svg\u0026gt; \u0026lt;/span\u0026gt; {{- end }} \u0026lt;/h2\u0026gt; \u0026lt;/header\u0026gt; {{- if (ne (.Param \u0026#34;hideSummary\u0026#34;) true) }} \u0026lt;div class=\u0026#34;entry-content\u0026#34;\u0026gt; \u0026lt;p\u0026gt;{{ .Summary | plainify | htmlUnescape }}{{ if .Truncated }}...{{ end }}\u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; {{- end }} {{- if not (.Param \u0026#34;hideMeta\u0026#34;) }} \u0026lt;footer class=\u0026#34;entry-footer\u0026#34;\u0026gt; {{- partial \u0026#34;post_meta.html\u0026#34; . -}} \u0026lt;/footer\u0026gt; {{- end }} \u0026lt;a class=\u0026#34;entry-link\u0026#34; aria-label=\u0026#34;post link to {{ .Title | plainify }}\u0026#34; href=\u0026#34;{{ .Permalink }}\u0026#34;\u0026gt;\u0026lt;/a\u0026gt; \u0026lt;/article\u0026gt; 修改为\n\u0026lt;!-- layouts/_default/list.html --\u0026gt; \u0026lt;article class=\u0026#34;{{ $class }}\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;post-info\u0026#34;\u0026gt; \u0026lt;header class=\u0026#34;entry-header\u0026#34;\u0026gt; \u0026lt;h2\u0026gt;{{ .Title }}\u0026lt;/h2\u0026gt; \u0026lt;/header\u0026gt; {{- if .Description }} \u0026lt;section class=\u0026#34;entry-content\u0026#34;\u0026gt; \u0026lt;p\u0026gt;{{ .Description }}\u0026lt;/p\u0026gt; \u0026lt;/section\u0026gt; {{- else if (ne (.Param \u0026#34;hideSummary\u0026#34;) true) }} \u0026lt;section class=\u0026#34;entry-content\u0026#34;\u0026gt; \u0026lt;p\u0026gt;{{ .Summary | plainify | htmlUnescape }}{{ if .Truncated }}...{{ end }}\u0026lt;/p\u0026gt; \u0026lt;/section\u0026gt; {{- end }} {{- if not (.Param \u0026#34;hideMeta\u0026#34;) }} \u0026lt;footer class=\u0026#34;entry-footer\u0026#34;\u0026gt; {{- partial \u0026#34;post_meta.html\u0026#34; . -}} \u0026lt;/footer\u0026gt; {{- end }} \u0026lt;/div\u0026gt; {{- $isHidden := (.Param \u0026#34;cover.hiddenInList\u0026#34;) | default (.Param \u0026#34;cover.hidden\u0026#34;) | default false }} {{- partial \u0026#34;cover.html\u0026#34; (dict \u0026#34;cxt\u0026#34; . \u0026#34;IsHome\u0026#34; true \u0026#34;isHidden\u0026#34; $isHidden) }} \u0026lt;a class=\u0026#34;entry-link\u0026#34; aria-label=\u0026#34;post link to {{ .Title | plainify }}\u0026#34; href=\u0026#34;{{ .Permalink }}\u0026#34;\u0026gt;\u0026lt;/a\u0026gt; \u0026lt;/article\u0026gt; 添加自定义样式\n/* assets/css/extended/blank.css */ .post-entry { display: flex; flex-direction: row; align-items: center; } .entry-cover { overflow: hidden; /* padding-left: 18px; */ height: 100%; width: 50%; margin-bottom: unset; border-radius: 12px; /* 你可以根据需要调整圆角大小 */ } .entry-cover img { border-radius: 12px; } .post-info { display: inline-block; overflow: hidden; width: 90%; } 侧边首图放大动画\n/* assets/css/extended/blank.css */ .post-entry img{ transition: all 0.3s ease-out; transform:scale(1,1); } .post-entry:hover img{ transition: all 0.3s ease-out; transform:scale(1.02,1.02); } 自定义 Post Footer 复制single.html 在路径themes/PaperMod/layouts/_default找到single.html这个文件，复制到layouts/_default/single.html这个位置\n修改post-footer段落 找到\n\u0026lt;!-- layouts/_default/single.html --\u0026gt; \u0026lt;footer class=\u0026#34;post-footer\u0026#34;\u0026gt; ... \u0026lt;/footer\u0026gt; 修改为\n\u0026lt;!-- layouts/_default/single.html --\u0026gt; \u0026lt;footer class=\u0026#34;post-footer\u0026#34;\u0026gt; {{- $tags := .Language.Params.Taxonomies.tag | default \u0026#34;tags\u0026#34; }} \u0026lt;p style=\u0026#34;font-size: medium; margin-bottom: 5px; font-weight: bold;\u0026#34;\u0026gt;tags:\u0026lt;/p\u0026gt; \u0026lt;ul class=\u0026#34;post-tags\u0026#34;\u0026gt; {{- range ($.GetTerms $tags) }} \u0026lt;li\u0026gt;\u0026lt;a href=\u0026#34;{{ .Permalink }}\u0026#34;\u0026gt;{{ .LinkTitle }}\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; {{- end }} \u0026lt;/ul\u0026gt; {{- $categories := .Language.Params.Taxonomies.categories | default \u0026#34;categories\u0026#34; }} \u0026lt;p style=\u0026#34;font-size: medium; margin-bottom: 5px; font-weight: bold;\u0026#34;\u0026gt;categories:\u0026lt;/p\u0026gt; \u0026lt;ul class=\u0026#34;post-tags\u0026#34;\u0026gt; {{- range ($.GetTerms $categories) }} \u0026lt;li\u0026gt;\u0026lt;a href=\u0026#34;{{ .Permalink }}\u0026#34;\u0026gt;{{ .LinkTitle }}\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; {{- end }} \u0026lt;/ul\u0026gt; {{- if (.Param \u0026#34;ShowPostNavLinks\u0026#34;) }} {{- partial \u0026#34;post_nav_links.html\u0026#34; . }} {{- end }} {{- if (and site.Params.ShowShareButtons (ne .Params.disableShare true)) }} {{- partial \u0026#34;share_icons.html\u0026#34; . -}} {{- end }} \u0026lt;/footer\u0026gt; 效果 博客末尾放参考链接 在blank.css里加一点样式\n/* assets/css/extended/blank.css */ /* 浅色模式 */ .zhihu-ref { background: #f6f7fa; border-radius: 8px; padding: 1.2em 1.5em 1.2em 1.5em; margin-top: 2em; font-size: 1em; box-shadow: 0 2px 8px rgba(0,0,0,0.03); border-left: 4px solid #0084ff; transition: background 0.3s, border-color 0.3s; } .zhihu-ref-title { font-weight: bold; color: #175199; margin-bottom: 0.5em; font-size: 1.1em; } .zhihu-ref a { color: #175199; } .zhihu-ref a:hover { color: #0084ff; } /* 深色模式（PaperMod主题深色class为 .dark） */ .dark .zhihu-ref { background: #23272e; border-left: 4px solid #3ea6ff; } .dark .zhihu-ref-title, .dark .zhihu-ref a { color: #3ea6ff; } .dark .zhihu-ref a:hover { color: #8cc8ff; } markdown中语法如下\n\u0026lt;hr\u0026gt; \u0026lt;div class=\u0026#34;references\u0026#34;\u0026gt; \u0026lt;h3\u0026gt;参考资料\u0026lt;/h3\u0026gt; \u0026lt;ol\u0026gt; \u0026lt;li\u0026gt;\u0026lt;a href=\u0026#34;https://gohugo.io/documentation/\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;Hugo 官方文档\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;\u0026lt;a href=\u0026#34;https://github.com/adityatelange/hugo-PaperMod\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;PaperMod 主题\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;\u0026lt;a href=\u0026#34;https://www.markdownguide.org/\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;Markdown Guide\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;/ol\u0026gt; \u0026lt;/div\u0026gt; 效果如下\n侧边目录设置 在layouts/partials文件夹下创建toc.html，添加如下代码：\n\u0026lt;!-- layouts/partials/toc.html --\u0026gt; {{- $headers := findRE \u0026#34;\u0026lt;h[1-6].*?\u0026gt;(.|\\n])+?\u0026lt;/h[1-6]\u0026gt;\u0026#34; .Content -}} {{- $has_headers := ge (len $headers) 1 -}} {{- if $has_headers -}} \u0026lt;aside id=\u0026#34;toc-container\u0026#34; class=\u0026#34;toc-container wide\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;toc\u0026#34;\u0026gt; \u0026lt;details {{if (.Param \u0026#34;TocOpen\u0026#34;) }} open{{ end }}\u0026gt; \u0026lt;summary accesskey=\u0026#34;c\u0026#34; title=\u0026#34;(Alt + C)\u0026#34;\u0026gt; \u0026lt;span class=\u0026#34;details\u0026#34;\u0026gt;{{- i18n \u0026#34;toc\u0026#34; | default \u0026#34;Table of Contents\u0026#34; }}\u0026lt;/span\u0026gt; \u0026lt;/summary\u0026gt; \u0026lt;div class=\u0026#34;inner\u0026#34;\u0026gt; {{- $largest := 6 -}} {{- range $headers -}} {{- $headerLevel := index (findRE \u0026#34;[1-6]\u0026#34; . 1) 0 -}} {{- $headerLevel := len (seq $headerLevel) -}} {{- if lt $headerLevel $largest -}} {{- $largest = $headerLevel -}} {{- end -}} {{- end -}} {{- $firstHeaderLevel := len (seq (index (findRE \u0026#34;[1-6]\u0026#34; (index $headers 0) 1) 0)) -}} {{- $.Scratch.Set \u0026#34;bareul\u0026#34; slice -}} \u0026lt;ul\u0026gt; {{- range seq (sub $firstHeaderLevel $largest) -}} \u0026lt;ul\u0026gt; {{- $.Scratch.Add \u0026#34;bareul\u0026#34; (sub (add $largest .) 1) -}} {{- end -}} {{- range $i, $header := $headers -}} {{- $headerLevel := index (findRE \u0026#34;[1-6]\u0026#34; . 1) 0 -}} {{- $headerLevel := len (seq $headerLevel) -}} {{/* get id=\u0026#34;xyz\u0026#34; */}} {{- $id := index (findRE \u0026#34;(id=\\\u0026#34;(.*?)\\\u0026#34;)\u0026#34; $header 9) 0 }} {{- /* strip id=\u0026#34;\u0026#34; to leave xyz, no way to get regex capturing groups in hugo */ -}} {{- $cleanedID := replace (replace $id \u0026#34;id=\\\u0026#34;\u0026#34; \u0026#34;\u0026#34;) \u0026#34;\\\u0026#34;\u0026#34; \u0026#34;\u0026#34; }} {{- $header := replaceRE \u0026#34;\u0026lt;h[1-6].*?\u0026gt;((.|\\n])+?)\u0026lt;/h[1-6]\u0026gt;\u0026#34; \u0026#34;$1\u0026#34; $header -}} {{- if ne $i 0 -}} {{- $prevHeaderLevel := index (findRE \u0026#34;[1-6]\u0026#34; (index $headers (sub $i 1)) 1) 0 -}} {{- $prevHeaderLevel := len (seq $prevHeaderLevel) -}} {{- if gt $headerLevel $prevHeaderLevel -}} {{- range seq $prevHeaderLevel (sub $headerLevel 1) -}} \u0026lt;ul\u0026gt; {{/* the first should not be recorded */}} {{- if ne $prevHeaderLevel . -}} {{- $.Scratch.Add \u0026#34;bareul\u0026#34; . -}} {{- end -}} {{- end -}} {{- else -}} \u0026lt;/li\u0026gt; {{- if lt $headerLevel $prevHeaderLevel -}} {{- range seq (sub $prevHeaderLevel 1) -1 $headerLevel -}} {{- if in ($.Scratch.Get \u0026#34;bareul\u0026#34;) . -}} \u0026lt;/ul\u0026gt; {{/* manually do pop item */}} {{- $tmp := $.Scratch.Get \u0026#34;bareul\u0026#34; -}} {{- $.Scratch.Delete \u0026#34;bareul\u0026#34; -}} {{- $.Scratch.Set \u0026#34;bareul\u0026#34; slice}} {{- range seq (sub (len $tmp) 1) -}} {{- $.Scratch.Add \u0026#34;bareul\u0026#34; (index $tmp (sub . 1)) -}} {{- end -}} {{- else -}} \u0026lt;/ul\u0026gt; \u0026lt;/li\u0026gt; {{- end -}} {{- end -}} {{- end -}} {{- end }} \u0026lt;li\u0026gt; \u0026lt;a href=\u0026#34;#{{- $cleanedID -}}\u0026#34; aria-label=\u0026#34;{{- $header | plainify -}}\u0026#34;\u0026gt;{{- $header | safeHTML -}}\u0026lt;/a\u0026gt; {{- else }} \u0026lt;li\u0026gt; \u0026lt;a href=\u0026#34;#{{- $cleanedID -}}\u0026#34; aria-label=\u0026#34;{{- $header | plainify -}}\u0026#34;\u0026gt;{{- $header | safeHTML -}}\u0026lt;/a\u0026gt; {{- end -}} {{- end -}} \u0026lt;!-- {{- $firstHeaderLevel := len (seq (index (findRE \u0026#34;[1-6]\u0026#34; (index $headers 0) 1) 0)) -}} --\u0026gt; {{- $firstHeaderLevel := $largest }} {{- $lastHeaderLevel := len (seq (index (findRE \u0026#34;[1-6]\u0026#34; (index $headers (sub (len $headers) 1)) 1) 0)) }} \u0026lt;/li\u0026gt; {{- range seq (sub $lastHeaderLevel $firstHeaderLevel) -}} {{- if in ($.Scratch.Get \u0026#34;bareul\u0026#34;) (add . $firstHeaderLevel) }} \u0026lt;/ul\u0026gt; {{- else }} \u0026lt;/ul\u0026gt; \u0026lt;/li\u0026gt; {{- end -}} {{- end }} \u0026lt;/ul\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/details\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/aside\u0026gt; \u0026lt;script\u0026gt; let activeElement; let elements; window.addEventListener(\u0026#39;DOMContentLoaded\u0026#39;, function (event) { checkTocPosition(); elements = document.querySelectorAll(\u0026#39;h1[id],h2[id],h3[id],h4[id],h5[id],h6[id]\u0026#39;); // Make the first header active activeElement = elements[0]; const id = encodeURI(activeElement.getAttribute(\u0026#39;id\u0026#39;)).toLowerCase(); document.querySelector(`.inner ul li a[href=\u0026#34;#${id}\u0026#34;]`).classList.add(\u0026#39;active\u0026#39;); }, false); window.addEventListener(\u0026#39;resize\u0026#39;, function(event) { checkTocPosition(); }, false); window.addEventListener(\u0026#39;scroll\u0026#39;, () =\u0026gt; { // Check if there is an object in the top half of the screen or keep the last item active activeElement = Array.from(elements).find((element) =\u0026gt; { if ((getOffsetTop(element) - window.pageYOffset) \u0026gt; 0 \u0026amp;\u0026amp; (getOffsetTop(element) - window.pageYOffset) \u0026lt; window.innerHeight/2) { return element; } }) || activeElement elements.forEach(element =\u0026gt; { const id = encodeURI(element.getAttribute(\u0026#39;id\u0026#39;)).toLowerCase(); if (element === activeElement){ document.querySelector(`.inner ul li a[href=\u0026#34;#${id}\u0026#34;]`).classList.add(\u0026#39;active\u0026#39;); } else { document.querySelector(`.inner ul li a[href=\u0026#34;#${id}\u0026#34;]`).classList.remove(\u0026#39;active\u0026#39;); } }) }, false); const main = parseInt(getComputedStyle(document.body).getPropertyValue(\u0026#39;--article-width\u0026#39;), 10); const toc = parseInt(getComputedStyle(document.body).getPropertyValue(\u0026#39;--toc-width\u0026#39;), 10); const gap = parseInt(getComputedStyle(document.body).getPropertyValue(\u0026#39;--gap\u0026#39;), 10); function checkTocPosition() { const width = document.body.scrollWidth; if (width - main - (toc * 2) - (gap * 4) \u0026gt; 0) { document.getElementById(\u0026#34;toc-container\u0026#34;).classList.add(\u0026#34;wide\u0026#34;); } else { document.getElementById(\u0026#34;toc-container\u0026#34;).classList.remove(\u0026#34;wide\u0026#34;); } } function getOffsetTop(element) { if (!element.getClientRects().length) { return 0; } let rect = element.getBoundingClientRect(); let win = element.ownerDocument.defaultView; return rect.top + win.pageYOffset; } \u0026lt;/script\u0026gt; {{- end }} 修改css:\n/* assets/css/extended/blank.css */ :root { --nav-width: 1380px; --article-width: 650px; --toc-width: 300px; } .toc { margin: 0 2px 40px 2px; border: 1px solid var(--border); background: var(--entry); border-radius: var(--radius); padding: 0.4em; } .toc-container.wide { position: absolute; height: 100%; border-right: 1px solid var(--border); left: calc((var(--toc-width) + var(--gap)) * -1); top: calc(var(--gap) * 2); width: var(--toc-width); } .wide .toc { position: sticky; top: var(--gap); border: unset; background: unset; border-radius: unset; width: 100%; margin: 0 2px 40px 2px; } .toc details summary { cursor: zoom-in; margin-inline-start: 20px; padding: 12px 0; } .toc details[open] summary { font-weight: 500; } .toc-container.wide .toc .inner { margin: 0; } .active { font-size: 110%; font-weight: 600; } .toc ul { list-style-type: circle; } .toc .inner { margin: 0 0 0 20px; padding: 0px 15px 15px 20px; font-size: 16px; } .toc li ul { margin-inline-start: calc(var(--gap) * 0.5); list-style-type: none; } .toc li { list-style: none; font-size: 0.95rem; padding-bottom: 5px; } .toc li a:hover { color: var(--secondary); } 按照LastMod参数进行文章排序 Posts界面 修改layouts/_default/list.html如下\n\u0026lt;!-- layouts/_default/list.html --\u0026gt; {{- if .IsHome }} {{- $pages = where site.RegularPages \u0026#34;Type\u0026#34; \u0026#34;in\u0026#34; site.Params.mainSections }} {{- $pages = where $pages \u0026#34;Params.hiddenInHomeList\u0026#34; \u0026#34;!=\u0026#34; \u0026#34;true\u0026#34; }} {{- end }} {{- $pages := $pages.ByLastmod.Reverse }} \u0026lt;!-- 添加这行代码 --\u0026gt; {{- $paginator := .Paginate $pages }} archives界面 复制themes/PaperMod/layouts/_default/archives.html至layouts/_default，将\n\u0026lt;!-- layouts/_default/archives.html --\u0026gt; {{- range $pages.GroupByPublishDate \u0026#34;2006\u0026#34; }} ... {{- range .Pages.GroupByDate \u0026#34;January\u0026#34; }} ... {{- range .Pages }} ... {{- end }} ... {{- end }} ... {{- end }} 修改为\n\u0026lt;!-- layouts/_default/archives.html --\u0026gt; {{- range $pages.GroupByParamDate \u0026#34;lastmod\u0026#34; \u0026#34;2006\u0026#34; }} ... {{- range .Pages.GroupByParamDate \u0026#34;lastmod\u0026#34; \u0026#34;January\u0026#34; }} ... {{- range .Pages.ByLastmod.Reverse }} ... {{- end }} ... {{- end }} ... {{- end }} 参考文献 小M平碎碎念-小M平部落格整形手術 CSDN-Hugo博客PaperMod主题目录放在侧边 ","permalink":"https://cspaulia.github.io/cspaulia-blog/posts/hugo-papermod/","summary":"\u003ch2 id=\"自定义post_meta显示\"\u003e自定义post_meta显示\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e最后编辑(Lastmod)\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e在\u003ccode\u003econfig.yaml\u003c/code\u003e中添加：\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-yaml\" data-lang=\"yaml\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"nt\"\u003efrontmatter\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e    \u003c/span\u003e\u003cspan class=\"nt\"\u003edate\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e        \u003c/span\u003e- \u003cspan class=\"l\"\u003edate\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e        \u003c/span\u003e- \u003cspan class=\"l\"\u003epublishDate\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e        \u003c/span\u003e- \u003cspan class=\"l\"\u003elastmod\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e    \u003c/span\u003e\u003cspan class=\"nt\"\u003elastmod\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e        \u003c/span\u003e- \u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"l\"\u003egit\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e        \u003c/span\u003e- \u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"l\"\u003efileModTime\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e        \u003c/span\u003e- \u003cspan class=\"l\"\u003elastmod\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e        \u003c/span\u003e- \u003cspan class=\"l\"\u003edate\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e        \u003c/span\u003e- \u003cspan class=\"l\"\u003epublishDate\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e最后编辑时间會根據frontmatter中的順序取值\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003e:git\u003c/code\u003e：會去抓git提交紀錄的日期，且必須於config.yml中啟用enableGitInfo = true(沒試成功)\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003e:fileModTime\u003c/code\u003e：根據本機的文件最後修改紀錄\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003elastmod\u003c/code\u003e：可以在文章的frontmatter區塊中直接設定\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003edate\u003c/code\u003e：可以在文章的frontmatter區塊中直接設定\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003epublishDate\u003c/code\u003e：文章發布的日期\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e修改 post_meta.html 文件\u003c/strong\u003e\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-html\" data-lang=\"html\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c\"\u003e\u0026lt;!-- layouts/partials/post_meta.html --\u0026gt;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e{{ $scratch := newScratch }}\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e{{ if not .Date.IsZero }}\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e{{ $scratch.Add \u0026#34;meta\u0026#34; (slice (printf `\u003cspan class=\"p\"\u003e\u0026lt;\u003c/span\u003e\u003cspan class=\"nt\"\u003espan\u003c/span\u003e \u003cspan class=\"na\"\u003eclass\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;post-meta-item\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026gt;\u0026lt;\u003c/span\u003e\u003cspan class=\"nt\"\u003esvg\u003c/span\u003e \u003cspan class=\"na\"\u003exmlns\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;http://www.w3.org/2000/svg\u0026#34;\u003c/span\u003e \u003cspan class=\"na\"\u003ewidth\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;16\u0026#34;\u003c/span\u003e \u003cspan class=\"na\"\u003eheight\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;16\u0026#34;\u003c/span\u003e \u003cspan class=\"na\"\u003eviewBox\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;0 0 24 24\u0026#34;\u003c/span\u003e \u003cspan class=\"na\"\u003efill\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;none\u0026#34;\u003c/span\u003e \u003cspan class=\"na\"\u003estroke\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;currentColor\u0026#34;\u003c/span\u003e \u003cspan class=\"na\"\u003estroke-width\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;2\u0026#34;\u003c/span\u003e \u003cspan class=\"na\"\u003estroke-linecap\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;round\u0026#34;\u003c/span\u003e \u003cspan class=\"na\"\u003estroke-linejoin\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;round\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026gt;\u0026lt;\u003c/span\u003e\u003cspan class=\"nt\"\u003erect\u003c/span\u003e \u003cspan class=\"na\"\u003ex\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;3\u0026#34;\u003c/span\u003e \u003cspan class=\"na\"\u003ey\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;4\u0026#34;\u003c/span\u003e \u003cspan class=\"na\"\u003ewidth\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;18\u0026#34;\u003c/span\u003e \u003cspan class=\"na\"\u003eheight\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;18\u0026#34;\u003c/span\u003e \u003cspan class=\"na\"\u003erx\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;2\u0026#34;\u003c/span\u003e \u003cspan class=\"na\"\u003ery\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;2\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026gt;\u0026lt;/\u003c/span\u003e\u003cspan class=\"nt\"\u003erect\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026gt;\u0026lt;\u003c/span\u003e\u003cspan class=\"nt\"\u003eline\u003c/span\u003e \u003cspan class=\"na\"\u003ex1\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;16\u0026#34;\u003c/span\u003e \u003cspan class=\"na\"\u003ey1\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;2\u0026#34;\u003c/span\u003e \u003cspan class=\"na\"\u003ex2\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;16\u0026#34;\u003c/span\u003e \u003cspan class=\"na\"\u003ey2\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;6\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026gt;\u0026lt;/\u003c/span\u003e\u003cspan class=\"nt\"\u003eline\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026gt;\u0026lt;\u003c/span\u003e\u003cspan class=\"nt\"\u003eline\u003c/span\u003e \u003cspan class=\"na\"\u003ex1\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;8\u0026#34;\u003c/span\u003e \u003cspan class=\"na\"\u003ey1\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;2\u0026#34;\u003c/span\u003e \u003cspan class=\"na\"\u003ex2\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;8\u0026#34;\u003c/span\u003e \u003cspan class=\"na\"\u003ey2\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;6\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026gt;\u0026lt;/\u003c/span\u003e\u003cspan class=\"nt\"\u003eline\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026gt;\u0026lt;\u003c/span\u003e\u003cspan class=\"nt\"\u003eline\u003c/span\u003e \u003cspan class=\"na\"\u003ex1\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;3\u0026#34;\u003c/span\u003e \u003cspan class=\"na\"\u003ey1\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;10\u0026#34;\u003c/span\u003e \u003cspan class=\"na\"\u003ex2\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;21\u0026#34;\u003c/span\u003e \u003cspan class=\"na\"\u003ey2\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;10\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026gt;\u0026lt;/\u003c/span\u003e\u003cspan class=\"nt\"\u003eline\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026gt;\u0026lt;/\u003c/span\u003e\u003cspan class=\"nt\"\u003esvg\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026gt;\u003c/span\u003e %s\u003cspan class=\"p\"\u003e\u0026lt;/\u003c/span\u003e\u003cspan class=\"nt\"\u003espan\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026gt;\u003c/span\u003e` (.Date | time.Format (default \u0026#34;January 2, 2006\u0026#34; site.Params.DateFormat)))) }}\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e{{ end }}\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e{{ if not .Lastmod.IsZero }}\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e{{ $scratch.Add \u0026#34;meta\u0026#34; (slice (printf `\u003cspan class=\"p\"\u003e\u0026lt;\u003c/span\u003e\u003cspan class=\"nt\"\u003espan\u003c/span\u003e \u003cspan class=\"na\"\u003eclass\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;post-meta-item\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026gt;\u0026lt;\u003c/span\u003e\u003cspan class=\"nt\"\u003esvg\u003c/span\u003e \u003cspan class=\"na\"\u003exmlns\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;http://www.w3.org/2000/svg\u0026#34;\u003c/span\u003e \u003cspan class=\"na\"\u003ewidth\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;16\u0026#34;\u003c/span\u003e \u003cspan class=\"na\"\u003eheight\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;16\u0026#34;\u003c/span\u003e \u003cspan class=\"na\"\u003eviewBox\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;0 0 24 24\u0026#34;\u003c/span\u003e \u003cspan class=\"na\"\u003efill\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;none\u0026#34;\u003c/span\u003e \u003cspan class=\"na\"\u003estroke\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;currentColor\u0026#34;\u003c/span\u003e \u003cspan class=\"na\"\u003estroke-width\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;2\u0026#34;\u003c/span\u003e \u003cspan class=\"na\"\u003estroke-linecap\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;round\u0026#34;\u003c/span\u003e \u003cspan class=\"na\"\u003estroke-linejoin\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;round\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026gt;\u0026lt;\u003c/span\u003e\u003cspan class=\"nt\"\u003epath\u003c/span\u003e \u003cspan class=\"na\"\u003ed\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;M12 19l7-7 3 3-7 7-3-3z\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026gt;\u0026lt;/\u003c/span\u003e\u003cspan class=\"nt\"\u003epath\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026gt;\u0026lt;\u003c/span\u003e\u003cspan class=\"nt\"\u003epath\u003c/span\u003e \u003cspan class=\"na\"\u003ed\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;M18 13l-1.5-7.5L2 2l3.5 14.5L13 18l5-5z\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026gt;\u0026lt;/\u003c/span\u003e\u003cspan class=\"nt\"\u003epath\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026gt;\u0026lt;\u003c/span\u003e\u003cspan class=\"nt\"\u003epath\u003c/span\u003e \u003cspan class=\"na\"\u003ed\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;M2 2l7.586 7.586\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026gt;\u0026lt;/\u003c/span\u003e\u003cspan class=\"nt\"\u003epath\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026gt;\u0026lt;\u003c/span\u003e\u003cspan class=\"nt\"\u003ecircle\u003c/span\u003e \u003cspan class=\"na\"\u003ecx\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;11\u0026#34;\u003c/span\u003e \u003cspan class=\"na\"\u003ecy\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;11\u0026#34;\u003c/span\u003e \u003cspan class=\"na\"\u003er\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;2\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026gt;\u0026lt;/\u003c/span\u003e\u003cspan class=\"nt\"\u003ecircle\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026gt;\u0026lt;/\u003c/span\u003e\u003cspan class=\"nt\"\u003esvg\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026gt;\u003c/span\u003e %s\u003cspan class=\"p\"\u003e\u0026lt;/\u003c/span\u003e\u003cspan class=\"nt\"\u003espan\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026gt;\u003c/span\u003e` (.Lastmod | time.Format (default \u0026#34;January 2, 2006\u0026#34; site.Params.DateFormat)))) }}\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e{{ end }}\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e{{ if (.Param \u0026#34;ShowWordCount\u0026#34;) }}\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e{{ $scratch.Add \u0026#34;meta\u0026#34; (slice (printf `\u003cspan class=\"p\"\u003e\u0026lt;\u003c/span\u003e\u003cspan class=\"nt\"\u003espan\u003c/span\u003e \u003cspan class=\"na\"\u003eclass\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;post-meta-item\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026gt;\u0026lt;\u003c/span\u003e\u003cspan class=\"nt\"\u003esvg\u003c/span\u003e \u003cspan class=\"na\"\u003exmlns\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;http://www.w3.org/2000/svg\u0026#34;\u003c/span\u003e \u003cspan class=\"na\"\u003ewidth\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;16\u0026#34;\u003c/span\u003e \u003cspan class=\"na\"\u003eheight\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;16\u0026#34;\u003c/span\u003e \u003cspan class=\"na\"\u003eviewBox\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;0 0 24 24\u0026#34;\u003c/span\u003e \u003cspan class=\"na\"\u003efill\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;none\u0026#34;\u003c/span\u003e \u003cspan class=\"na\"\u003estroke\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;currentColor\u0026#34;\u003c/span\u003e \u003cspan class=\"na\"\u003estroke-width\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;2\u0026#34;\u003c/span\u003e \u003cspan class=\"na\"\u003estroke-linecap\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;round\u0026#34;\u003c/span\u003e \u003cspan class=\"na\"\u003estroke-linejoin\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;round\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026gt;\u0026lt;\u003c/span\u003e\u003cspan class=\"nt\"\u003epath\u003c/span\u003e \u003cspan class=\"na\"\u003ed\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;M14 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V8z\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026gt;\u0026lt;/\u003c/span\u003e\u003cspan class=\"nt\"\u003epath\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026gt;\u0026lt;\u003c/span\u003e\u003cspan class=\"nt\"\u003epath\u003c/span\u003e \u003cspan class=\"na\"\u003ed\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;M14 2v6h6\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026gt;\u0026lt;/\u003c/span\u003e\u003cspan class=\"nt\"\u003epath\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026gt;\u0026lt;\u003c/span\u003e\u003cspan class=\"nt\"\u003eline\u003c/span\u003e \u003cspan class=\"na\"\u003ex1\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;8\u0026#34;\u003c/span\u003e \u003cspan class=\"na\"\u003ey1\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;13\u0026#34;\u003c/span\u003e \u003cspan class=\"na\"\u003ex2\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;16\u0026#34;\u003c/span\u003e \u003cspan class=\"na\"\u003ey2\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;13\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026gt;\u0026lt;/\u003c/span\u003e\u003cspan class=\"nt\"\u003eline\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026gt;\u0026lt;\u003c/span\u003e\u003cspan class=\"nt\"\u003eline\u003c/span\u003e \u003cspan class=\"na\"\u003ex1\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;8\u0026#34;\u003c/span\u003e \u003cspan class=\"na\"\u003ey1\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;17\u0026#34;\u003c/span\u003e \u003cspan class=\"na\"\u003ex2\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;16\u0026#34;\u003c/span\u003e \u003cspan class=\"na\"\u003ey2\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;17\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026gt;\u0026lt;/\u003c/span\u003e\u003cspan class=\"nt\"\u003eline\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026gt;\u0026lt;\u003c/span\u003e\u003cspan class=\"nt\"\u003eline\u003c/span\u003e \u003cspan class=\"na\"\u003ex1\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;8\u0026#34;\u003c/span\u003e \u003cspan class=\"na\"\u003ey1\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;9\u0026#34;\u003c/span\u003e \u003cspan class=\"na\"\u003ex2\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;12\u0026#34;\u003c/span\u003e \u003cspan class=\"na\"\u003ey2\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;9\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026gt;\u0026lt;/\u003c/span\u003e\u003cspan class=\"nt\"\u003eline\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026gt;\u0026lt;/\u003c/span\u003e\u003cspan class=\"nt\"\u003esvg\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026gt;\u003c/span\u003e %s\u003cspan class=\"p\"\u003e\u0026lt;/\u003c/span\u003e\u003cspan class=\"nt\"\u003espan\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026gt;\u003c/span\u003e` (i18n \u0026#34;words\u0026#34; .WordCount | default (printf \u0026#34;%d words\u0026#34; .WordCount)))) }}\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e{{ end }}\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e{{ if (.Param \u0026#34;ShowReadingTime\u0026#34;) }}\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e{{ $scratch.Add \u0026#34;meta\u0026#34; (slice (printf `\u003cspan class=\"p\"\u003e\u0026lt;\u003c/span\u003e\u003cspan class=\"nt\"\u003espan\u003c/span\u003e \u003cspan class=\"na\"\u003eclass\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;post-meta-item\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026gt;\u0026lt;\u003c/span\u003e\u003cspan class=\"nt\"\u003esvg\u003c/span\u003e \u003cspan class=\"na\"\u003exmlns\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;http://www.w3.org/2000/svg\u0026#34;\u003c/span\u003e \u003cspan class=\"na\"\u003ewidth\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;16\u0026#34;\u003c/span\u003e \u003cspan class=\"na\"\u003eheight\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;16\u0026#34;\u003c/span\u003e \u003cspan class=\"na\"\u003eviewBox\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;0 0 24 24\u0026#34;\u003c/span\u003e \u003cspan class=\"na\"\u003efill\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;none\u0026#34;\u003c/span\u003e \u003cspan class=\"na\"\u003estroke\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;currentColor\u0026#34;\u003c/span\u003e \u003cspan class=\"na\"\u003estroke-width\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;2\u0026#34;\u003c/span\u003e \u003cspan class=\"na\"\u003estroke-linecap\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;round\u0026#34;\u003c/span\u003e \u003cspan class=\"na\"\u003estroke-linejoin\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;round\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026gt;\u0026lt;\u003c/span\u003e\u003cspan class=\"nt\"\u003ecircle\u003c/span\u003e \u003cspan class=\"na\"\u003ecx\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;12\u0026#34;\u003c/span\u003e \u003cspan class=\"na\"\u003ecy\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;12\u0026#34;\u003c/span\u003e \u003cspan class=\"na\"\u003er\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;10\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026gt;\u0026lt;/\u003c/span\u003e\u003cspan class=\"nt\"\u003ecircle\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026gt;\u0026lt;\u003c/span\u003e\u003cspan class=\"nt\"\u003epolyline\u003c/span\u003e \u003cspan class=\"na\"\u003epoints\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;12 6 12 12 16 14\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026gt;\u0026lt;/\u003c/span\u003e\u003cspan class=\"nt\"\u003epolyline\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026gt;\u0026lt;/\u003c/span\u003e\u003cspan class=\"nt\"\u003esvg\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026gt;\u003c/span\u003e %s\u003cspan class=\"p\"\u003e\u0026lt;/\u003c/span\u003e\u003cspan class=\"nt\"\u003espan\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026gt;\u003c/span\u003e` (i18n \u0026#34;read_time\u0026#34; .ReadingTime | default (printf \u0026#34;%d min\u0026#34; .ReadingTime)))) }}\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e{{ end }}\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e{{ with (partial \u0026#34;author.html\u0026#34; .) }}\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e{{ $scratch.Add \u0026#34;meta\u0026#34; (slice (printf `\u003cspan class=\"p\"\u003e\u0026lt;\u003c/span\u003e\u003cspan class=\"nt\"\u003espan\u003c/span\u003e \u003cspan class=\"na\"\u003eclass\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;post-meta-item\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026gt;\u0026lt;\u003c/span\u003e\u003cspan class=\"nt\"\u003esvg\u003c/span\u003e \u003cspan class=\"na\"\u003exmlns\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;http://www.w3.org/2000/svg\u0026#34;\u003c/span\u003e \u003cspan class=\"na\"\u003ewidth\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;16\u0026#34;\u003c/span\u003e \u003cspan class=\"na\"\u003eheight\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;16\u0026#34;\u003c/span\u003e \u003cspan class=\"na\"\u003eviewBox\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;0 0 24 24\u0026#34;\u003c/span\u003e \u003cspan class=\"na\"\u003efill\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;none\u0026#34;\u003c/span\u003e \u003cspan class=\"na\"\u003estroke\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;currentColor\u0026#34;\u003c/span\u003e \u003cspan class=\"na\"\u003estroke-width\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;2\u0026#34;\u003c/span\u003e \u003cspan class=\"na\"\u003estroke-linecap\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;round\u0026#34;\u003c/span\u003e \u003cspan class=\"na\"\u003estroke-linejoin\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;round\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026gt;\u0026lt;\u003c/span\u003e\u003cspan class=\"nt\"\u003epath\u003c/span\u003e \u003cspan class=\"na\"\u003ed\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;M20 21v-2a4 4 0 0 0-4-4H8a4 4 0 0 0-4 4v2\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026gt;\u0026lt;/\u003c/span\u003e\u003cspan class=\"nt\"\u003epath\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026gt;\u0026lt;\u003c/span\u003e\u003cspan class=\"nt\"\u003ecircle\u003c/span\u003e \u003cspan class=\"na\"\u003ecx\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;12\u0026#34;\u003c/span\u003e \u003cspan class=\"na\"\u003ecy\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;7\u0026#34;\u003c/span\u003e \u003cspan class=\"na\"\u003er\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;4\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026gt;\u0026lt;/\u003c/span\u003e\u003cspan class=\"nt\"\u003ecircle\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026gt;\u0026lt;/\u003c/span\u003e\u003cspan class=\"nt\"\u003esvg\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026gt;\u003c/span\u003e %s\u003cspan class=\"p\"\u003e\u0026lt;/\u003c/span\u003e\u003cspan class=\"nt\"\u003espan\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026gt;\u003c/span\u003e` .)) }}\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e{{ end }}\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e{{ with ($scratch.Get \u0026#34;meta\u0026#34;) }}\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e{{ delimit . \u0026#34; ｜ \u0026#34; | safeHTML }}\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e{{ end }}\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e添加 CSS 样式来调整图标的显示效果\u003c/strong\u003e\u003c/p\u003e","title":"PaperMod进化论"},{"content":"I. CLIP 对比预训练：\n从网络上收集N个图片-文本对（OpenAI收集了4亿个图片文本对）作为正样本；\nN张图片与剩下的N-1张图片对应的文本组成数据对，作为负样本（即文本描述和图片内容不符）；\nN张图片送入图像编码器，对应文本送入文本编码器，将图像特征与文本特征做点积，得到相似度矩阵；\n将矩阵的每一行当作是一个N类预测的结果，以第 i 行为例，为了使第 i 行、第 i 列的值最大（在第 i 行中相似度最大），我们的 label 应该也是 i，将第 i 行与 label 作 cross entropy，即可完成矩阵的优化；\n将矩阵的每一列当作是一个N类预测的结果，以第 i 列为例，为了使第 i 列、第 i 行的值最大（在第 i 列中相似度最大），我们的 label 应该也是 i，将第 i 列与 label 作 cross entropy，即可完成矩阵的优化。\n从 label 中构建数据分类器：\n用文本标签构建句子，送入文本编码器得到文本特征。 用于zero-shot预测：\n将标签构建的文本特征与图像特征进行相似度匹配，从而完成预测。 II. 利用CLIP做语义分割 2.1 LSeg 与CLIP的关系：\n利用已经对齐好的 CLIP 特征空间，将语义标签和像素特征映射到同一空间，通过相似性进行分割预测；\n文本编码器：与CLIP保持一致，训练时不更新参数\u0026#x2744;\u0026#xfe0f;；\n与CLIP不同的点：\n方法 训练方式 文本编码器参数 相似度计算 CLIP 对比学习 可训练 计算图像文本对的相似度 LSeg 有监督学习 冻结 计算图像特征与文本特征之间的相似度 CLIP的输入：多个图像文本对 LSeg的输入：一张图像+标签（可看作图像的描述文本） 2.2 GroupViT 与CLIP和LSeg的关系： 方法 训练方式 相似度计算 CLIP 对比学习 计算图像文本对的相似度 LSeg 有监督学习 计算图像特征与文本特征之间的相似度 GroupViT 对比学习 计算图像文本对的相似度 LSeg的训练方式：利用已经对齐好的 CLIP 特征空间进行有监督训练； GroupViT的训练方式：调整CLIP中视觉编码器的架构，以适应语义分割任务，进行与CLIP一致的对比学习。 架构细节： 模型输入：图像Patchs + 可学习Group Tokens 分割流程：通过Group Block将Patch特征分配给可学习Group Tokens 可学习Group Tokens：类似于聚类中心 III. 利用CLIP做目标检测 3.1 ViLD Vanilla Detector = Head + Classifier + 交叉熵有监督 ViLD-text = Head + 相似度匹配 + 交叉熵有监督 相似度匹配流程（CLIP流程）： n个标签通过提示词工程送入文本编码器得到n个文本编码； 为防止文本编码无法描述所有region embeddings，引入背景编码描述剩余的region embeddings； region embeddings与文本编码和背景编码做相似度匹配，得到n个Text Embeddings和一个Background，这一步替代Classifier，且在训练中冻结\u0026#x2744;\u0026#xfe0f;； ViLD-image = 教师网络 + 学生网络 + L1知识蒸馏 教师网络：CLIP图像编码器 学生网络：Vanilla Detector 为了减少训练量，利用预训练检测模型提前提取m个region embeddings ViLD = ViLD-text + ViLD-image IV. 利用CLIP做Visual Grounding 4.1 GLIP 本质为有监督训练； 计算Regions和Words之间的相似度，从而完成Regions的分类/caption。 模型的训练阶段，必须知道Regions和Caption中Words之间的对应关系，为此： Detection数据集：利用Bounding Boxes的标注构造Caption（例如Banana\u0026ndash;\u0026gt;There is a banana.） Caption数据集：利用在Detection数据集上训练好的GLIP模型在Caption数据集中找到Regions和Words之间的关系，构造伪标签。 V. 利用CLIP做图像生成 5.1 CLIPasso 工作出发点 发现问题：以往的简笔画生成方法，仅适用于某一特定类别\n解决问题：利用CLIP模型强大的泛化性，完成对所有类别的简笔画生成\n工作流程 生成简笔画： 首先利用图像编码器，获取图像的热图 根据热图采样点 通过可学习参数聚合点，生成贝兹曲线，从而获得简笔画 利用CLIP约束生成： 将生成的简笔画和原图送入两个不同的CLIP图像编码器 $L_g$约束两张图的几何信息，越接近越好 $L_s$约束两张图的语义信息，越接近越好 VI. 利用CLIP做视频检索 6.1 CLIP4Clip 工作出发点 CLIP是为图像-文本对设计的模型。对于视频检索任务来说，其本质上是一段文本和多张图像（视频帧）进行匹配，找到最相关的视频帧 CLIP4Clip探索了三种匹配方法; Parameter-free Type：不需要参数的模块，例如均值池化（没考虑时序） Sequential Type：时序模块，例如LSTM和Transformer Tight Type：使用一个Transformer Encoder共同学习文本特征和视频特征，输出相似度 6.2 ActionCLIP 与CLIP4Clip类似\nVII. 利用CLIP做语音识别 7.1 AudioCLIP 添加音频编码器，仿照CLIP架构构造音频-图像对比学习和音频-文本对比学习\nVIII. 利用CLIP做三维理解 8.1 PointCLIP 将点云映射到二维空间； 构造Prompt：Point Cloud Depth Map of a [CLASS] IX. 利用CLIP做深度估计 9.1 DepthCLIP 构建七类文本Prompt：\u0026ldquo;This object is [distance class]\u0026quot;，[distance class]： ’giant’ ’extremely close’ ’close’ ’not in distance’ ’a little remote’ ’far’ ’unseen’ 网络结构与LSeg类似，通过Softmax完成分类预测 参考文献 CLIP 改进工作串讲（上）【论文精读·42】 CLIP 改进工作串讲（下）【论文精读·42】 ","permalink":"https://cspaulia.github.io/cspaulia-blog/posts/clip/","summary":"\u003ch2 id=\"i-clip\"\u003eI. CLIP\u003c/h2\u003e\n\u003cp align=\"center\"\u003e\n  \u003cimg src=\"clip.png\" alt=\"clip\" /\u003e\n\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e对比预训练：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e从网络上收集N个图片-文本对（OpenAI收集了4亿个图片文本对）作为正样本；\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eN张图片与剩下的N-1张图片对应的文本组成数据对，作为负样本（即文本描述和图片内容不符）；\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eN张图片送入图像编码器，对应文本送入文本编码器，将图像特征与文本特征做点积，得到相似度矩阵；\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e将矩阵的每一行当作是一个N类预测的结果，以第 i 行为例，为了使第 i 行、第 i 列的值最大（在第 i 行中相似度最大），我们的 label 应该也是 i，将第 i 行与 label 作 cross entropy，即可完成矩阵的优化；\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e将矩阵的每一列当作是一个N类预测的结果，以第 i 列为例，为了使第 i 列、第 i 行的值最大（在第 i 列中相似度最大），我们的 label 应该也是 i，将第 i 列与 label 作 cross entropy，即可完成矩阵的优化。\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e从 label 中构建数据分类器：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e用文本标签构建句子，送入文本编码器得到文本特征。\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e用于zero-shot预测：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e将标签构建的文本特征与图像特征进行相似度匹配，从而完成预测。\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"ii-利用clip做语义分割\"\u003eII. 利用CLIP做语义分割\u003c/h2\u003e\n\u003ch3 id=\"21-lseg\"\u003e2.1 LSeg\u003c/h3\u003e\n\u003cp align=\"center\"\u003e\n  \u003cimg src=\"lseg.png\" alt=\"lseg\" /\u003e\n\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e与CLIP的关系：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e利用已经对齐好的 CLIP 特征空间，将语义标签和像素特征映射到同一空间，通过相似性进行分割预测；\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e文本编码器：与CLIP保持一致，训练时不更新参数\u0026#x2744;\u0026#xfe0f;；\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e与CLIP不同的点：\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003e方法\u003c/th\u003e\n          \u003cth\u003e训练方式\u003c/th\u003e\n          \u003cth\u003e文本编码器参数\u003c/th\u003e\n          \u003cth\u003e相似度计算\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eCLIP\u003c/td\u003e\n          \u003ctd\u003e对比学习\u003c/td\u003e\n          \u003ctd\u003e可训练\u003c/td\u003e\n          \u003ctd\u003e计算图像文本对的相似度\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eLSeg\u003c/td\u003e\n          \u003ctd\u003e有监督学习\u003c/td\u003e\n          \u003ctd\u003e冻结\u003c/td\u003e\n          \u003ctd\u003e计算图像特征与文本特征之间的相似度\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003cul\u003e\n\u003cli\u003eCLIP的输入：多个图像文本对\u003c/li\u003e\n\u003cli\u003eLSeg的输入：一张图像+标签（可看作图像的描述文本）\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"22-groupvit\"\u003e2.2 GroupViT\u003c/h3\u003e\n\u003cp align=\"center\"\u003e\n  \u003cimg src=\"groupvit_overview.png\" alt=\"groupvit_overview\" width=\"50%\" /\u003e\n\u003c/p\u003e","title":"CLIP及其改进工作"},{"content":"screen基本命令 新建一个screen会话 screen -S \u0026lt;名字\u0026gt; 查看所有screen会话 screen -ls 恢复之前分离的会话 screen -r \u0026lt;会话ID\u0026gt; 退出当前screen会话 键盘点击ctrl+a , 然后按d 查看当前所在会话(id.name) echo $STY 关闭会话 如果在会话之中，输入exit或者Ctrl+d来终止这个会话。成功终止后，如果有其他处于Attached状态的screen界面，他就会跳到那个界面中，如果没有，他就会跳到默认界面上。\n删除会话\nscreen -X -S session_name quit 清理会话 screen -wipe #清理那些dead的会话 ","permalink":"https://cspaulia.github.io/cspaulia-blog/posts/screen/","summary":"\u003ch2 id=\"screen基本命令\"\u003escreen基本命令\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e新建一个screen会话\u003c/li\u003e\n\u003c/ul\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003escreen -S \u0026lt;名字\u0026gt;\n\u003c/code\u003e\u003c/pre\u003e\u003cul\u003e\n\u003cli\u003e查看所有screen会话\u003c/li\u003e\n\u003c/ul\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003escreen -ls\n\u003c/code\u003e\u003c/pre\u003e\u003cul\u003e\n\u003cli\u003e恢复之前分离的会话\u003c/li\u003e\n\u003c/ul\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003escreen -r \u0026lt;会话ID\u0026gt;\n\u003c/code\u003e\u003c/pre\u003e\u003cul\u003e\n\u003cli\u003e退出当前screen会话\u003c/li\u003e\n\u003c/ul\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e键盘点击ctrl+a , 然后按d\n\u003c/code\u003e\u003c/pre\u003e\u003cul\u003e\n\u003cli\u003e查看当前所在会话(id.name)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003eecho $STY\n\u003c/code\u003e\u003c/pre\u003e\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e关闭会话\n如果在会话之中，输入exit或者Ctrl+d来终止这个会话。成功终止后，如果有其他处于Attached状态的screen界面，他就会跳到那个界面中，如果没有，他就会跳到默认界面上。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e删除会话\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003escreen -X -S session_name quit\n\u003c/code\u003e\u003c/pre\u003e\u003cul\u003e\n\u003cli\u003e清理会话\u003c/li\u003e\n\u003c/ul\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003escreen -wipe #清理那些dead的会话\n\u003c/code\u003e\u003c/pre\u003e","title":"终端多路复用工具Screen的用法"},{"content":"Cross Attention 来自博客\n简介 Cross Attention是：\n融合两种不同的嵌入序列的注意力机制 两个序列必须包含相同的维度 两个序列可以来自不同的模态（例如文本、图像、声音） 其中一个序列作为Query的输入，决定了输出的长度 另一个序列作为Key和Value的输入 Cross Attention vs Self-attention Cross Attention与Self-attention只有输入不同。Cross Attention输入为两个维度相同的嵌入序列；Self-attention输入为一个嵌入序列，其KQV均由该序列生成。\nCross Attention算法 拥有两个序列S1、S2 计算S1的K、V 计算S2的Q 根据K和Q计算注意力矩阵 将V应用于注意力矩阵 输出的序列长度与S2一致 $$ \\pmb{\\text{softmax}}((W_Q S_2)(W_K S_1)^\\mathrm{T})W_v S_1 $$\n","permalink":"https://cspaulia.github.io/cspaulia-blog/posts/cross_attention/","summary":"\u003ch2 id=\"cross-attention\"\u003eCross Attention\u003c/h2\u003e\n\u003cp\u003e来自\u003ca href=\"https://vaclavkosar.com/ml/cross-attention-in-transformer-architecture\"\u003e博客\u003c/a\u003e\u003c/p\u003e\n\u003ch3 id=\"简介\"\u003e简介\u003c/h3\u003e\n\u003cp\u003eCross Attention是：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e融合两种不同的嵌入序列的注意力机制\u003c/li\u003e\n\u003cli\u003e两个序列必须包含\u003cstrong\u003e相同的维度\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003e两个序列可以来自不同的模态（例如文本、图像、声音）\u003c/li\u003e\n\u003cli\u003e其中一个序列作为\u003cstrong\u003eQuery的输入\u003c/strong\u003e，决定了输出的长度\u003c/li\u003e\n\u003cli\u003e另一个序列作为\u003cstrong\u003eKey和Value的输入\u003c/strong\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"cross-attention-vs-self-attention\"\u003eCross Attention vs Self-attention\u003c/h3\u003e\n\u003cp\u003eCross Attention与Self-attention只有输入不同。Cross Attention输入为两个维度相同的嵌入序列；Self-attention输入为一个嵌入序列，其KQV均由该序列生成。\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"cross attention\" loading=\"lazy\" src=\"/cspaulia-blog/posts/cross_attention/cross_attention.png\"\u003e\u003c/p\u003e\n\u003ch3 id=\"cross-attention算法\"\u003eCross Attention算法\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e拥有两个序列S1、S2\u003c/li\u003e\n\u003cli\u003e计算S1的K、V\u003c/li\u003e\n\u003cli\u003e计算S2的Q\u003c/li\u003e\n\u003cli\u003e根据K和Q计算注意力矩阵\u003c/li\u003e\n\u003cli\u003e将V应用于注意力矩阵\u003c/li\u003e\n\u003cli\u003e输出的序列长度与S2一致\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e$$\n\\pmb{\\text{softmax}}((W_Q S_2)(W_K S_1)^\\mathrm{T})W_v S_1\n$$\u003c/p\u003e","title":"交叉注意力机制"},{"content":"ReLU $$ \\text{ReLU}(x) = \\max(0, x) $$\nGELU(Gaussian Error Linear Unit) $$ \\text{GELU}(x) = x \\cdot \\Phi(x) $$\n其中$\\Phi(x)$是标准正态分布的累积分布函数（CDF）：\n$$ \\Phi(x) = \\frac{1}{2}[1+\\text{erf}(\\frac{x}{\\sqrt{2}})] $$\n其中$\\text{erf}$是高斯误差函数（error function），因此GELU可写为\n$$ \\text{GELU}(x) = \\frac{x}{2}[1+\\text{erf}(\\frac{x}{\\sqrt{2}})] $$\n可近似为\n$$ \\text{GELU}(x) = 0.5x(1+\\tanh(\\sqrt{\\frac{2}{\\pi}}(x+0.044715x^3))) $$\n直觉理解 GELU 的思想是：\n不再像 ReLU 一样“硬地”把负数截为 0，而是用一个概率加权的方式，让输出平滑地过渡。\n也就是说，它让输入 $x$ 通过一个“高斯门控”：\n当 $x$ 很大时，$\\Phi(x) \\approx 1$，输出 $\\approx x$ 当 $x$ 很小时，$\\Phi(x) \\approx 0$，输出 $\\approx 0$ $x$ 接近 0 时，$\\Phi(x)$ 在 0 和 1 之间平滑变化 → 所以 GELU 比 ReLU 更“柔和”，能保留一些负数输入的信息\n优点 具有更光滑的导数：GELU函数的导数是连续的，这使得在训练深度神经网络时可以更容易地传播梯度，避免了ReLU函数在$x=0$处的导数不连续的问题，从而减少了训练过程中出现的梯度消失问题 可以提高模型的性能：在实际任务中，使用GELU函数的模型通常比使用ReLU函数的模型表现更好，尤其是在自然语言处理和计算机视觉任务中 可以加速收敛：GELU函数在激活函数的非线性变换中引入了类似于sigmoid函数的变换，这使得GELU函数的输出可以落在一个更广的范围内，有助于加速模型的收敛速度 Swish $$ \\text{Swish}(x) = x \\cdot \\sigma(x) = \\frac{x}{1 + e^{-x}} $$\n导数平滑，类似于门控\nSwish可以通过参数$\\beta$进行平滑调整\n$$ \\text{Swish}(x) = x \\cdot \\sigma(\\beta x) = \\frac{x}{1 + e^{-\\beta x}} $$\nGLU(Gated Linear Unit) $$ \\begin{align} [x_1,x_2]\u0026amp;=xW+b \\\\ \\text{GLU}(x_1, x_2) \u0026amp;= x_1 \\odot \\sigma(x_2) \\end{align} $$\n其中：\n输入$x$经线性映射（或卷积）被拆分成两个部分 $x_1, x_2$； $\\sigma$ 是 Sigmoid 函数，作为“门控函数”； $\\odot$ 表示逐元素相乘（Hadamard product）； 第一部分 $x_1$ 是“信息流（content）”，第二部分 $x_2$ 是“控制流（gate）” 直觉理解：信息流 + 控制流 普通的线性层输出：\n$$ y=xW+b $$\n所有输入都被同等处理\n而在 GLU 中，我们为信息流加了一个动态调节门：\n$$ y=content \\times gate $$\n当 $\\sigma(x_2)$ 接近 1 → 内容 $x_1$ 完全通过； 当 $\\sigma(x_2)$ 接近 0 → 内容 $x_1$ 被抑制； 当 $\\sigma(x_2)$ 在中间值 → 内容部分通过 可以理解为：\nGLU 给神经网络每个神经元加上了一个“可学习的开关”，让模型能控制信息在不同路径上的流动强弱\n代码 import torch import torch.nn.functional as F def GLU(x): x1, x2 = x.chunk(2, dim=-1) return x1 * torch.sigmoid(x2) 优点 选择性信息传递：门可以学习“该让哪些特征通过、哪些被压制”，这提高了模型的表达灵活性 缓解梯度消失 / 饱和：Sigmoid 的导数非零，使得梯度能在负区间流动 模型可解释性更强：门值（通常介于 0~1 之间）可以理解为“注意力权重”，可视化后能显示模型关注哪些通道或特征 ReGLU(ReLU-GLU) $$ \\text{ReGLU}(x) = x_1 \\odot \\text{ReLU}(x_2) $$\n使得门控具备稀疏性，计算更便宜\nimport torch from torch import nn class ReGLU(nn.Module): def __init__(self, d_in, d_out): super().__init__() self.w_gate = nn.Linear(d_in, d_out, bias=False) self.w_up = nn.Linear(d_in, d_out, bias=False) self.w_down = nn.Linear(d_out, d_in, bias=False) def forward(self, x): gate = F.relu(self.w_gate(x)) up = self.w_up(x) return self.w_down(gate * up) GEGLU(Gaussian Error GLU) $$ \\text{GEGLU}(x) = x_1 \\odot \\text{GELU}(x_2) $$\n兼顾稀疏与平滑\nimport torch from torch import nn class GEGLU(nn.Module): def __init__(self, d_in, d_out): super().__init__() self.w_gate = nn.Linear(d_in, d_out, bias=False) self.w_up = nn.Linear(d_in, d_out, bias=False) self.w_down = nn.Linear(d_out, d_in, bias=False) def forward(self, x): gate = F.gelu(self.w_gate(x)) up = self.w_up(x) return self.w_down(gate * up) SwiGLU(Swish-GLU) $$ \\text{SwiGLU}(x) = x_1 \\odot \\text{Swish}(x_2) $$\nimport troch from torch import nn class SwiGLU(nn.Module): def __init__(self, d_in, d_out, beta=1.0): super().__init__() self.beta = beta self.w_gate = nn.Linear(d_in, d_out, bias=False) self.w_up = nn.Linear(d_in, d_out, bias=False) self.w_down = nn.Linear(d_out, d_in, bias=False) def forward(self, x): gate = self.w_gate(x) gate = gate * torch.sigmoid(self.beta * gate) # Swish up = self.w_up(x) return self.w_down(gate * up) ","permalink":"https://cspaulia.github.io/cspaulia-blog/posts/activation/","summary":"\u003ch3 id=\"relu\"\u003eReLU\u003c/h3\u003e\n\u003cp\u003e$$\n\\text{ReLU}(x) = \\max(0, x)\n$$\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"ReLU\" loading=\"lazy\" src=\"/cspaulia-blog/posts/activation/activation_relu.png\"\u003e\u003c/p\u003e\n\u003chr\u003e\n\u003ch3 id=\"gelugaussian-error-linear-unit\"\u003eGELU(Gaussian Error Linear Unit)\u003c/h3\u003e\n\u003cp\u003e$$\n\\text{GELU}(x) = x \\cdot \\Phi(x)\n$$\u003c/p\u003e\n\u003cp\u003e其中$\\Phi(x)$是标准正态分布的累积分布函数（CDF）：\u003c/p\u003e\n\u003cp\u003e$$\n\\Phi(x) = \\frac{1}{2}[1+\\text{erf}(\\frac{x}{\\sqrt{2}})]\n$$\u003c/p\u003e\n\u003cp\u003e其中$\\text{erf}$是高斯误差函数（error function），因此GELU可写为\u003c/p\u003e\n\u003cp\u003e$$\n\\text{GELU}(x) = \\frac{x}{2}[1+\\text{erf}(\\frac{x}{\\sqrt{2}})]\n$$\u003c/p\u003e\n\u003cp\u003e可近似为\u003c/p\u003e\n\u003cp\u003e$$\n\\text{GELU}(x) = 0.5x(1+\\tanh(\\sqrt{\\frac{2}{\\pi}}(x+0.044715x^3)))\n$$\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"GELU_Derivative\" loading=\"lazy\" src=\"/cspaulia-blog/posts/activation/activation_gelu.png\"\u003e\u003c/p\u003e\n\u003ch4 id=\"直觉理解\"\u003e直觉理解\u003c/h4\u003e\n\u003cp\u003eGELU 的思想是：\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e不再像 ReLU 一样“硬地”把负数截为 0，而是用一个概率加权的方式，让输出平滑地过渡。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e也就是说，它让输入 $x$ 通过一个“高斯门控”：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e当 $x$ 很大时，$\\Phi(x) \\approx 1$，输出 $\\approx x$\u003c/li\u003e\n\u003cli\u003e当 $x$ 很小时，$\\Phi(x) \\approx 0$，输出 $\\approx 0$\u003c/li\u003e\n\u003cli\u003e$x$ 接近 0 时，$\\Phi(x)$ 在 0 和 1 之间平滑变化\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e→ 所以 GELU 比 ReLU 更“柔和”，能保留一些负数输入的信息\u003c/p\u003e","title":"收集N个激活函数"},{"content":"Layer Normalization 在上图中，$N$表示样本轴，$C$表示通道轴，$F$是每个通道的特征数量。BN如右侧所示，它是取不同样本的同一个通道的特征做归一化；LN则是如左侧所示，它取的是同一个样本的不同通道做归一化\n1. BN的问题 1.1. BN与Batch Size BN是按照样本数计算归一化统计量的，当样本数很少时，比如说只有4个，这四个样本的均值和方差便不能反映全局的统计分布息，所以基于少量样本的BN的效果会变得很差。\n1.2. BN与RNN 在一个batch中，通常各个样本的长度都是不同的，当统计到比较靠后的时间片时，例如上图中$t\u0026gt;4$时，这时只有一个样本还有数据，基于这个样本的统计信息不能反映全局分布，所以这时BN的效果并不好。\n另外如果在测试时我们遇到了长度大于任何一个训练样本的测试样本，我们无法找到保存的归一化统计量，所以BN无法运行。\n2. LN详解 2.1. MLP中的LN 先看MLP中的LN。设$H$是一层中隐层节点的数量，$l$是MLP的层数，我们可以计算LN的归一化统计量$\\mu$和$\\sigma$：\n$$ \\mu^{l} = \\frac{1}{H} \\sum_{i=1}^{H} a^l_i ~~~~~~~ \\sigma^{l} = \\sqrt{\\frac{1}{H} \\sum_{i=1}^{H}(a^l_i-\\mu^l)^2} $$\n注意上面统计量的计算是和样本数量没有关系的，它的数量只取决于隐层节点的数量，所以只要隐层节点的数量足够多，我们就能保证LN的归一化统计量足够具有代表性。通过$\\mu^{l}$和$\\sigma^{l}$ 可以得到归一化后的值：\n$$ \\hat{a}^l = \\frac{a^l-\\mu^l}{\\sqrt{(\\sigma^l)^2+\\epsilon}} \\tag{1} $$\n其中$\\epsilon$是一个很小的小数，防止除0。\n在LN中我们也需要一组参数来保证归一化操作不会破坏之前的信息，在LN中这组参数叫做增（gain）$g$和偏置（bias）$b$。假设激活函数为$f$，最终LN的输出为：\n$$ h^l = f(g^l \\odot \\hat{a}^l + b^l) \\tag{2} $$\n合并公式(1)和(2)并忽略参数$l$，有：\n$$ h=f(\\frac{g}{\\sqrt{\\sigma^2+\\epsilon}} \\odot (a-\\mu) + b) $$\n2.2. RNN中的LN 对于RNN时刻$t$时的节点，其输入是$t-1$时刻的隐层状态$h^t$和$t$时刻的输入数据$\\text{x}_t$，可以表示为：\n$$ \\text{a}^t = W_{hh}h^{t-1}+W_{xh}\\text{x}^{t} $$\n接着我们便可以在$\\text{a}^t$上采取和1.1节中完全相同的归一化过程：\n$$ h^t=f(\\frac{g}{\\sqrt{\\sigma^2+\\epsilon}} \\odot (a^t-\\mu^t) + b) ~~~~~~ \\mu^{t} = \\frac{1}{H} \\sum_{i=1}^{H} a^t_i ~~~~~~~ \\sigma^{l} = \\sqrt{\\frac{1}{H} \\sum_{i=1}^{H}(a^t_i-\\mu^t)^2} $$\n","permalink":"https://cspaulia.github.io/cspaulia-blog/posts/norm/","summary":"\u003ch3 id=\"layer-normalization\"\u003eLayer Normalization\u003c/h3\u003e\n\u003cp align=\"center\"\u003e\n  \u003cimg src=\"LNvsBN.jpg\" alt=\"LNvsBN\" /\u003e\n\u003c/p\u003e\n\u003cp\u003e在上图中，$N$表示样本轴，$C$表示通道轴，$F$是每个通道的特征数量。BN如右侧所示，它是取\u003cstrong\u003e不同样本的同一个通道\u003c/strong\u003e的特征做归一化；LN则是如左侧所示，它取的是\u003cstrong\u003e同一个样本的不同通道\u003c/strong\u003e做归一化\u003c/p\u003e\n\u003ch4 id=\"1-bn的问题\"\u003e1. BN的问题\u003c/h4\u003e\n\u003ch5 id=\"11-bn与batch-size\"\u003e1.1. BN与Batch Size\u003c/h5\u003e\n\u003cp\u003eBN是按照\u003cstrong\u003e样本数\u003c/strong\u003e计算归一化统计量的，当样本数很少时，比如说只有4个，这四个样本的均值和方差便不能反映全局的统计分布息，所以基于少量样本的BN的效果会变得很差。\u003c/p\u003e\n\u003ch5 id=\"12-bn与rnn\"\u003e1.2. BN与RNN\u003c/h5\u003e\n\u003cp align=\"center\"\u003e\n  \u003cimg src=\"RNN.jpg\" alt=\"RNN\" /\u003e\n\u003c/p\u003e\n\u003cp\u003e在一个batch中，通常各个样本的长度都是不同的，当统计到比较靠后的时间片时，例如上图中$t\u0026gt;4$时，这时只有一个样本还有数据，基于这个样本的统计信息不能反映全局分布，所以这时BN的效果并不好。\u003c/p\u003e\n\u003cp\u003e另外如果在测试时我们遇到了长度大于任何一个训练样本的测试样本，我们无法找到保存的归一化统计量，所以BN无法运行。\u003c/p\u003e\n\u003ch4 id=\"2-ln详解\"\u003e2. LN详解\u003c/h4\u003e\n\u003ch5 id=\"21-mlp中的ln\"\u003e2.1. MLP中的LN\u003c/h5\u003e\n\u003cp\u003e先看MLP中的LN。设$H$是一层中隐层节点的数量，$l$是MLP的层数，我们可以计算LN的归一化统计量$\\mu$和$\\sigma$：\u003c/p\u003e\n\u003cp\u003e$$\n\\mu^{l} = \\frac{1}{H} \\sum_{i=1}^{H} a^l_i ~~~~~~~\n\\sigma^{l} = \\sqrt{\\frac{1}{H} \\sum_{i=1}^{H}(a^l_i-\\mu^l)^2}\n$$\u003c/p\u003e\n\u003cp\u003e注意上面统计量的计算是和样本数量没有关系的，它的数量只取决于隐层节点的数量，所以只要隐层节点的数量足够多，我们就能保证LN的归一化统计量足够具有代表性。通过$\\mu^{l}$和$\\sigma^{l}$\n可以得到归一化后的值：\u003c/p\u003e\n\u003cp\u003e$$\n\\hat{a}^l = \\frac{a^l-\\mu^l}{\\sqrt{(\\sigma^l)^2+\\epsilon}} \\tag{1}\n$$\u003c/p\u003e\n\u003cp\u003e其中$\\epsilon$是一个很小的小数，防止除0。\u003c/p\u003e\n\u003cp\u003e在LN中我们也需要一组参数来保证归一化操作不会破坏之前的信息，在LN中这组参数叫做增（gain）$g$和偏置（bias）$b$。假设激活函数为$f$，最终LN的输出为：\u003c/p\u003e\n\u003cp\u003e$$\nh^l = f(g^l \\odot \\hat{a}^l + b^l) \\tag{2}\n$$\u003c/p\u003e\n\u003cp\u003e合并公式(1)和(2)并忽略参数$l$，有：\u003c/p\u003e\n\u003cp\u003e$$\nh=f(\\frac{g}{\\sqrt{\\sigma^2+\\epsilon}} \\odot (a-\\mu) + b)\n$$\u003c/p\u003e\n\u003ch5 id=\"22-rnn中的ln\"\u003e2.2. RNN中的LN\u003c/h5\u003e\n\u003cp\u003e对于RNN时刻$t$时的节点，其输入是$t-1$时刻的隐层状态$h^t$和$t$时刻的输入数据$\\text{x}_t$，可以表示为：\u003c/p\u003e\n\u003cp\u003e$$\n\\text{a}^t = W_{hh}h^{t-1}+W_{xh}\\text{x}^{t}\n$$\u003c/p\u003e\n\u003cp\u003e接着我们便可以在$\\text{a}^t$上采取和1.1节中完全相同的归一化过程：\u003c/p\u003e\n\u003cp\u003e$$\nh^t=f(\\frac{g}{\\sqrt{\\sigma^2+\\epsilon}} \\odot (a^t-\\mu^t) + b) ~~~~~~\n\\mu^{t} = \\frac{1}{H} \\sum_{i=1}^{H} a^t_i ~~~~~~~\n\\sigma^{l} = \\sqrt{\\frac{1}{H} \\sum_{i=1}^{H}(a^t_i-\\mu^t)^2}\n$$\u003c/p\u003e","title":"收集N个Norm方法"},{"content":"上传本地文件到Github库 1. 在GitHub上创建仓库（远程仓库） 在 GitHub 上创建一个新的代码仓库\n2. 安装/配置Git 安装略，配置 Git：\ngit config --global user.name \u0026quot;Your Name\u0026quot; git config --global user.email \u0026quot;your_email@example.com\u0026quot; 这里的 \u0026ldquo;Your Name\u0026rdquo; 和 \u0026ldquo;your_email@example.com\u0026rdquo; 分别为你的用户名和邮箱地址\n检查 Git 是否已经配置用户名和邮箱：\ngit config --global user.name git config --global user.email 3. 上传文件到Github（本地仓库–\u0026gt;远程仓库） 初始化 Git 仓库, 执行以下命令：\ngit init 将 csj_project 项目文件夹添加到本地仓库中，执行以下命令：\ngit add csj_project/ #或者输入 git add . 将当前工作目录中的更改保存到本地代码仓库中，执行以下命令：\ngit commit -m \u0026quot;Initial commit\u0026quot; 在 GitHub 上创建一个新的远程仓库，获取复制该仓库的 SSH 或 HTTPS 链接\n将本地仓库与远程仓库进行关联，执行以下命令：\ngit remote add origin \u0026lt;远程仓库链接\u0026gt; \u0026lt;远程仓库链接\u0026gt;就是你刚才复制的仓库的 SSH 或 HTTPS 链接，例如我的就是： https://github.com/CSPaulia/(库的名称).git 完整命令 git remote add origin https://github.com/CSPaulia/(库的名称).git 将本地仓库中的代码推送到远程仓库中，执行以下命令：\n#git push origin 分支名 #完整命令 git push -u origin master ","permalink":"https://cspaulia.github.io/cspaulia-blog/posts/github-tips/","summary":"\u003ch2 id=\"上传本地文件到github库\"\u003e上传本地文件到Github库\u003c/h2\u003e\n\u003ch3 id=\"1-在github上创建仓库远程仓库\"\u003e1. 在GitHub上创建仓库（远程仓库）\u003c/h3\u003e\n\u003cp\u003e在 GitHub 上创建一个新的代码仓库\u003c/p\u003e\n\u003ch3 id=\"2-安装配置git\"\u003e2. 安装/配置Git\u003c/h3\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e安装略，配置 Git：\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e git config --global user.name \u0026quot;Your Name\u0026quot;\n git config --global user.email \u0026quot;your_email@example.com\u0026quot;\n\u003c/code\u003e\u003c/pre\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e这里的 \u0026ldquo;Your Name\u0026rdquo; 和 \u0026ldquo;\u003ca href=\"mailto:your_email@example.com\"\u003eyour_email@example.com\u003c/a\u003e\u0026rdquo; 分别为你的用户名和邮箱地址\u003c/p\u003e\n\u003col start=\"3\"\u003e\n\u003cli\u003e\n\u003cp\u003e检查 Git 是否已经配置用户名和邮箱：\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e git config --global user.name\n git config --global user.email\n\u003c/code\u003e\u003c/pre\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3 id=\"3-上传文件到github本地仓库远程仓库\"\u003e3. 上传文件到Github（本地仓库–\u0026gt;远程仓库）\u003c/h3\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e初始化 Git 仓库, 执行以下命令：\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e git init\n\u003c/code\u003e\u003c/pre\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e将 csj_project 项目文件夹添加到本地仓库中，执行以下命令：\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e git add csj_project/\n #或者输入\n git add .\n\u003c/code\u003e\u003c/pre\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e将当前工作目录中的更改保存到本地代码仓库中，执行以下命令：\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e git commit -m \u0026quot;Initial commit\u0026quot;\n\u003c/code\u003e\u003c/pre\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e在 GitHub 上创建一个新的远程仓库，获取复制该仓库的 SSH 或 HTTPS 链接\u003c/p\u003e","title":"如何上传本地文件到Github库"},{"content":"回复流程 整理罗列所有审稿人的意见，并进行分类\n约老师、约同门师兄姐妹开始讨论，给出回答\n整理所有需要补充的实验，估计大概要用到多少的算力资源\n写rebuttal文档\n论据准备\n理论论证：给出详细的推导过程，把过程给师兄、老师看 实验论证：多次检查实验结果 引用论证：明确给出论据的位置（把arXiv的链接贴出来） 表达要求\n用第二人称称呼审稿人（拉近距离） 态度诚恳、有理有据、逻辑清晰、有人情味的表达 撰写流程\n先写中文回答 DeepL翻译 再GPT润色 写完之后，给老师、师兄过目！！！！再统一进行回复。\n如果审稿人继续回复，则继续讨论：\n包括继续和师兄、老师进行一对一的交流 更新rebuttal文档 ","permalink":"https://cspaulia.github.io/cspaulia-blog/posts/rebuttal/writing-tips-rebuttal/","summary":"\u003ch2 id=\"回复流程\"\u003e回复流程\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e整理罗列\u003c/strong\u003e所有审稿人的意见，并进行分类\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e约老师、约同门师兄姐妹开始\u003cstrong\u003e讨论\u003c/strong\u003e，给出回答\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e整理所有需要补充的实验\u003c/strong\u003e，估计大概要用到多少的\u003cstrong\u003e算力资源\u003c/strong\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e写rebuttal文档\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e论据准备\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e理论论证：给出详细的推导过程，把过程给师兄、老师看\u003c/li\u003e\n\u003cli\u003e实验论证：多次检查实验结果\u003c/li\u003e\n\u003cli\u003e引用论证：明确给出论据的位置（把arXiv的链接贴出来）\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e表达要求\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e用第二人称称呼审稿人（拉近距离）\u003c/li\u003e\n\u003cli\u003e态度诚恳、有理有据、逻辑清晰、有人情味的表达\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e撰写流程\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e先写中文回答\u003c/li\u003e\n\u003cli\u003eDeepL翻译\u003c/li\u003e\n\u003cli\u003e再GPT润色\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e写完之后，\u003cstrong\u003e给老师、师兄过目\u003c/strong\u003e！！！！再统一进行回复。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e如果审稿人继续回复，则继续讨论：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e包括继续和师兄、老师进行一对一的交流\u003c/li\u003e\n\u003cli\u003e更新rebuttal文档\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e","title":"论文回复方法（Rebuttal Method）"},{"content":"分类任务损失函数 交叉熵（Cross Entropy） $$ \\text{H}_p(q) = \\sum_x q(x) \\log_2(\\frac{1}{p(x)}) = - \\sum_x q(x) \\log_2(p(x)) $$\n交叉熵为我们提供了一种表达两种概率分布的差异的方法。p和q的分布越不相同，p相对于q的交叉熵将越大于p的熵。\n在实际计算中，\n$$ \\text{L} = - \\sum_x q(y|x) \\log_2(p(y|x)) = - \\frac{1}{N} \\sum_x \\sum_c y_{xc} \\log_2(p(y_c|x)) $$\n其中，$N$表示样本数量，$x$表示样本，$c$表示类别，$y_{xc}$表示类别为$c$时$x$的预测标签，只有$c$与真实标签的类别$\\hat{c}$相同时，$y_{x\\hat{c}} = 1$，即$q(y_{\\hat{c}}|x)=1/N$，其余类别$y_{xc} = 0$，即$q(y_c|x)=0/N=0$。\n举个例子，\n预测（softmax归一化后） 真实值 [0.1, 0.2, 0.7] [0, 0, 1] [0.3, 0.4, 0.3] [0, 1, 0] [0.1, 0.2, 0.7] [1, 0, 0] 计算损失函数值：\n$$ \\text{sample 1 Loss} = - (0 \\times \\log{0.1} + 0 \\times \\log{0.2} + 1 \\times \\log{0.7}) = 0.36 $$\n$$ \\text{sample 2 Loss} = - (0 \\times \\log{0.3} + 1 \\times \\log{0.4} + 0 \\times \\log{0.3}) = 0.92 $$\n$$ \\text{sample 3 Loss} = - (1 \\times \\log{0.1} + 0 \\times \\log{0.2} + 0 \\times \\log{0.7}) = 2.30 $$\n$$ \\text{L} = \\frac{0.36+0.92+2.3}{3} = 1.19 $$\nKL 散度（KL Divergence） $$ \\text{D}_{\\text{KL}}(q | p) = - \\sum_i q(x) \\log_2(p(x)) + \\sum_x p(x) \\log_2(p(x)) = \\text{H}_p(q) - \\text{H}(p) $$\n在交叉熵的基础上减去了p的熵，衡量了两个分布之间的距离。\n在神经网络的训练当中，由于p往往是标签的分布，p的熵值是确定的。所以KL散度和交叉熵是等价的。但是由于交叉熵不惜要计算信息熵，计算更加简单，所以交叉熵使用更加广泛。\n二值交叉熵（Binary Cross Entropy） 模型预测结果：\n$$ P_\\theta(y=1)=\\theta ~~~~~~~ P_\\theta(y=0)=1 - \\theta $$\n合并上面两个式子，得到：\n$$ p_\\theta(y) = \\theta^y(1-\\theta)^{(1-y)} $$\n观测到这些数据点的对数似然为：\n$$ l(\\theta) = \\log \\prod^N_{i=1} p_\\theta(y_i) = \\log \\prod^N_{i=1}\\theta^y(1-\\theta)^{(1-y)} = \\sum_{i=1}^N [y_i\\log \\theta + (1-y_i)\\log(1-\\theta)] $$\n这个损失函数就是$y_i$与$\\theta$的交叉熵$H_y(\\theta)$。\n平衡交叉熵（Balenced Cross Entropy） 为了解决样本数量不平衡这个问题，我们可以选择给Cross Entropy添加权重。以二分类问题举例，Binary Cross Entropy已经介绍过Binary Cross Entropy：\n$$ \\text{L} = - \\sum_{i=1}^N [y_i\\log p + (1-y_i)\\log(1-p)] $$\n改写一下，\n$$ \\text{L} = \\begin{cases} -\\log(p) \u0026amp; \\text{if}~y=1 \\\\ -\\log(1-p) \u0026amp; \\text{otherwise} \\end{cases} $$\n再改写一下，\n$$ p_t= \\begin{cases} \u0026amp; p \u0026amp; \\text{if}~y=1 \\\\ \u0026amp; 1-p \u0026amp; \\text{otherwise} \\end{cases} $$\n$$ \\text{L} = -\\log(p_t) $$\n添加权重，\n$$ \\text{L} = -\\alpha_t\\log(p_t) $$\n其中$y=1$时$\\alpha_t=\\alpha$；$y=0$时$\\alpha_t=1-\\alpha$。$\\frac{\\alpha}{1-\\alpha}=\\frac{n}{m}$，$n$为$y=0$的样本（负样本）个数，$m$为$y=1$的样本（正样本）个数。\nBalenced Cross Entropy确实解决了样本不均衡问题，但并未解决样本难易问题。为解决这个问题，详见Focal Loss.\nFocal Loss $$ \\text{FL}(p_t) = (1-p_t)^\\gamma\\log(p_t) $$\n$p_t$是模型预测的结果的类别概率值。$−\\log(p_t)$和交叉熵损失函数一致，因此当前样本类别对应的那个$p_t$如果越小，说明预测越不准确，那么$(1-p_t)^{\\gamma}$这一项就会增大，这一项也作为困难样本的系数，预测越不准，Focal Loss越倾向于把这个样本当作困难样本，这个系数也就越大，目的是让困难样本对损失和梯度的贡献更大。\n前面的$\\alpha_t$是类别权重系数。如果你有一个类别不平衡的数据集，那么你肯定想对数量少的那一类在loss贡献上赋予一个高权重，这个$\\alpha_t$就起到这样的作用。因此，$\\alpha_t$应该是一个向量，向量的长度等于类别的个数，用于存放各个类别的权重。一般来说$\\alpha_t$中的值为每一个类别样本数量的倒数，相当于平衡样本的数量差距\nLovasz Loss Lovasz Loss的推导 IoU (intersection-over-union，也叫jaccard index)是自然图像分割比赛中常用的一个衡量分割效果的评价指标，所以一个自然的想法就是能否将IoU作为loss function来直接优化。交并比公式：\n$$ J_c(y^*, \\widetilde{y}) = \\frac{ | { y^* = c } \\cap { \\widetilde{y} = c } | }{ | { y^* = c } \\cup { \\widetilde{y} = c } | } $$\n其中$y^{*}$表示Ground Truth标签，$\\widetilde{y}$表示预测标签，$\\vert \\cdot \\vert$表示集合中的元素个数。可以看出上式的值是介于0到1之间的，由此可以设计出损失函数：\n$$ \\Delta_{J_c}(y^{*},\\widetilde{y})=1-J_c(y^{*},\\widetilde{y}) $$\n这个损失函数是离散的，无法直接求导，需要对其做光滑延拓。\n改写一下$\\Delta_{J_c}$,\n$$ \\Delta_{J_c} = 1-J_c(y^{*},\\widetilde{y}) = \\frac{\\vert M_c \\vert}{\\vert {y^{*}=c} \\cup M_c \\vert} \\tag{1} $$\n其中，$M_c(y^{*},\\widetilde{y}) = {y^{*}=c,\\widetilde{y}\\neq c} \\cup {y^{*} \\neq c,\\widetilde{y}=c}$，$M_c$是损失函数的自变量，它表达网络分割结果与Ground Truth标签不匹配的集合。$M_c$的定义域为${0,1}^p$，即$M_c \\in {0,1}^p$，$p$表示集合$M_c$中像素的个数。\n由于(1)是次模（submodular）函数，故可以对其做光滑延拓。\n定义1 若一个集合函数$\\Delta:{0,1}^p \\rightarrow \\mathbb{R}$对于所有的集合$A,B \\in {0,1}^p$满足\n$$ \\Delta(A) + \\Delta(B) \\geq \\Delta(A \\cup B) + \\Delta(A \\cap B) $$\n则我们称$\\Delta$是次模函数。\n定义2 Lovasz extension 现存在一集合函数$\\Delta:{0,1}^p \\rightarrow \\mathbb{R}$且$\\Delta(\\pmb{0})=0$，则其Lovasz extension为\n$$ \\overline{\\Delta} = \\sum_{i=1}^p m_i g_i(\\pmb{m}) \\tag{2} $$\n$$ g_i(m) = \\Delta({\\pi_1,\\cdots,\\pi_i}) - \\Delta({\\pi_1,\\cdots,\\pi_{i-1}}) $$\n$\\pi$是一个数组，根据元素$\\pmb{m}$降序排序。例如，$x_{\\pi_1} \\geq x_{\\pi_2} \\geq \\cdots \\geq x_{\\pi_p}$。\n此时$\\overline{\\Delta}$已经是一个连续、分段线性的函数了，可以直接对误差$m$求导，导数为$g(m)$。\nLovasz Loss在多类分割中的应用 假设$F_i(c)$表示的是模型最后输出的像素$i$预测为类别$c$的非归一化分数，则可以通过softmax函数将$F_i(c)$归一化得到像素$i$预测为类别$c$的概率：\n$$ f_i(c) = \\frac{e^{F_i(c)}}{\\sum_{c\u0026rsquo; \\in C} e^{F_i(c\u0026rsquo;)}} $$\n那么(2)中的$m_i(c)$可以定义为\n$$ m_i(c) = \\begin{cases} \u0026amp; 1-f_i(c) \u0026amp; \\text{if}~c=y_i^{*} \\\\ \u0026amp; f_i(c) \u0026amp; \\text{otherwise} \\end{cases} $$\n那么损失函数为\n$$ loss(\\pmb{f}(c)) = \\overline{\\Delta_{J_c}}(\\pmb{m}(c)) $$\n考虑到类别平均mIoU的计算方式，最终的损失函数为\n$$ loss(\\pmb{f}) = \\frac{1}{\\vert C \\vert} \\sum_{c \\in C} \\overline{\\Delta_{J_c}}(\\pmb{m}(c)) $$\nLovasz Loss在多类分割中的代码流程 步骤1 计算预测结果的误差\nsigns = 2. * predictions.float() - 1. errors = (1. - logits * Variable(signs)) errors_sorted, perm = torch.sort(errors, dim=0, descending=True) 这一步得到公式(2)中的$m_i$。\n步骤2 计算IoU得分\ngts = gt_sorted.sum() intersection = gts - gt_sorted.float().cumsum(0) union = gts + (1 - gt_sorted).float().cumsum(0) jaccard = 1. - intersection / union 这一步得到公式(1)的值，即IoU得分。\n步骤3 根据IoU得分计算Lovasz extension的梯度\njaccard[1:p] = jaccard[1:p] - jaccard[0:-1] 这一步得到公式(2)中的$g_i(\\pmb{m})$。\n步骤4 计算Loss\nloss = torch.dot(F.relu(errors_sorted), Variable(grad)) 这一步得到公式(2)的值。\n","permalink":"https://cspaulia.github.io/cspaulia-blog/posts/loss/","summary":"\u003ch2 id=\"分类任务损失函数\"\u003e分类任务损失函数\u003c/h2\u003e\n\u003ch3 id=\"交叉熵cross-entropy\"\u003e交叉熵（Cross Entropy）\u003c/h3\u003e\n\u003cp\u003e$$\n\\text{H}_p(q) = \\sum_x q(x) \\log_2(\\frac{1}{p(x)}) = - \\sum_x q(x) \\log_2(p(x))\n$$\u003c/p\u003e\n\u003cp\u003e交叉熵为我们提供了一种表达两种概率分布的差异的方法。p和q的分布越不相同，p相对于q的交叉熵将越大于p的熵。\u003c/p\u003e\n\u003cp\u003e在实际计算中，\u003c/p\u003e\n\u003cp\u003e$$\n\\text{L} = - \\sum_x q(y|x) \\log_2(p(y|x))\n= - \\frac{1}{N} \\sum_x \\sum_c y_{xc} \\log_2(p(y_c|x))\n$$\u003c/p\u003e\n\u003cp\u003e其中，$N$表示样本数量，$x$表示样本，$c$表示类别，$y_{xc}$表示类别为$c$时$x$的预测标签，只有$c$与真实标签的类别$\\hat{c}$相同时，$y_{x\\hat{c}} = 1$，即$q(y_{\\hat{c}}|x)=1/N$，其余类别$y_{xc} = 0$，即$q(y_c|x)=0/N=0$。\u003c/p\u003e\n\u003cp\u003e举个例子，\u003c/p\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth style=\"text-align: center\"\u003e预测（softmax归一化后）\u003c/th\u003e\n          \u003cth style=\"text-align: center\"\u003e真实值\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: center\"\u003e[0.1, 0.2, 0.7]\u003c/td\u003e\n          \u003ctd style=\"text-align: center\"\u003e[0, 0, 1]\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: center\"\u003e[0.3, 0.4, 0.3]\u003c/td\u003e\n          \u003ctd style=\"text-align: center\"\u003e[0, 1, 0]\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: center\"\u003e[0.1, 0.2, 0.7]\u003c/td\u003e\n          \u003ctd style=\"text-align: center\"\u003e[1, 0, 0]\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e计算损失函数值：\u003c/p\u003e\n\u003cp\u003e$$\n\\text{sample 1 Loss} = - (0 \\times \\log{0.1} + 0 \\times \\log{0.2} + 1 \\times \\log{0.7}) = 0.36\n$$\u003c/p\u003e","title":"记录100种损失函数（Loss Function）"},{"content":"","permalink":"https://cspaulia.github.io/cspaulia-blog/series/","summary":"series","title":"Series"}]