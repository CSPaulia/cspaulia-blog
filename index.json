[{"content":"Cross Attention 来自博客\n简介 Cross Attention是：\n融合两种不同的嵌入序列的注意力机制 两个序列必须包含相同的维度 两个序列可以来自不同的模态（例如文本、图像、声音） 其中一个序列作为Query的输入，决定了输出的长度 另一个序列作为Key和Value的输入 Cross Attention vs Self-attention Cross Attention与Self-attention只有输入不同。Cross Attention输入为两个维度相同的嵌入序列；Self-attention输入为一个嵌入序列，其KQV均由该序列生成。\nCross Attention算法 拥有两个序列S1、S2 计算S1的K、V 计算S2的Q 根据K和Q计算注意力矩阵 将V应用于注意力矩阵 输出的序列长度与S2一致 $$ \\pmb{\\text{softmax}}((W_Q S_2)(W_K S_1)^\\mathrm{T})W_v S_1 $$\n","permalink":"https://cspaulia.github.io/posts/cross_attention/","summary":"\u003ch1 id=\"cross-attention\"\u003eCross Attention\u003c/h1\u003e\n\u003cp\u003e来自\u003ca href=\"https://vaclavkosar.com/ml/cross-attention-in-transformer-architecture\"\u003e博客\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"简介\"\u003e简介\u003c/h2\u003e\n\u003cp\u003eCross Attention是：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e融合两种不同的嵌入序列的注意力机制\u003c/li\u003e\n\u003cli\u003e两个序列必须包含\u003cstrong\u003e相同的维度\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003e两个序列可以来自不同的模态（例如文本、图像、声音）\u003c/li\u003e\n\u003cli\u003e其中一个序列作为\u003cstrong\u003eQuery的输入\u003c/strong\u003e，决定了输出的长度\u003c/li\u003e\n\u003cli\u003e另一个序列作为\u003cstrong\u003eKey和Value的输入\u003c/strong\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"cross-attention-vs-self-attention\"\u003eCross Attention vs Self-attention\u003c/h2\u003e\n\u003cp\u003eCross Attention与Self-attention只有输入不同。Cross Attention输入为两个维度相同的嵌入序列；Self-attention输入为一个嵌入序列，其KQV均由该序列生成。\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"cross attention\" loading=\"lazy\" src=\"cross_attention/cross_attention.png\"\u003e\u003c/p\u003e\n\u003ch2 id=\"cross-attention算法\"\u003eCross Attention算法\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e拥有两个序列S1、S2\u003c/li\u003e\n\u003cli\u003e计算S1的K、V\u003c/li\u003e\n\u003cli\u003e计算S2的Q\u003c/li\u003e\n\u003cli\u003e根据K和Q计算注意力矩阵\u003c/li\u003e\n\u003cli\u003e将V应用于注意力矩阵\u003c/li\u003e\n\u003cli\u003e输出的序列长度与S2一致\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e$$\n\\pmb{\\text{softmax}}((W_Q S_2)(W_K S_1)^\\mathrm{T})W_v S_1\n$$\u003c/p\u003e","title":""},{"content":"FLOPs 注意s小写，是floating point operations的缩写（这里的小s则表示复数），表示浮点运算数，理解为计算量。可以用来衡量算法/模型的复杂度\n","permalink":"https://cspaulia.github.io/posts/flops/","summary":"\u003ch1 id=\"flops\"\u003eFLOPs\u003c/h1\u003e\n\u003cp\u003e注意s小写，是floating point operations的缩写（这里的小s则表示复数），表示浮点运算数，理解为计算量。可以用来衡量算法/模型的复杂度\u003c/p\u003e","title":""},{"content":"Focal Loss $$ \\text{FL}(p_t) = (1-p_t)^\\gamma\\log(p_t) $$\n背景 Focal Loss是为了解决样本数量不平衡而提出的，还强调了样本的难易性。\nBalenced Cross Entropy 为了解决样本数量不平衡这个问题，我们可以选择给Cross Entropy添加权重。以二分类问题举例，Cross Entropy \u0026amp; KL Divergence这篇博客已经介绍过Binary Cross Entropy：\n$$ \\text{L} = \\sum_{i=1}^N [y_i\\log p + (1-y_i)\\log(1-p)] $$\n改写一下，\n$$ \\text{L}=\\left{ \\begin{aligned} \u0026amp; -log(p) \u0026amp; \\text{if}~y=1 \\ \u0026amp; -log(1-p) \u0026amp; \\text{otherwise} \\end{aligned} \\right. $$\n再改写一下，\n$$ p_t=\\left{ \\begin{aligned} \u0026amp; p \u0026amp; \\text{if}~y=1 \\ \u0026amp; 1-p \u0026amp; \\text{otherwise} \\end{aligned} \\right. $$\n$$ \\text{L} = -log(p_t) $$\n添加权重，\n$$ \\text{L} = -\\alpha_tlog(p_t) $$\n其中$y=1$时$\\alpha_t=\\alpha$；$y=0$时$\\alpha_t=1-\\alpha$。$\\frac{\\alpha}{1-\\alpha}=\\frac{n}{m}$，$n$为$y=0$的样本（负样本）个数，$m$为$y=1$的样本（正样本）个数。\n样本难易问题 Balenced Cross Entropy确实解决了样本不均衡问题，但并未解决样本难易问题。\nFocal Loss $$ \\text{FL}(p_t) = (1-p_t)^\\gamma\\log(p_t) $$\n$p_t$是模型预测的结果的类别概率值。$−\\log(p_t)$和交叉熵损失函数一致，因此当前样本类别对应的那个$p_t$如果越小，说明预测越不准确，那么$(1-p_t)^{\\gamma}$这一项就会增大，这一项也作为困难样本的系数，预测越不准，Focal Loss越倾向于把这个样本当作困难样本，这个系数也就越大，目的是让困难样本对损失和梯度的贡献更大。\n前面的$\\alpha_t$是类别权重系数。如果你有一个类别不平衡的数据集，那么你肯定想对数量少的那一类在loss贡献上赋予一个高权重，这个$\\alpha_t$就起到这样的作用。因此，$\\alpha_t$应该是一个向量，向量的长度等于类别的个数，用于存放各个类别的权重。一般来说$\\alpha_t$中的值为每一个类别样本数量的倒数，相当于平衡样本的数量差距\n","permalink":"https://cspaulia.github.io/posts/focal/","summary":"\u003ch1 id=\"focal-loss\"\u003eFocal Loss\u003c/h1\u003e\n\u003cp\u003e$$\n\\text{FL}(p_t) = (1-p_t)^\\gamma\\log(p_t)\n$$\u003c/p\u003e\n\u003ch2 id=\"背景\"\u003e背景\u003c/h2\u003e\n\u003cp\u003eFocal Loss是为了解决\u003cstrong\u003e样本数量不平衡\u003c/strong\u003e而提出的，还强调了样本的\u003cstrong\u003e难易性\u003c/strong\u003e。\u003c/p\u003e\n\u003ch2 id=\"balenced-cross-entropy\"\u003eBalenced Cross Entropy\u003c/h2\u003e\n\u003cp\u003e为了解决\u003cstrong\u003e样本数量不平衡\u003c/strong\u003e这个问题，我们可以选择给Cross Entropy添加权重。以二分类问题举例，\u003ca href=\"CE.md\"\u003eCross Entropy \u0026amp; KL Divergence\u003c/a\u003e这篇博客已经介绍过Binary Cross Entropy：\u003c/p\u003e\n\u003cp\u003e$$\n\\text{L} = \\sum_{i=1}^N [y_i\\log p + (1-y_i)\\log(1-p)]\n$$\u003c/p\u003e\n\u003cp\u003e改写一下，\u003c/p\u003e\n\u003cp\u003e$$\n\\text{L}=\\left{\n\\begin{aligned}\n\u0026amp; -log(p) \u0026amp; \\text{if}~y=1 \\\n\u0026amp; -log(1-p) \u0026amp; \\text{otherwise}\n\\end{aligned}\n\\right.\n$$\u003c/p\u003e\n\u003cp\u003e再改写一下，\u003c/p\u003e\n\u003cp\u003e$$\np_t=\\left{\n\\begin{aligned}\n\u0026amp; p \u0026amp; \\text{if}~y=1 \\\n\u0026amp; 1-p \u0026amp; \\text{otherwise}\n\\end{aligned}\n\\right.\n$$\u003c/p\u003e\n\u003cp\u003e$$\n\\text{L} = -log(p_t)\n$$\u003c/p\u003e\n\u003cp\u003e添加权重，\u003c/p\u003e\n\u003cp\u003e$$\n\\text{L} = -\\alpha_tlog(p_t)\n$$\u003c/p\u003e","title":""},{"content":"GELU $$ \\text{GELU}(x) = 0.5x(1+\\tanh(\\sqrt{\\frac{2}{\\pi}}(x+0.044715x^3))) $$\n优点 具有更光滑的导数：GELU函数的导数是连续的，这使得在训练深度神经网络时可以更容易地传播梯度，避免了ReLU函数在$x=0$处的导数不连续的问题，从而减少了训练过程中出现的梯度消失问题。 可以提高模型的性能：在实际任务中，使用GELU函数的模型通常比使用ReLU函数的模型表现更好，尤其是在自然语言处理和计算机视觉任务中。 可以加速收敛：GELU函数在激活函数的非线性变换中引入了类似于sigmoid函数的变换，这使得GELU函数的输出可以落在一个更广的范围内，有助于加速模型的收敛速度。 ","permalink":"https://cspaulia.github.io/posts/gelu/","summary":"\u003ch1 id=\"gelu\"\u003eGELU\u003c/h1\u003e\n\u003cp\u003e$$\n\\text{GELU}(x) = 0.5x(1+\\tanh(\\sqrt{\\frac{2}{\\pi}}(x+0.044715x^3)))\n$$\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"GELU_Derivative\" loading=\"lazy\" src=\"GELU/GELU_Derivative.jpg\"\u003e\u003c/p\u003e\n\u003ch2 id=\"优点\"\u003e优点\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003e具有更光滑的导数\u003c/strong\u003e：GELU函数的导数是连续的，这使得在训练深度神经网络时可以更容易地传播梯度，避免了ReLU函数在$x=0$处的导数不连续的问题，从而减少了训练过程中出现的梯度消失问题。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e可以提高模型的性能\u003c/strong\u003e：在实际任务中，使用GELU函数的模型通常比使用ReLU函数的模型表现更好，尤其是在自然语言处理和计算机视觉任务中。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e可以加速收敛\u003c/strong\u003e：GELU函数在激活函数的非线性变换中引入了类似于sigmoid函数的变换，这使得GELU函数的输出可以落在一个更广的范围内，有助于加速模型的收敛速度。\u003c/li\u003e\n\u003c/ol\u003e","title":""},{"content":"Layer Normalization {style=\u0026ldquo;margin:0px 100px 0px 100px\u0026rdquo;}\n在上图中，$N$表示样本轴，$C$表示通道轴，$F$是每个通道的特征数量。BN如右侧所示，它是取不同样本的同一个通道的特征做归一化；LN则是如左侧所示，它取的是同一个样本的不同通道做归一化\n1. BN的问题 1.1. BN与Batch Size BN是按照样本数计算归一化统计量的，当样本数很少时，比如说只有4个，这四个样本的均值和方差便不能反映全局的统计分布息，所以基于少量样本的BN的效果会变得很差。\n1.2. BN与RNN {style=\u0026ldquo;margin:0px 250px 0px 250px\u0026rdquo;}\n在一个batch中，通常各个样本的长度都是不同的，当统计到比较靠后的时间片时，例如上图中$t\u0026gt;4$时，这时只有一个样本还有数据，基于这个样本的统计信息不能反映全局分布，所以这时BN的效果并不好。\n另外如果在测试时我们遇到了长度大于任何一个训练样本的测试样本，我们无法找到保存的归一化统计量，所以BN无法运行。\n2. LN详解 2.1. MLP中的LN 先看MLP中的LN。设$H$是一层中隐层节点的数量，$l$是MLP的层数，我们可以计算LN的归一化统计量$\\mu$和$\\sigma$：\n$$ \\mu^{l} = \\frac{1}{H} \\sum_{i=1}^{H} a^l_i ~~~~~~~ \\sigma^{l} = \\sqrt{\\frac{1}{H} \\sum_{i=1}^{H}(a^l_i-\\mu^l)^2} $$\n注意上面统计量的计算是和样本数量没有关系的，它的数量只取决于隐层节点的数量，所以只要隐层节点的数量足够多，我们就能保证LN的归一化统计量足够具有代表性。通过$\\mu^{l}$和$\\sigma^{l}$ 可以得到归一化后的值：\n$$ \\hat{a}^l = \\frac{a^l-\\mu^l}{\\sqrt{(\\sigma^l)^2+\\epsilon}} \\tag{1} $$\n其中$\\epsilon$是一个很小的小数，防止除0。\n在LN中我们也需要一组参数来保证归一化操作不会破坏之前的信息，在LN中这组参数叫做增（gain）$g$和偏置（bias）$b$。假设激活函数为$f$，最终LN的输出为：\n$$ h^l = f(g^l \\odot \\hat{a}^l + b^l) \\tag{2} $$\n合并公式(1)和(2)并忽略参数$l$，有：\n$$ h=f(\\frac{g}{\\sqrt{\\sigma^2+\\epsilon}} \\odot (a-\\mu) + b) $$\n2.2. RNN中的LN 对于RNN时刻$t$时的节点，其输入是$t-1$时刻的隐层状态$h^t$和$t$时刻的输入数据$\\text{x}_t$，可以表示为：\n$$ \\text{a}^t = W_{hh}h^{t-1}+W_{xh}\\text{x}^{t} $$\n接着我们便可以在$\\text{a}^t$上采取和1.1节中完全相同的归一化过程：\n$$ h^t=f(\\frac{g}{\\sqrt{\\sigma^2+\\epsilon}} \\odot (a^t-\\mu^t) + b) ~~~~~~ \\mu^{t} = \\frac{1}{H} \\sum_{i=1}^{H} a^t_i ~~~~~~~ \\sigma^{l} = \\sqrt{\\frac{1}{H} \\sum_{i=1}^{H}(a^t_i-\\mu^t)^2} $$\n","permalink":"https://cspaulia.github.io/posts/layernormalizaition/","summary":"\u003ch1 id=\"layer-normalization\"\u003eLayer Normalization\u003c/h1\u003e\n\u003cp\u003e\u003cimg alt=\"LNvsBN\" loading=\"lazy\" src=\"LN_Pic/LNvsBN.jpg\"\u003e{style=\u0026ldquo;margin:0px 100px 0px 100px\u0026rdquo;}\u003c/p\u003e\n\u003cp\u003e在上图中，$N$表示样本轴，$C$表示通道轴，$F$是每个通道的特征数量。BN如右侧所示，它是取\u003cstrong\u003e不同样本的同一个通道\u003c/strong\u003e的特征做归一化；LN则是如左侧所示，它取的是\u003cstrong\u003e同一个样本的不同通道\u003c/strong\u003e做归一化\u003c/p\u003e\n\u003ch2 id=\"1-bn的问题\"\u003e1. BN的问题\u003c/h2\u003e\n\u003ch3 id=\"11-bn与batch-size\"\u003e1.1. BN与Batch Size\u003c/h3\u003e\n\u003cp\u003eBN是按照\u003cstrong\u003e样本数\u003c/strong\u003e计算归一化统计量的，当样本数很少时，比如说只有4个，这四个样本的均值和方差便不能反映全局的统计分布息，所以基于少量样本的BN的效果会变得很差。\u003c/p\u003e\n\u003ch3 id=\"12-bn与rnn\"\u003e1.2. BN与RNN\u003c/h3\u003e\n\u003cp\u003e\u003cimg alt=\"LNvsBN\" loading=\"lazy\" src=\"LN_Pic/RNN.jpg\"\u003e{style=\u0026ldquo;margin:0px 250px 0px 250px\u0026rdquo;}\u003c/p\u003e\n\u003cp\u003e在一个batch中，通常各个样本的长度都是不同的，当统计到比较靠后的时间片时，例如上图中$t\u0026gt;4$时，这时只有一个样本还有数据，基于这个样本的统计信息不能反映全局分布，所以这时BN的效果并不好。\u003c/p\u003e\n\u003cp\u003e另外如果在测试时我们遇到了长度大于任何一个训练样本的测试样本，我们无法找到保存的归一化统计量，所以BN无法运行。\u003c/p\u003e\n\u003ch2 id=\"2-ln详解\"\u003e2. LN详解\u003c/h2\u003e\n\u003ch3 id=\"21-mlp中的ln\"\u003e2.1. MLP中的LN\u003c/h3\u003e\n\u003cp\u003e先看MLP中的LN。设$H$是一层中隐层节点的数量，$l$是MLP的层数，我们可以计算LN的归一化统计量$\\mu$和$\\sigma$：\u003c/p\u003e\n\u003cp\u003e$$\n\\mu^{l} = \\frac{1}{H} \\sum_{i=1}^{H} a^l_i ~~~~~~~\n\\sigma^{l} = \\sqrt{\\frac{1}{H} \\sum_{i=1}^{H}(a^l_i-\\mu^l)^2}\n$$\u003c/p\u003e\n\u003cp\u003e注意上面统计量的计算是和样本数量没有关系的，它的数量只取决于隐层节点的数量，所以只要隐层节点的数量足够多，我们就能保证LN的归一化统计量足够具有代表性。通过$\\mu^{l}$和$\\sigma^{l}$\n可以得到归一化后的值：\u003c/p\u003e\n\u003cp\u003e$$\n\\hat{a}^l = \\frac{a^l-\\mu^l}{\\sqrt{(\\sigma^l)^2+\\epsilon}} \\tag{1}\n$$\u003c/p\u003e\n\u003cp\u003e其中$\\epsilon$是一个很小的小数，防止除0。\u003c/p\u003e\n\u003cp\u003e在LN中我们也需要一组参数来保证归一化操作不会破坏之前的信息，在LN中这组参数叫做增（gain）$g$和偏置（bias）$b$。假设激活函数为$f$，最终LN的输出为：\u003c/p\u003e\n\u003cp\u003e$$\nh^l = f(g^l \\odot \\hat{a}^l + b^l) \\tag{2}\n$$\u003c/p\u003e\n\u003cp\u003e合并公式(1)和(2)并忽略参数$l$，有：\u003c/p\u003e\n\u003cp\u003e$$\nh=f(\\frac{g}{\\sqrt{\\sigma^2+\\epsilon}} \\odot (a-\\mu) + b)\n$$\u003c/p\u003e\n\u003ch3 id=\"22-rnn中的ln\"\u003e2.2. RNN中的LN\u003c/h3\u003e\n\u003cp\u003e对于RNN时刻$t$时的节点，其输入是$t-1$时刻的隐层状态$h^t$和$t$时刻的输入数据$\\text{x}_t$，可以表示为：\u003c/p\u003e\n\u003cp\u003e$$\n\\text{a}^t = W_{hh}h^{t-1}+W_{xh}\\text{x}^{t}\n$$\u003c/p\u003e","title":""},{"content":"Lovasz Loss Lovasz Loss的推导 IoU (intersection-over-union，也叫jaccard index)是自然图像分割比赛中常用的一个衡量分割效果的评价指标，所以一个自然的想法就是能否将IoU作为loss function来直接优化。交并比公式：\n$$ J_c(y^{},\\widetilde{y}) = \\frac{\\vert {y^{}=c} \\cap {\\widetilde{y}=c}\\vert}{\\vert {y^{*}=c} \\cup {\\widetilde{y}=c}\\vert} $$\n其中$y^{*}$表示Ground Truth标签，$\\widetilde{y}$表示预测标签，$\\vert \\cdot \\vert$表示集合中的元素个数。可以看出上式的值是介于0到1之间的，由此可以设计出损失函数：\n$$ \\Delta_{J_c}(y^{},\\widetilde{y})=1-J_c(y^{},\\widetilde{y}) $$\n这个损失函数是离散的，无法直接求导，需要对其做光滑延拓。\n改写一下$\\Delta_{J_c}$,\n$$ \\Delta_{J_c} = 1-J_c(y^{},\\widetilde{y}) = \\frac{\\vert M_c \\vert}{\\vert {y^{}=c} \\cup M_c \\vert} \\tag{1} $$\n其中，$M_c(y^{},\\widetilde{y}) = {y^{}=c,\\widetilde{y}\\neq c} \\cup {y^{*} \\neq c,\\widetilde{y}=c}$，$M_c$是损失函数的自变量，它表达网络分割结果与Ground Truth标签不匹配的集合。$M_c$的定义域为${0,1}^p$，即$M_c \\in {0,1}^p$，$p$表示集合$M_c$中像素的个数。\n由于(1)是次模（submodular）函数，故可以对其做光滑延拓。\n定义1 若一个集合函数$\\Delta:{0,1}^p \\rightarrow \\mathbb{R}$对于所有的集合$A,B \\in {0,1}^p$满足\n$$ \\Delta(A) + \\Delta(B) \\geq \\Delta(A \\cup B) + \\Delta(A \\cap B) $$\n则我们称$\\Delta$是次模函数。\n定义2 Lovasz extension 现存在一集合函数$\\Delta:{0,1}^p \\rightarrow \\mathbb{R}$且$\\Delta(\\pmb{0})=0$，则其Lovasz extension为\n$$ \\overline{\\Delta} = \\sum_{i=1}^p m_i g_i(\\pmb{m}) \\tag{2} $$\n$$ g_i(m) = \\Delta({\\pi_1,\\cdots,\\pi_i}) - \\Delta({\\pi_1,\\cdots,\\pi_{i-1}}) $$\n$\\pi$是一个数组，根据元素$\\pmb{m}$降序排序。例如，$x_{\\pi_1} \\geq x_{\\pi_2} \\geq \\cdots \\geq x_{\\pi_p}$。\n此时\\overline{\\Delta}已经是一个连续、分段线性的函数了，可以直接对误差$m$求导，导数为$g(m)$。\nLovasz Loss在多类分割中的应用 假设$F_i(c)$表示的是模型最后输出的像素$i$预测为类别$c$的非归一化分数，则可以通过softmax函数将$F_i(c)$归一化得到像素$i$预测为类别$c$的概率：\n$$ f_i(c) = \\frac{e^{F_i(c)}}{\\sum_{c\u0026rsquo; \\in C} e^{F_i(c\u0026rsquo;)}} $$\n那么(2)中的$m_i(c)$可以定义为\n$$ m_i(c) = \\left{ \\begin{aligned} \u0026amp; 1-f_i(c) \u0026amp; \\text{if}~c=y_i^{*} \\ \u0026amp; f_i(c) \u0026amp; \\text{otherwise} \\end{aligned} \\right. $$\n那么损失函数为\n$$ loss(\\pmb{f}(c)) = \\overline{\\Delta_{J_c}}(\\pmb{m}(c)) $$\n考虑到类别平均mIoU的计算方式，最终的损失函数为\n$$ loss(\\pmb{f}) = \\frac{1}{\\vert C \\vert} \\sum_{c \\in C} \\overline{\\Delta_{J_c}}(\\pmb{m}(c)) $$\nLovasz Loss在多类分割中的代码流程 步骤1 计算预测结果的误差\nsigns = 2. * predictions.float() - 1. errors = (1. - logits * Variable(signs)) errors_sorted, perm = torch.sort(errors, dim=0, descending=True) 这一步得到(2)中的$m_i$。\n步骤2 计算IoU得分\ngts = gt_sorted.sum() intersection = gts - gt_sorted.float().cumsum(0) union = gts + (1 - gt_sorted).float().cumsum(0) jaccard = 1. - intersection / union 这一步得到(1)的值，即IoU得分。\n步骤3 根据IoU得分计算Lovasz extension的梯度\njaccard[1:p] = jaccard[1:p] - jaccard[0:-1] 这一步得到(2)中的$g_i(\\pmb{m})$。\n步骤4 计算Loss\nloss = torch.dot(F.relu(errors_sorted), Variable(grad)) 这一步得到(2)的值。\n","permalink":"https://cspaulia.github.io/posts/lovasz/","summary":"\u003ch1 id=\"lovasz-loss\"\u003eLovasz Loss\u003c/h1\u003e\n\u003ch2 id=\"lovasz-loss的推导\"\u003eLovasz Loss的推导\u003c/h2\u003e\n\u003cp\u003eIoU (intersection-over-union，也叫jaccard index)是自然图像分割比赛中常用的一个衡量分割效果的评价指标，所以一个自然的想法就是能否将IoU作为loss function来直接优化。交并比公式：\u003c/p\u003e\n\u003cp\u003e$$\nJ_c(y^{\u003cem\u003e},\\widetilde{y}) = \\frac{\\vert {y^{\u003c/em\u003e}=c} \\cap {\\widetilde{y}=c}\\vert}{\\vert {y^{*}=c} \\cup {\\widetilde{y}=c}\\vert}\n$$\u003c/p\u003e\n\u003cp\u003e其中$y^{*}$表示Ground Truth标签，$\\widetilde{y}$表示预测标签，$\\vert \\cdot \\vert$表示集合中的元素个数。可以看出上式的值是介于0到1之间的，由此可以设计出损失函数：\u003c/p\u003e\n\u003cp\u003e$$\n\\Delta_{J_c}(y^{\u003cem\u003e},\\widetilde{y})=1-J_c(y^{\u003c/em\u003e},\\widetilde{y})\n$$\u003c/p\u003e\n\u003cp\u003e这个损失函数是离散的，无法直接求导，需要对其做\u003cstrong\u003e光滑延拓\u003c/strong\u003e。\u003c/p\u003e\n\u003cp\u003e改写一下$\\Delta_{J_c}$,\u003c/p\u003e\n\u003cp\u003e$$\n\\Delta_{J_c} = 1-J_c(y^{\u003cem\u003e},\\widetilde{y}) = \\frac{\\vert M_c \\vert}{\\vert {y^{\u003c/em\u003e}=c} \\cup M_c \\vert} \\tag{1}\n$$\u003c/p\u003e\n\u003cp\u003e其中，$M_c(y^{\u003cem\u003e},\\widetilde{y}) = {y^{\u003c/em\u003e}=c,\\widetilde{y}\\neq c} \\cup {y^{*} \\neq c,\\widetilde{y}=c}$，$M_c$是损失函数的自变量，它表达网络分割结果与Ground Truth标签不匹配的集合。$M_c$的定义域为${0,1}^p$，即$M_c \\in {0,1}^p$，$p$表示集合$M_c$中像素的个数。\u003c/p\u003e\n\u003cp\u003e由于(1)是次模（submodular）函数，故可以对其做\u003cstrong\u003e光滑延拓\u003c/strong\u003e。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e定义1\u003c/strong\u003e 若一个集合函数$\\Delta:{0,1}^p \\rightarrow \\mathbb{R}$对于所有的集合$A,B \\in {0,1}^p$满足\u003c/p\u003e\n\u003cp\u003e$$\n\\Delta(A) + \\Delta(B) \\geq \\Delta(A \\cup B) + \\Delta(A \\cap B)\n$$\u003c/p\u003e","title":""}]